<?xml version="1.0" encoding="UTF-8"?>
<!-- This file originates from the project https://github.com/openSUSE/doc-kit -->
<!-- This file can be edited downstream. -->
<!DOCTYPE topic
[
  <!ENTITY % entities SYSTEM "../common/generic-entities.ent">
    %entities;
]>
<!-- refers to legacy doc: <add github link to legacy doc piece, if applicable> -->
<!-- point back to this document with a similar comment added to your legacy doc piece -->
<!-- refer to README.md for file and id naming conventions -->
<!-- metadata is dealt with on the assembly level -->
<topic xml:id="ai-prevent-hallucinations"
 role="concept" xml:lang="en"
 xmlns="http://docbook.org/ns/docbook" version="5.2"
 xmlns:its="http://www.w3.org/2005/11/its"
 xmlns:xi="http://www.w3.org/2001/XInclude"
 xmlns:xlink="http://www.w3.org/1999/xlink"
 xmlns:trans="http://docbook.org/ns/transclusion">
  <info>
    <title>Preventing AI hallucinations</title>
    <meta name="maintainer" content="tbazant@suse.com" its:translate="no"/>
    <abstract>
      <xi:include href="../snippets/ai-intro.xml"/>
      <para>
        This topic describes how to create system prompts that can help AI
        generate valid and accurate content.
      </para>
    </abstract>
  </info>
  <section xml:id="what-is-ai-hallucination">
    <title>What is an AI hallucination?</title>
    <para>
      A hallucination occurs when an LLM generates information that is not based
      on real-world facts or evidence. This can include fictional events,
      incorrect data or irrelevant outputs.
    </para>
  </section>
  <section xml:id="what-causes-ai-hallucinations">
    <title>What causes AI hallucinations?</title>
    <para>
      The most common causes of hallucinations are:
    </para>
    <itemizedlist>
      <listitem>
        <para>
          <emphasis role="bold">Ambiguous prompts.</emphasis> Vague queries can
          lead to random or inaccurate answers.
        </para>
      </listitem>
      <listitem>
        <para>
          <emphasis role="bold">Lack of clear context.</emphasis> When the
          language model lacks context, it can fabricate answers.
        </para>
      </listitem>
      <listitem>
        <para>
          <emphasis role="bold">Long generation length.</emphasis> The longer
          the generated response, the higher the chance that hallucinations can
          happen.
        </para>
      </listitem>
      <listitem>
        <para>
          <emphasis role="bold">No retrieval-augmented process.</emphasis> LLMs
          without access to external sources&mdash;such as databases or search
          engines&mdash;can produce errors when they need to generate specific
          information.
        </para>
      </listitem>
    </itemizedlist>
  </section>
  <section xml:id="how-prevent-hallucinations">
    <title>How can I prevent AI from generating hallucinations?</title>
    <para>
      You can help AI to generate more valid and accurate content by creating
      good prompts. This process is called <emphasis>prompt
      engineering</emphasis>. This section outlines several techniques to create
      a good prompt with real-life examples.
    </para>
    <section xml:id="ai-clear-expectations">
      <title>Set clear expectations</title>
      <para>
        The clearer the prompt, the less the LLM relies on assumptions or
        creativity. A well-defined prompt guides the model toward specific
        information, reducing the likelihood of hallucinations.
      </para>
      <itemizedlist>
        <title>Techniques:</title>
        <listitem>
          <para>
            Use <emphasis role="bold">specific language</emphasis> that guides
            the model.
          </para>
        </listitem>
        <listitem>
          <para>
            Focus on <emphasis role="bold">known data sources</emphasis> or real
            events.
          </para>
        </listitem>
        <listitem>
          <para>
            Ask for <emphasis role="bold">summaries</emphasis> or
            <emphasis>paraphrasing</emphasis> from established sources.
          </para>
        </listitem>
      </itemizedlist>
      <itemizedlist>
        <title>Example</title>
        <listitem>
          <para>
            <emphasis role="bold">Ambiguous prompt:</emphasis> <quote>Tell me
            about space.</quote>
          </para>
        </listitem>
        <listitem>
          <para>
            <emphasis role="bold">Clearer prompt:</emphasis> <quote>Give me a
            summary of NASA's recent Mars missions, including factual details
            from their official reports.</quote>
          </para>
        </listitem>
      </itemizedlist>
      <itemizedlist>
        <title>Example</title>
        <listitem>
          <para>
            <emphasis role="bold">Ambiguous prompt:</emphasis> <quote>What is
            quantum computing?</quote>
          </para>
        </listitem>
        <listitem>
          <para>
            <emphasis role="bold">Clearer prompt: </emphasis> <quote>Explain the
            basic principles of quantum computing, specifically how qubits work
            compared to classical bits.</quote>
          </para>
        </listitem>
      </itemizedlist>
    </section>
    <section xml:id="ai-break-complex">
      <title>Break down complex prompts</title>
      <para>
        Break down complex or broad prompts into manageable pieces. This keeps
        the language model focused on a narrower scope and reduces the chance of
        hallucination.
      </para>
      <itemizedlist>
        <title>Example</title>
        <listitem>
          <para>
            <emphasis role="bold">Complex query:</emphasis> <quote>Explain AI
            and how it can change the world.</quote>
          </para>
        </listitem>
        <listitem>
          <para>
            <emphasis role="bold">Broken down prompt:</emphasis> <quote>What are
            the most recent advancements in AI? How are these advancements being
            applied in the healthcare industry?</quote>
          </para>
        </listitem>
      </itemizedlist>
    </section>
    <section xml:id="ai-rag">
      <title>Use retrieval-augmented generation (RAG)</title>
      <para>
        When crafting prompts, encourage the model to retrieve relevant
        information instead of generating from scratch. Integrating a RAG system
        allows the LLM to query a specific database or resource.
      </para>
      <itemizedlist>
        <title>Techniques</title>
        <listitem>
          <para>
            Include context cues, for example, <quote>Based on the following
            document</quote> or <quote>From the official website</quote> to
            point the model toward facts.
          </para>
        </listitem>
        <listitem>
          <para>
            If using a tool like &milvus; or &chromadb;, structure your prompt
            to refer to specific collections or documents. This reduces
            hallucination by grounding the LLM in real data.
          </para>
        </listitem>
      </itemizedlist>
      <itemizedlist>
        <listitem>
          <para>
            <emphasis role="bold">Prompt without RAG:</emphasis> <quote>Tell me
            about the company's AI products.</quote>
          </para>
        </listitem>
        <listitem>
          <para>
            <emphasis role="bold">Prompt with RAG:</emphasis> <quote>Based on the
            <quote>technical-info</quote> collection in &milvus;, provide
            details about the company's AI product line.</quote>
          </para>
        </listitem>
      </itemizedlist>
    </section>
    <section xml:id="ai-contrain">
      <title>Constrain the output</title>
      <para>
        Limit the length or scope of the language model's response. Shorter,
        more direct answers reduce the chances of the model drifting off-topic
        or hallucinating extra details.
      </para>
      <itemizedlist>
        <title>Technique</title>
        <listitem>
          <para>
            Use <emphasis>tokens</emphasis> or <emphasis>word limits</emphasis>
            where possible to enforce the output length.
          </para>
        </listitem>
      </itemizedlist>
      <itemizedlist>
        <title>Example</title>
        <listitem>
          <para>
            <emphasis role="bold">Unconstrained prompt:</emphasis> <quote>Give
            me a detailed report on quantum mechanics</quote>
          </para>
        </listitem>
        <listitem>
          <para>
            <emphasis role="bold">Prompt with limited output:</emphasis>
            <quote>In 100 words or fewer, explain the main concept of quantum
            entanglement.</quote>
          </para>
        </listitem>
      </itemizedlist>
    </section>
    <section xml:id="ai-prompt-verification">
      <title>Prompt for verification</title>
      <para>
        You can structure prompts to ask the LLM for clarification or to cite
        the source of its statements. This leads the model to produce more
        grounded and reliable responses.
      </para>
      <itemizedlist>
        <title>Examples</title>
        <listitem>
          <para>
            <quote>Where did you find this information?</quote>
          </para>
        </listitem>
        <listitem>
          <para>
            <quote>Verify this answer against known historical facts about the
            event.</quote>
          </para>
        </listitem>
      </itemizedlist>
    </section>
    <section xml:id="ai-cot">
      <title>Use Chain-of-Thought (CoT) Prompting</title>
      <para>
        By guiding the model through logical steps, you can control the
        reasoning path and help the model arrive at accurate conclusions. This
        method.is especially helpful when asking the model to explain complex
        processes.
      </para>
      <itemizedlist>
        <title>Example</title>
        <listitem>
          <para>
            <emphasis role="bold">Step-by-step prompt: </emphasis>
            <quote>Explain the following concepts step by step: 1. How do neural
            networks learn from data? 2. How is backpropagation used in this
            process?</quote>
          </para>
        </listitem>
      </itemizedlist>
    </section>
    <section xml:id="ai-prompt-template">
      <title>Use templates for complex tasks</title>
      <para>
        For complex tasks, for example, answering requests for proposals or
        technical questions, templates help provide a structure that minimizes
        hallucinations. This is achieved by making the desired format and
        content explicit.
      </para>
      <itemizedlist>
        <title>Examples</title>
        <listitem>
          <para>
            <quote>Based on the document provided, summarize the key technical
            features of the product. Format the response as: 1. Feature, 2.
            Benefit, 3. Use Case. Use only factual information.</quote>
          </para>
        </listitem>
        <listitem>
          <para>
            Assume your task is to create a customer-facing report that follows
            these guidelines:
          </para>
          <itemizedlist>
            <listitem>
              <para>
                <emphasis role="bold">Direction:</emphasis> Set the tone as
                professional and informative.
              </para>
            </listitem>
            <listitem>
              <para>
                <emphasis role="bold">Format:</emphasis> Specify output as a
                formal report.
              </para>
            </listitem>
            <listitem>
              <para>
                <emphasis role="bold">Examples:</emphasis> Provide a template or
                previous reports as examples.
              </para>
            </listitem>
            <listitem>
              <para>
                <emphasis role="bold">Quality:</emphasis> Use a checklist to
                ensure accuracy and relevance.
              </para>
            </listitem>
            <listitem>
              <para>
                <emphasis role="bold">Labor:</emphasis> Divide sections into
                executive summary, detailed findings and conclusions.
              </para>
            </listitem>
          </itemizedlist>
          <para>
            The resulting prompt that corresponds to the above guidelines may
            look similar to the following example. You can copy and paste the
            whole text into an AI-driven chatbot prompt.
          </para>
<screen>Direction:

Adopt a professional and informative tone throughout the report. The
content should be clear, concise, and tailored to a business audience.

Format:

The output should be in the form of a formal report, structured with headings,
subheadings, and bullet points where necessary. Use professional language
and adhere to business writing standards.

Examples:

Here is a template of the report structure to follow:

Executive Summary:
- Overview of key findings and recommendations.
Detailed Findings:
- Section 1: [Topic]
- Section 2: [Topic]
- Section 3: [Topic]
Conclusions:
- Summary of findings and next steps.

Please refer to previous reports such as [Report A] and [Report B] for style
and formatting guidelines.

Quality:

Use the following checklist to ensure the report's accuracy and relevance:
  1. Verify all data and statistics are correct and up-to-date.
  2. Ensure the report is free of grammatical and typographical errors.
  3. Cross-check that all sections are consistent and logically structured.
  4. Validate that the report meets the customer’s objectives and addresses
     their concerns.

Labor:

Divide the report into the following sections:
  1. Executive Summary: Summarize the main findings and key recommendations in a 
     concise manner.
  2. Detailed Findings: Provide in-depth analysis and data for each key area of
     focus, divided into logical subsections.
  3. Conclusions: Offer a summary of the findings and suggest actionable next
     steps for the customer.</screen>
        </listitem>
      </itemizedlist>
    </section>
  </section>
</topic>
