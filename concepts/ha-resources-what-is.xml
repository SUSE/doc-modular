<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic
[
  <!ENTITY % entities SYSTEM "../common/generic-entities.ent">
    %entities;
]>

<!-- refers to legacy doc: https://github.com/SUSE/doc-sleha/blob/main/xml/ha_configuring_resources.xml -->

<topic xml:id="ha-resources-what-is"
 role="concept" xml:lang="en"
 xmlns="http://docbook.org/ns/docbook" version="5.2"
 xmlns:its="http://www.w3.org/2005/11/its"
 xmlns:xi="http://www.w3.org/2001/XInclude"
 xmlns:xlink="http://www.w3.org/1999/xlink"
 xmlns:trans="http://docbook.org/ns/transclusion">
  <info>
    <title>What are cluster resources?</title>
    <meta name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
    <abstract>
      <xi:include href="../snippets/ha-resources.xml"/>
      <xi:include href="../snippets/ha-resource-agent.xml"/>
    </abstract>
  </info>

<section xml:id="sec-ha-config-basics-resources-types">
   <title>Types of resources</title>
   <variablelist>
    <varlistentry>
     <term>Primitives</term>
     <listitem>
      <para>
       A primitive resource, the most basic type of resource.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Groups</term>
     <listitem>
      <para>
       Groups contain a set of resources that need to be located together,
       started sequentially and stopped in the reverse order.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Clones</term>
     <listitem>
      <para>
       Clones are resources that can be active on multiple nodes. Any
       resource can be cloned, provided the respective resource agent
       supports it.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Promotable clones</term>
     <listitem>
      <para>
       Promotable clones are a
       special type of clone resource that can be promoted.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </section>

  <section xml:id="sec-ha-config-basics-raclasses">
   <title>Supported resource agent classes</title>
   <para>
    For each cluster resource you add, you need to define the standard that
    the resource agent conforms to. Resource agents abstract the services
    they provide and present an accurate status to the cluster, which allows
    the cluster to be non-committal about the resources it manages. The
    cluster relies on the resource agent to react appropriately when given a
    start, stop or monitor command.
   </para>
   <para>
    Typically, resource agents come in the form of shell scripts. &sleha;
    supports the following classes of resource agents:
   </para>
   <variablelist>
    <varlistentry xml:id="vle-ha-resources-ocf-ra">
     <term>Open Cluster Framework (OCF) resource agents</term>
     <listitem>
      <para>
       OCF RA agents are best suited for use with &ha;, especially when
       you need promotable clone resources or special monitoring abilities. The
       agents are generally located in
       <filename>/usr/lib/ocf/resource.d/<replaceable>provider</replaceable>/</filename>.
       Their functionality is similar to that of LSB scripts. However, the
       configuration is always done with environmental variables that allow
       them to accept and process parameters easily.
       OCF specifications have strict definitions of which exit codes must
       be returned by actions.
      </para>
      <para>
       All OCF Resource Agents are required to have at least the actions
       <literal>start</literal>, <literal>stop</literal>,
       <literal>status</literal>, <literal>monitor</literal> and
       <literal>meta-data</literal>. The <literal>meta-data</literal> action
       retrieves information about how to configure the agent. For example,
       to know more about the <literal>IPaddr</literal> agent by
       the provider <literal>heartbeat</literal>, use the following command:
      </para>
<screen>OCF_ROOT=/usr/lib/ocf /usr/lib/ocf/resource.d/heartbeat/IPaddr meta-data</screen>
      <para>
       The output is information in XML format, including several sections
       (general description, available parameters, available actions for the
       agent).
      </para>
      <para>
       Alternatively, use the &crmsh; to view information on OCF resource
       agents.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Linux Standards Base (LSB) scripts</term>
     <listitem>
      <para>
       LSB resource agents are generally provided by the operating
       system/distribution and are found in
       <filename>/etc/init.d</filename>. To be used with the cluster, they
       must conform to the LSB init script specification. For example, they
       must have several actions implemented, which are, at minimum,
       <literal>start</literal>, <literal>stop</literal>,
       <literal>restart</literal>, <literal>reload</literal>,
       <literal>force-reload</literal> and <literal>status</literal>. For
       more information, see
       <link xlink:href="https://refspecs.linuxbase.org/LSB_4.1.0/LSB-Core-generic/LSB-Core-generic/iniscrptact.html"/>.
      </para>
      <para>
       The configuration of those services is not standardized. If you
       intend to use an LSB script with &ha;, make sure that you
       understand how the relevant script is configured. You can often find
       information about this in the documentation of the relevant package
       in
       <filename>/usr/share/doc/packages/<replaceable>PACKAGENAME</replaceable></filename>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>systemd</term>
     <listitem>
      <para>
       &pace; can manage systemd services if they
       are present. Instead of init scripts, systemd has unit files.
       Generally, the services (or unit files) are provided by the operating
       system. In case you want to convert existing init scripts, find more
       information at
       <link xlink:href="https://0pointer.de/blog/projects/systemd-for-admins-3.html"/>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Service</term>
     <listitem>
      <para>
       There are currently many types of system
       services that exist in parallel: <literal>LSB</literal> (belonging to
       System V init), <literal>systemd</literal> and (in some
       distributions) <literal>upstart</literal>. Therefore, &pace;
       supports a special alias that figures out which one
       applies to a given cluster node. This is particularly useful when the
       cluster contains a mix of systemd, upstart and LSB services.
       &pace; tries to find the named service in the following order:
       as an LSB (SYS-V) init script, a systemd unit file or an Upstart
       job.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>&stonith; (fencing) resource agents</term>
     <listitem>
      <para>
       This class is used exclusively for fencing related resources.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
   <para>
    The agents supplied with &sleha; are written to OCF
    specifications.
   </para>
  </section>

  <section xml:id="sec-ha-config-basics-timeouts">
   <title>Timeout values</title>
   <para>
    Timeouts values for resources can be influenced by the following
    parameters:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      <varname>op_defaults</varname> (global timeout for operations),
     </para>
    </listitem>
    <listitem>
     <para>
      a specific timeout value defined in a resource template,
     </para>
    </listitem>
    <listitem>
     <para>
      a specific timeout value defined for a resource.
     </para>
    </listitem>
   </itemizedlist>
   <note>
    <title>Priority of values</title>
    <para>
     If a <emphasis>specific</emphasis> value is defined for a resource, it
     takes precedence over the global default. A specific value for a
     resource also takes precedence over a value that is defined in a
     resource template.
    </para>
   </note>
   <para>
    Getting timeout values right is very important. Setting them too low
    results in a lot of (unnecessary) fencing operations for the
    following reasons:
   </para>
   <orderedlist spacing="normal">
    <listitem>
     <para>
      If a resource runs into a timeout, it fails and the cluster tries
      to stop it.
     </para>
    </listitem>
    <listitem>
     <para>
      If stopping the resource also fails (for example, because the timeout
      for stopping is set too low), the cluster fences the node. It
      considers the node where this happens to be out of control.
     </para>
    </listitem>
   </orderedlist>
   <para>
    You can adjust the global default for operations and set any specific
    timeout values with both &crmsh; and &hawk;. The best practice for
    determining and setting timeout values is as follows:
   </para>
   <procedure>
    <title>Determining timeout values</title>
    <step>
     <para>
      Check how long it takes your resources to start and stop (under load).
     </para>
    </step>
    <step>
     <para>
      If needed, add the <varname>op_defaults</varname> parameter and set
      the (default) timeout value accordingly:
     </para>
     <substeps performance="required">
      <step>
       <para>
        For example, set <literal>op_defaults</literal> to
        <literal>60</literal> seconds:
       </para>
 <screen>&prompt.crm.conf;<command>op_defaults timeout=60</command></screen>
      </step>
      <step>
       <para>
        For resources that need longer periods of time, define individual
        timeout values.
       </para>
      </step>
     </substeps>
    </step>
    <step>
     <para>
      When configuring operations for a resource, add separate
      <literal>start</literal> and <literal>stop</literal> operations. When
      configuring operations with &hawk;, it provides useful timeout
      proposals for those operations.
     </para>
    </step>
   </procedure>
  </section>
  <section xml:id="sec-ha-config-basics-meta-attr">
  <title>Resource options (meta attributes)</title>
  <para>
   For each resource you add, you can define options. Options are used by
   the cluster to decide how your resource should behave; they tell
   the CRM how to treat a specific resource. Resource options can be set
   with the <command>crm_resource --meta</command> command or with &hawk;.
  </para>
  <para>
   The following list shows some common options:
  </para>
  <variablelist>
   <varlistentry>
    <term><literal>priority</literal></term>
    <listitem>
     <para>
      If not all resources can be active, the cluster stops lower-priority
      resources to keep higher-priority resources active.
     </para>
     <para>
      The default value is <literal>0</literal>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><literal>target-role</literal></term>
    <listitem>
     <para>
      In what state should the cluster attempt to keep this resource?
      Allowed values: <literal>Stopped</literal>, <literal>Started</literal>,
      <literal>Unpromoted</literal>, <literal>Promoted</literal>.
     </para>
     <para>
      The default value is <literal>Started</literal>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><literal>is-managed</literal></term>
    <listitem>
     <para>
      Is the cluster allowed to start and stop the resource? Allowed
      values: <literal>true</literal>, <literal>false</literal>. If the
      value is set to <literal>false</literal>, the status of the
      resource is still monitored and any failures are reported. This is
      different from setting a resource to
      <literal>maintenance="true"</literal>.
     </para>
     <para>
      The default value is <literal>true</literal>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><literal>maintenance</literal></term>
    <listitem>
     <para>
      Can the resources be touched manually? Allowed values:
      <literal>true</literal>, <literal>false</literal>. If set to
      <literal>true</literal>, all resources become unmanaged: the
      cluster stops monitoring them and does not know their
      status. You can stop or restart cluster resources without
      the cluster attempting to restart them.
     </para>
     <para>
      The default value is <literal>false</literal>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><literal>resource-stickiness</literal></term>
    <listitem>
     <para>
      How much does the resource prefer to stay where it is?
     </para>
     <para>
      The default value is <literal>1</literal> for individual clone instances,
      and <literal>0</literal> for all other resources.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><literal>migration-threshold</literal></term>
    <listitem>
     <para>
      How many failures should occur for this resource on a node before
      making the node ineligible to host this resource?
     </para>
     <para>
      The default value is <literal>INFINITY</literal>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><literal>multiple-active</literal></term>
    <listitem>
     <para>
      What should the cluster do if it ever finds the resource active on
      more than one node? Allowed values: <literal>block</literal> (mark
      the resource as unmanaged), <literal>stop_only</literal>,
      <literal>stop_start</literal>.
     </para>
     <para>
      The default value is <literal>stop_start</literal>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><literal>failure-timeout</literal></term>
    <listitem>
     <para>
      How many seconds to wait before acting as if the failure did not
      occur (and potentially allowing the resource back to the node on
      which it failed)?
     </para>
     <para>
      The default value is <literal>0</literal> (disabled).
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><literal>allow-migrate</literal></term>
    <listitem>
     <para>
      Whether to allow live migration for resources that support
      <literal>migrate_to</literal> and <literal>migrate_from</literal>
      actions. If the value is set to <literal>true</literal>, the resource can
      be migrated without loss of state. If the value is set to <literal>false</literal>,
      the resource will be shut down on the first node and restarted on the second node.
     </para>
     <para>
      The default value is <literal>true</literal> for
      <literal>ocf:pacemaker:remote</literal> resources, and
      <literal>false</literal> for all other resources.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
     <term><literal>allow-unhealthy-nodes</literal></term>
     <listitem>
       <para>
        Allows the resource to run on a node even if the node's health score would otherwise
        prevent it.
       </para>
       <para>
         The default value is <literal>false</literal>.
       </para>
     </listitem>
   </varlistentry>
   <varlistentry>
    <term><literal>remote-node</literal></term>
    <listitem>
     <para>
      The name of the remote node this resource defines. This both
      enables the resource as a remote node and defines the unique name
      used to identify the remote node. If no other parameters are set,
      this value is also assumed as the host name to connect to at the
      <varname>remote-port</varname> port.
     </para>
     <para>
      This option is disabled by default.
     </para>
     <warning>
      <title>Use unique IDs</title>
      <para>
       This value must not overlap with any existing resource or node IDs.
      </para>
     </warning>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><literal>remote-port</literal></term>
    <listitem>
     <para>
      Custom port for the guest connection to pacemaker_remote.
     </para>
     <para>
      The default value is <literal>3121</literal>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><literal>remote-addr</literal></term>
    <listitem>
     <para>
      The IP address or host name to connect to if the remote node's
      name is not the host name of the guest.
     </para>
     <para>
      The default value is the value set by <literal>remote-node</literal>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><literal>remote-connect-timeout</literal></term>
    <listitem>
     <para>
      How long before a pending guest connection times out?
     </para>
     <para>
      The default value is <literal>60s</literal>.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </section>

 <section xml:id="sec-ha-config-basics-inst-attr">
  <title>Instance attributes (parameters)</title>

  <para>
   The scripts of all resource classes can be given parameters which
   determine how they behave and which instance of a service they control.
   If your resource agent supports parameters, you can add them with the
   <command>crm_resource</command> command or with &hawk;. In the
   <command>crm</command> command line utility and in &hawk;, instance
   attributes are called <literal>params</literal> or
   <literal>Parameter</literal>, respectively. The list of instance
   attributes supported by an OCF script can be found by executing the
   following command as &rootuser;:
  </para>
<screen>&prompt.root;<command>crm ra info <replaceable>[class:[provider:]]resource_agent</replaceable></command></screen>
  <para>
   or (without the optional parts):
  </para>
<screen>&prompt.root;<command>crm ra info <replaceable>resource_agent</replaceable></command></screen>
  <para>
   The output lists all the supported attributes, their purpose and default
   values.
  </para>
  <note>
   <title>Instance attributes for groups, clones or promotable clones</title>
   <para>
    Note that groups, clones and promotable clone resources do not have instance
    attributes. However, any instance attributes set are inherited by
    the group's, clone's or promotable clone's children.
   </para>
  </note>
 </section>

 <section xml:id="sec-ha-config-basics-operations">
  <title>Resource operations</title>
  <para>
   By default, the cluster does not ensure that your resources are still
   healthy. To instruct the cluster to do this, you need to add a monitor
   operation to the resource's definition. Monitor operations can be
   added for all classes or resource agents.
  </para>
  <para>
   If you want to ensure that a resource is running, you must configure
   resource monitoring for it. You can configure resource monitoring using
   either &hawk2; or &crmsh;.
  </para>
  <para>
   If the resource monitor detects a failure, the following takes place:
  </para>
  <itemizedlist>
   <listitem>
    <para>
     Log file messages are generated, according to the configuration
     specified in the <literal>logging</literal> section of
     <filename>/etc/corosync/corosync.conf</filename>.
    </para>
   </listitem>
   <listitem>
    <para>
     The failure is reflected in the cluster management tools (&hawk2;,
     <command>crm status</command>), and in the CIB status section.
    </para>
   </listitem>
   <listitem>
    <para>
     The cluster initiates noticeable recovery actions, which may include
     stopping the resource to repair the failed state and restarting the
     resource locally or on another node. The resource also may not be
     restarted, depending on the configuration and state of the cluster.
    </para>
   </listitem>
  </itemizedlist>
  <para>
   If you do not configure resource monitoring, resource failures after a
   successful start are not communicated, and the cluster will always
   show the resource as healthy.
  </para>
   <para>
    Usually, resources are only
    monitored by the cluster while they are running. However, to detect
    concurrency violations, also configure monitoring for resources which are
    stopped. For resource monitoring, specify a timeout and/or start delay
    value, and an interval. The interval tells the CRM how often it should check
    the resource status. You can also set particular parameters such as
    <literal>timeout</literal> for <literal>start</literal> or
    <literal>stop</literal> operations.
   </para>
  <para>
   Monitor operations can have the following properties:
  </para>
  <variablelist>
   <varlistentry>
    <term><literal>id</literal></term>
    <listitem>
     <para>
      Your name for the action. Must be unique. (The ID is not shown.)
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><literal>name</literal></term>
    <listitem>
     <para>
      The action to perform. Common values: <literal>monitor</literal>,
        <literal>start</literal>, <literal>stop</literal>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><literal>interval</literal></term>
    <listitem>
     <para>
      How frequently to perform the operation, in seconds.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><literal>timeout</literal></term>
    <listitem>
     <para>
      How long to wait before declaring the action has failed.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><literal>requires</literal></term>
    <listitem>
     <para>
      What conditions need to be satisfied before this action occurs.
      Allowed values: <literal>nothing</literal>,
      <literal>quorum</literal>, <literal>fencing</literal>. The default
      depends on whether fencing is enabled and if the resource's class
      is <literal>stonith</literal>. For &stonith; resources, the
      default is <literal>nothing</literal>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><literal>on-fail</literal></term>
    <listitem>
     <para>
      The action to take if this action ever fails. Allowed values:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        <literal>ignore</literal>: Pretend the resource did not fail.
       </para>
      </listitem>
      <listitem>
       <para>
        <literal>block</literal>: Do not perform any further operations
        on the resource.
       </para>
      </listitem>
      <listitem>
       <para>
        <literal>stop</literal>: Stop the resource and do not start it
        elsewhere.
       </para>
      </listitem>
      <listitem>
       <para>
        <literal>restart</literal>: Stop the resource and start it again
        (possibly on a different node).
       </para>
      </listitem>
      <listitem>
       <para>
        <literal>fence</literal>: Bring down the node on which the
        resource failed (&stonith;).
       </para>
      </listitem>
      <listitem>
       <para>
        <literal>standby</literal>: Move <emphasis>all</emphasis>
        resources away from the node on which the resource failed.
       </para>
      </listitem>
     </itemizedlist>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><literal>enabled</literal></term>
    <listitem>
     <para>
      If <literal>false</literal>, the operation is treated as if it does
      not exist. Allowed values: <literal>true</literal>,
      <literal>false</literal>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><literal>role</literal></term>
    <listitem>
     <para>
      Run the operation only if the resource has this role.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><literal>record-pending</literal></term>
    <listitem>
     <para>
      Can be set either globally or for individual resources. Makes the
        CIB reflect the state of <quote>in-flight</quote> operations on
        resources.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><literal>description</literal></term>
    <listitem>
     <para>
      Description of the operation.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </section>
</topic>
