<?xml version='1.0' encoding='UTF-8'?><article xmlns="http://docbook.org/ns/docbook" version="5.2" xml:id="two-node-cluster-diskless-sbd-qdevice" xml:lang="de">
  <info>
    <title xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude">Installieren eines einfachen High Availability-Clusters mit zwei Knoten</title>
    <revhistory xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xml:id="rh-HA-two-node-cluster-diskless-sbd-qdevice">
      <revision>
        <date>2025-11-04</date>
        <revdescription>
          <para>
              Erste Version
            </para>
        </revdescription>
      </revision>
    </revhistory>
    <meta xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/> <meta xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" name="architecture">
      <phrase>AMD64/Intel 64</phrase>
      <phrase>POWER</phrase>
      <phrase>IBM Z</phrase>
    </meta> <meta xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" name="productname" its:translate="no">
      <productname version="16.0">SUSE Linux Enterprise High Availability</productname>
    </meta>
    <meta xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" name="title" its:translate="yes">Installieren eines einfachen High Availability-Clusters mit zwei Knoten</meta>
    <meta xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" name="description" its:translate="yes">Einrichten eines einfachen High Availability-Clusters mit zwei Knoten zu Testzwecken</meta>
    <meta xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" name="social-descr" its:translate="yes">Einrichten eines einfachen HA-Clusters mit zwei Knoten</meta>
    <meta xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" name="category" its:translate="no">
      <phrase>Deployment</phrase>
    </meta> <meta xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" name="task" its:translate="no">
      <phrase>Clustering</phrase>
      <phrase>Configuration</phrase>
      <phrase>Deployment</phrase>
      <phrase>High Availability</phrase>
      <phrase>Installation</phrase>
    </meta>
    <meta xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" name="series">Produkte und Lösungen</meta>
    <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude">
      <dm:bugtracker>
        <dm:url>https://bugzilla.suse.com/enter_bug.cgi</dm:url>
        <dm:component>Documentation</dm:component>
        <dm:product>
          <dm:product condition="16.0">SUSE Linux Enterprise High Availability 16.0</dm:product>
        </dm:product>
        <dm:assignee>tahlia.richardson@suse.com</dm:assignee>
      </dm:bugtracker>
      <dm:translation>yes</dm:translation>
    </dm:docmanager>
    <abstract xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude">
      <variablelist>
        <varlistentry>
          <term>WAS?</term>
          <listitem>
            <para>
              Informationen zum Einrichten eines einfachen High Availability-Clusters mit zwei Knoten mit QDevice, festplattenlosem SBD und Software-Watchdog.
            </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>WARUM?</term>
          <listitem>
            <para>
              Dieser Cluster kann zu Testzwecken oder als anfängliche Clusterminimalkonfiguration verwendet werden, die später erweitert werden kann.
            </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>AUFWAND</term>
          <listitem>
            <para>
                Das Einrichten eines einfachen High Availability-Clusters dauert je nach Geschwindigkeit Ihrer Netzwerkverbindung etwa 15 Minuten.
              </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>ZIEL</term>
          <listitem>
            <para>
                Legen Sie schnell und einfach mit SUSE Linux Enterprise High Availability los.
              </para>
          </listitem>
        </varlistentry>
      </variablelist>
    </abstract>
  </info>
  <section role="concept" xml:lang="de" version="5.2" xml:id="ha-installing-cluster-usage-scenario">
    <info>
      <title xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">Einsatzszenario</title>
      <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
    </info>
    <para>
    Dieses Handbuch beschreibt die Einrichtung eines minimalen High Availability-Clusters mit den folgenden Eigenschaften:
  </para>
    <itemizedlist>
      <listitem>
        <para condition="twonode">
        Zwei Clusterknoten mit gegenseitigem SSH-Zugriff ohne Passwort.
      </para>
      </listitem>
      <listitem>
        <para>
        Eine virtuelle IP-Adresse nach dem Floating-IP-Prinzip, über die Clients eine Verbindung mit dem Grafikverwaltungswerkzeug Hawk herstellen können, und zwar unabhängig davon, auf welchem Knoten der Dienst ausgeführt wird.
      </para>
      </listitem>
      <listitem>
        <para>
        Festplattenloses SBD (STONITH Block Device) und ein Software-Watchdog werden als Knoten-Fencing-Mechanismus zur Vermeidung von Split Brain-Szenarien verwendet.
      </para>
      </listitem>
      <listitem condition="twonode">
        <para>
        QDevice arbeitet mit QNetd zusammen, um an Cluster-Quorum-Entscheidungen teilzunehmen. Für diese Einrichtung sind QDevice und QNetd erforderlich, damit festplattenloses SBD Split Brain-Szenarien für den Cluster mit zwei Knoten verarbeiten kann.
      </para>
      </listitem>
      <listitem>
        <para>
        Failover der Ressourcen von einem Knoten zu einem anderen, wenn der aktive Host ausfällt (<emphasis>Aktiv/Passiv</emphasis>-Einrichtung)
      </para>
      </listitem>
    </itemizedlist>
    <para>
    Dies ist eine einfache Clustereinrichtung mit minimalen externen Anforderungen. Sie können diesen Cluster zu Testzwecken oder als einfache Clusterkonfiguration verwenden, die später für eine Produktionsumgebung erweitert werden kann.
  </para>
  </section>
  <section role="glue" xml:lang="de" version="5.2" xml:id="ha-installing-cluster-overview">
    <info>
      <title xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">Installationsübersicht</title>
      <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
    </info>
    <para>
    Um den unter <xref linkend="ha-installing-cluster-usage-scenario"/> beschriebenen High Availability-Cluster zu installieren, müssen Sie die folgenden Aufgaben ausführen:
  </para>
    <orderedlist>
      <listitem>
        <para>
        Lesen Sie <xref linkend="ha-requirements"/>, um sicherzustellen, dass Sie alles haben, was Sie benötigen.
      </para>
      </listitem>
      <listitem>
        <para>
        Installieren Sie SUSE Linux Enterprise High Availability auf den Clusterknoten mit <xref linkend="ha-enabling-extension"/>.
      </para>
      </listitem>
      <listitem condition="twonode">
        <para>
        In <xref linkend="ha-qdevice-setting-up-qnetd"/> installieren Sie QNetd auf einem Nicht-Cluster-Server.
      </para>
      </listitem>
      <listitem>
        <para>
        Initialisieren Sie den Cluster auf dem ersten Knoten mit <xref linkend="ha-setting-up-first-node"/>.
      </para>
      </listitem>
      <listitem>
        <para>
        In <xref linkend="ha-adding-nodes"/> fügen Sie Ihrem Cluster weitere Knoten hinzu.
      </para>
      </listitem>
      <listitem>
        <para>
        In <xref linkend="ha-hawk-logging-in"/> melden Sie sich bei der Hawk-Weboberfläche an, um den Cluster zu überwachen.
      </para>
      </listitem>
      <listitem condition="twonode">
        <para>
        In <xref linkend="ha-qdevice-showing-quorum-status"/> überprüfen Sie den Status von QDevice und QNetd.
      </para>
      </listitem>
      <listitem>
        <para>
        In <xref linkend="ha-testing-the-cluster-basic"/> führen Sie grundlegende Tests durch, um sicherzustellen, dass der Cluster wie erwartet funktioniert.
      </para>
      </listitem>
      <listitem>
        <para>
        Lesen Sie <xref linkend="ha-installing-cluster-next-steps"/>, um Ratschläge zur Erweiterung des Clusters für eine Produktionsumgebung zu erhalten.
      </para>
      </listitem>
    </orderedlist>
  </section>
  <section role="reference" xml:lang="de" version="5.2" xml:id="ha-requirements">
    <info>
      <title xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude">Systemanforderungen</title>
      <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="" its:translate="no"/>
      <abstract xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">
        <para>
       In diesem Abschnitt werden die Systemanforderungen für eine Minimaleinrichtung von SUSE Linux Enterprise High Availability beschrieben.
      </para>
      </abstract>
    </info>
    <section xml:id="ha-requirements-hardware">
      <title>Hardwareanforderungen</title>
      <variablelist>
        <varlistentry>
          <term>Server</term>
          <listitem>
            <para condition="twonode">
            Drei Server: zwei als Clusterknoten und einer zum Ausführen von QNetd.
          </para>
            <para>
            Bei den Servern kann es sich um Bare Metal-Server oder um virtuelle Rechner handeln. Sie müssen nicht unbedingt mit identischer Hardware (Arbeitsspeicher, Festplattenspeicher usw.) ausgestattet sein, die gleiche Architektur wird jedoch vorausgesetzt. Plattformübergreifende Cluster werden nicht unterstützt.
          </para>
            <para>
            Weitere Informationen zur Serverhardware finden Sie in Abschnitt <citetitle>System Requirements</citetitle> unter <link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.suse.com/download/sle-ha/"></link>.
          </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Netzwerkschnittstellenkarten (NICs)</term>
          <listitem>
            <para>
            Mindestens zwei NICs pro Clusterknoten. Damit können Sie zwei oder mehr Kommunikationskanäle für den Cluster konfigurieren. Verwenden Sie dazu eine der folgenden Methoden:
          </para>
            <itemizedlist>
              <listitem>
                <para>
                Kombinieren Sie die NICs zu einem Netzwerk-Bonding (bevorzugt). In diesem Fall müssen Sie das Bond-Gerät auf jedem Knoten einrichten, bevor Sie den Cluster initialisieren.
              </para>
              </listitem>
              <listitem>
                <para>
                Erstellen Sie einen zweiten Kommunikationskanal in Corosync. Dies kann durch das Clustereinrichtungsskript konfiguriert werden. In diesem Fall müssen sich die beiden NICs in unterschiedlichen Teilnetzen befinden.
              </para>
              </listitem>
            </itemizedlist>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>STONITH (Knoten-Fencing)</term>
          <listitem>
            <para>
            Damit sie unterstützt werden, <emphasis>müssen</emphasis> alle SUSE Linux Enterprise High Availability-Cluster über mindestens ein Knoten-Fencing-Gerät (STONITH) verfügen, um Split Brain-Szenarien zu vermeiden. Dazu kann entweder ein physisches Gerät (ein Netzschalter) oder SBD (STONITH Block Device) in Kombination mit einem Watchdog verwendet werden. SBD kann entweder mit gemeinsam genutztem Speicher oder im festplattenlosen Modus verwendet werden.
          </para>
            <para>
            Die in diesem Handbuch beschriebene Minimaleinrichtung verwendet einen Software-Watchdog und festplattenloses SBD, sodass keine zusätzliche Hardware erforderlich ist. Ersetzen Sie den Software-Watchdog durch einen Hardware-Watchdog, bevor Sie diesen Cluster in einer Produktionsumgebung verwenden.
          </para>
          </listitem>
        </varlistentry>
      </variablelist>
    </section>
    <section xml:id="ha-requirements-software">
      <title>Software-Anforderungen</title>
      <variablelist>
        <varlistentry>
          <term>Betriebssystem</term>
          <listitem>
            <para>
            Auf allen Knoten <phrase condition="twonode">und dem QNetd-Server</phrase> muss SUSE Linux Enterprise Server installiert und registriert sein.
          </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>High Availability-Erweiterung</term>
          <listitem>
            <para>
            Für die SUSE Linux Enterprise High Availability-Erweiterung ist ein zusätzlicher Registrierungscode erforderlich.
          </para>
            <para>
            Diese Erweiterung kann während der SLES-Installation aktiviert werden. Sie können sie später auf einem ausgeführten System aktivieren. In diesem Handbuch wird erläutert, wie Sie die Erweiterung auf einem ausgeführten System aktivieren und registrieren.
          </para>
          </listitem>
        </varlistentry>
      </variablelist>
    </section>
    <section xml:id="ha-requirements-network">
      <title>Netzwerkanforderungen</title>
      <variablelist>
        <varlistentry>
          <term>Zeitsynchronisierung</term>
          <listitem>
            <para>
            Alle Systeme müssen mit einem NTP-Server außerhalb des Clusters synchronisiert werden. SUSE Linux Enterprise Server verwendet <systemitem class="resource">chrony</systemitem> für NTP. Wenn Sie den Cluster initialisieren, werden Sie gewarnt, falls <systemitem class="resource">chrony</systemitem> nicht ausgeführt wird.
          </para>
            <para>
            Selbst wenn die Knoten synchronisiert sind, können Protokolldateien und Clusterberichte schwer zu analysieren sein, falls für die Knoten unterschiedliche Zeitzonen konfiguriert wurden.
          </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Hostname und IP-Adresse</term>
          <listitem>
            <para>
            Alle Clusterknoten müssen in der Lage sein, sich<phrase condition="twonode"> und den QNetd-Server</phrase> anhand des Namens gegenseitig zu finden. Verwenden Sie die folgenden Methoden für eine zuverlässige Namensauflösung:
          </para>
            <itemizedlist>
              <listitem>
                <para>
                Verwenden Sie statische IP-Adressen.
              </para>
              </listitem>
              <listitem>
                <para>
                Listen Sie alle Knoten in der Datei <filename>/etc/hosts</filename> mit ihrer IP-Adresse, ihrem FQDN und ihrem kurzen Hostnamen auf.
              </para>
              </listitem>
            </itemizedlist>
            <para>
            Es wird nur die primäre IP-Adresse auf jeder NIC unterstützt.
          </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>SSH</term>
          <listitem>
            <para>
            Alle Clusterknoten müssen in der Lage sein, über SSH aufeinander<phrase condition="twonode"> und den QNetd-Server</phrase> zuzugreifen. Bestimmte Clustervorgänge erfordern auch eine SSH-Authentifizierung ohne Passwort. Bei der Initialisierung des Clusters prüft das Einrichtungsskript, ob SSH-Schlüssel vorhanden sind, und generiert sie, falls sie nicht vorhanden sind.
          </para>
            <important>
              <title><systemitem class="username">root</systemitem>-SSH-Zugriff in SUSE Linux Enterprise 16</title>
              <para>
              In SUSE Linux Enterprise 16 ist die <systemitem class="username">root</systemitem>-SSH-Anmeldung mit Passwort standardmäßig deaktiviert.
            </para>
              <para>
              Erstellen Sie auf jedem Knoten<phrase condition="twonode"> und auf dem QNetd-Server</phrase> entweder einen Benutzer mit <command>sudo</command>-Rechten oder richten Sie eine SSH-Authentifizierung ohne Passwort für den <systemitem class="username">root</systemitem>-Benutzer ein, bevor Sie den Cluster initialisieren.
            </para>
              <para>
              Wenn Sie den Cluster mit einem <command>sudo</command>-Benutzer initialisieren, erfordern bestimmte <systemitem>crmsh</systemitem>-Befehle auch ein <command>sudo</command>-Recht ohne Passwort.
            </para>
            </important>
          </listitem>
        </varlistentry>
        <varlistentry condition="twonode">
          <term>Separates Netzwerk für QNetd</term>
          <listitem>
            <para>
            Es wird empfohlen, dass die Clusterknoten den QNetd-Server über ein anderes Netzwerk erreichen als das, das von Corosync verwendet wird. Idealerweise sollte sich der QNetd-Server in einem vom Cluster getrennten Rack befinden oder zumindest über ein separates Netzteil verfügen und nicht im selben Netzwerksegment wie die Corosync-Kommunikationskanäle.
          </para>
          </listitem>
        </varlistentry>
      </variablelist>
    </section>
  </section>
  <section role="task" xml:lang="de" version="5.2" xml:id="ha-enabling-extension">
    <info>
      <title xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">Aktivieren der High Availability-Erweiterung</title>
      <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
      <abstract xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">
        <para>
        In diesem Verfahren wird erläutert, wie Sie SUSE Linux Enterprise High Availability auf einem vorhandenen SUSE Linux Enterprise Server installieren. Sie können dieses Verfahren überspringen, wenn Sie die High Availability-Erweiterung und die Pakete bereits während der SLES-Installation mit Agama installiert haben.
      </para>
      </abstract>
    </info>
    <itemizedlist>
      <title>Anforderungen</title>
      <listitem>
        <para>
        SUSE Linux Enterprise Server ist installiert und beim SUSE Customer Center registriert.
      </para>
      </listitem>
      <listitem>
        <para>
        Sie verfügen über einen zusätzlichen Registrierungscode für SUSE Linux Enterprise High Availability.
      </para>
      </listitem>
    </itemizedlist>
    <para>
    Führen Sie dieses Verfahren auf allen Rechnern aus, die Sie als Clusterknoten verwenden möchten:
  </para>
    <procedure>
      <step>
        <para>
        Melden Sie sich entweder als <systemitem class="username">root</systemitem>-Benutzer oder als Benutzer mit <command>sudo</command>-Rechten an.
      </para>
      </step>
      <step>
        <para>
        Überprüfen Sie, ob die High Availability-Erweiterung bereits aktiviert ist:
      </para>
        <screen>
          <prompt>&gt; </prompt>
          <command>sudo SUSEConnect --list-extensions</command>
        </screen>
      </step>
      <step>
        <para>
        Überprüfen Sie, ob die High Availability-Pakete bereits installiert sind:
      </para>
        <screen>
          <prompt>&gt; </prompt>
          <command>zypper search ha_sles</command>
        </screen>
      </step>
      <step>
        <para>
        Aktivieren der SUSE Linux Enterprise High Availability-Erweiterung:
      </para>
        <screen>
          <prompt>&gt; </prompt>
          <command>sudo SUSEConnect -p sle-ha/<phrase><phrase os="sleha">16.0</phrase></phrase>/x86_64 -r <replaceable>HA_REGCODE</replaceable></command>
        </screen>
      </step>
      <step>
        <para>
        Installieren der High Availability-Pakete:</para>
        <screen>
          <prompt>&gt; </prompt>
          <command>sudo zypper install -t pattern ha_sles</command>
        </screen>
      </step>
    </procedure>
  </section>
  <section role="task" xml:lang="de" version="5.2" xml:id="ha-qdevice-setting-up-qnetd">
    <info>
      <title xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">Einrichten des QNetd-Servers</title>
      <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
      <abstract xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">
        <para>
        QNetd ist der Vermittler, der dem auf den Clusterknoten ausgeführten QDevice-Daemon eine Stimme bereitstellt. Der QNetd-Server wird außerhalb des Clusters ausgeführt, sodass Sie keine Clusterressourcen auf diesen Server verschieben können. QNetd kann mehrere Cluster unterstützen, wenn jeder Cluster einen eindeutigen Namen hat.
      </para>
      </abstract>
    </info>
    <itemizedlist>
      <title>Anforderungen</title>
      <listitem>
        <para>
        SUSE Linux Enterprise Server ist installiert und beim SUSE Customer Center registriert.
      </para>
      </listitem>
      <listitem>
        <para>
        Sie verfügen über einen zusätzlichen Registrierungscode für SUSE Linux Enterprise High Availability.
      </para>
      </listitem>
    </itemizedlist>
    <para>
    Führen Sie dieses Verfahren auf einem Server aus, der nicht Teil des Clusters ist:
  </para>
    <procedure>
      <step>
        <para>
        Melden Sie sich entweder als <systemitem class="username">root</systemitem>-Benutzer oder als Benutzer mit <command>sudo</command>-Rechten an.
      </para>
      </step>
      <step>
        <para>
        Aktivieren der SUSE Linux Enterprise High Availability-Erweiterung:
      </para>
        <screen>
          <prompt>&gt; </prompt>
          <command>sudo SUSEConnect -p sle-ha/16.0/x86_64 -r <replaceable>HA_REGCODE</replaceable></command>
        </screen>
      </step>
      <step>
        <para>
        Installieren Sie das Paket <package>corosync-qnetd</package>:
      </para>
        <screen>
          <prompt>&gt; </prompt>
          <command>sudo zypper install corosync-qnetd</command>
        </screen>
        <para>
        Sie müssen den <systemitem>corosync-qnetd</systemitem>-Dienst nicht manuell starten. Er wird automatisch gestartet, wenn Sie QDevice auf dem Cluster konfigurieren.
      </para>
      </step>
    </procedure>
    <para>
    Der QNetd-Server ist bereit, Verbindungen von einem QDevice-Client (<systemitem>corosync-qdevice</systemitem>) anzunehmen. Die weitere Konfiguration übernimmt <systemitem>crmsh</systemitem>, wenn Sie QDevice-Clients verbinden.
  </para>
    <para>
        Standardmäßig führt der <systemitem>corosync-qnetd</systemitem>-Dienst den Daemon als <systemitem>coroqnetd</systemitem>-Benutzer in der <systemitem>coroqnetd</systemitem>-Gruppe aus. Dadurch wird vermieden, dass der Daemon als <systemitem class="username">root</systemitem> ausgeführt wird.
      </para>
  </section>
  <section role="glue" xml:lang="de" version="5.2" xml:id="ha-setting-up-first-node">
    <info>
      <title xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">Einrichtung des ersten Knotens</title>
      <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
    </info>
    <para>
    SUSE Linux Enterprise High Availability enthält Einrichtungsskripte, die die Installation eines Clusters vereinfachen. Um den Cluster auf dem ersten Knoten einzurichten, verwenden Sie das Skript <command>crm cluster init</command>.
  </para>
    <section role="reference" xml:lang="de" version="5.2" xml:id="ha-crmsh-overview-init-script">
      <info>
        <title xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">Übersicht über das <command>crm cluster init</command>-Skript</title>
        <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
        <abstract xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">
          <para>
       Der Befehl <command>crm cluster init</command> startet ein Skript, das die grundlegenden Parameter definiert, die für die Clusterkommunikation erforderlich sind, was zu einem ausgeführten Cluster mit einem Knoten führt.
      </para>
        </abstract>
      </info>
      <para>
    Das Skript prüft und konfiguriert die folgenden Komponenten:
  </para>
      <variablelist>
        <varlistentry>
          <term>NTP</term>
          <listitem>
            <para>
          Prüft, ob <systemitem class="resource">chrony</systemitem> zum Starten beim Booten konfiguriert ist. Wenn das nicht der Fall ist, wird eine Meldung angezeigt.
        </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>SSH</term>
          <listitem>
            <para>
          Erkennt SSH-Schlüssel für die Anmeldung ohne Passwort zwischen Clusterknoten.
        </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Firewall</term>
          <listitem>
            <para>
          Öffnet die Ports in der Firewall, die für die Clusterkommunikation benötigt werden.
        </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Csync2</term>
          <listitem>
            <para>
          Konfiguriert Csync2 für die Replikation der Konfigurationsdateien auf allen Knoten in einem Cluster.
        </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Corosync</term>
          <listitem>
            <para>
          Konfiguriert das Clusterkommunikationssystem.
        </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>SBD/Watchdog</term>
          <listitem>
            <para>
          Prüft, ob ein Watchdog vorhanden ist, und fragt, ob SBD als Knoten-Fencing-Mechanismus konfiguriert werden soll.
        </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Clusterverwaltung mit Hawk</term>
          <listitem>
            <para>
          Aktiviert den Hawk-Dienst und zeigt die URL für die Hawk-Weboberfläche an.
        </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Virtual Floating IP</term>
          <listitem>
            <para>
          Fragt, ob eine virtuelle IP-Adresse für die Hawk-Weboberfläche konfiguriert werden soll.
        </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>QDevice/QNetd</term>
          <listitem>
            <para>
          Fragt, ob QDevice und QNetd zur Teilnahme an Quorum-Entscheidungen konfiguriert werden sollen. Dies wird für Cluster mit einer geraden Anzahl von Knoten und insbesondere für Cluster mit zwei Knoten empfohlen.
        </para>
          </listitem>
        </varlistentry>
      </variablelist>
      <note>
        <title>Pacemaker-Standardeinstellungen</title>
        <para>
      Die vom <command>crm cluster init</command>-Skript festgelegten Optionen sind möglicherweise nicht mit den Standardeinstellungen von Pacemaker identisch. In <filename>/var/log/crmsh/crmsh.log</filename> können Sie überprüfen, welche Einstellungen das Skript geändert hat. Sämtliche Optionen, die während des Bootstrap-Prozesses festgelegt wurden, können später mit <systemitem>crmsh</systemitem> geändert werden.
    </para>
      </note>
      <note>
        <title>Clusterkonfiguration für verschiedene Plattformen</title>
        <para>
      Das <command>crm cluster init</command>-Skript erkennt die Systemumgebung (z. B. Microsoft Azure) und passt bestimmte Clustereinstellungen basierend auf dem Profil für diese Umgebung an. Weitere Informationen finden Sie in der Datei <filename>/etc/crm/profiles.yml</filename>.
    </para>
      </note>
    </section>
    <section role="task" xml:lang="de" version="5.2" xml:id="ha-initializing-cluster">
      <info>
        <title xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude">Initialisieren des Clusters auf dem ersten Knoten</title>
        <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
        <abstract xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">
          <para>
        Um den Cluster auf dem ersten Knoten einzurichten, verwenden Sie das <command>crm cluster init</command>-Skript. Das Skript fordert Sie zur Eingabe grundlegender Informationen zum Cluster auf und konfiguriert die erforderlichen Einstellungen und Dienste. Führen Sie für weitere Informationen den Befehl <command>crm cluster init --help</command> aus.
      </para>
        </abstract>
      </info>
      <itemizedlist>
        <title>Anforderungen</title>
        <listitem>
          <para>
        SUSE Linux Enterprise High Availability ist installiert und auf dem aktuellen Stand.
      </para>
        </listitem>
        <listitem>
          <para>
        Alle Knoten verfügen über mindestens zwei Netzwerkschnittstellen oder einen Netzwerk-Bond mit statischen IP-Adressen, die in der Datei <filename>/etc/hosts</filename> zusammen mit dem FQDN und dem kurzen Hostnamen des jeweiligen Knotens aufgeführt sind.
      </para>
        </listitem>
        <listitem condition="twonode">
          <para>
        Der QNetd-Server ist installiert. Wenn Sie sich beim QNetd-Server als <systemitem class="username">root</systemitem>-Benutzer anmelden, muss die SSH-Authentifizierung ohne Passwort aktiviert sein.
      </para>
        </listitem>
      </itemizedlist>
      <para>
    Führen Sie dieses Verfahren nur auf einem Knoten aus:
  </para>
      <procedure>
        <step>
          <para>
        Melden Sie sich beim ersten Knoten entweder als <systemitem class="username">root</systemitem>-Benutzer oder als Benutzer mit <command>sudo</command>-Rechten an.
      </para>
        </step>
        <step>
          <para>
        Starten Sie das <command>crm cluster init</command>-Skript:
      </para>
          <screen>
            <prompt>&gt; </prompt>
            <command>sudo crm cluster init</command>
          </screen>
          <para>
        Das Skript prüft, ob <systemitem class="resource">chrony</systemitem> ausgeführt wird, öffnet die erforderlichen Firewall-Ports, konfiguriert Csync2 und sucht nach SSH-Schlüsseln. Wenn keine SSH-Schlüssel vorhanden sind, generiert das Skript sie.
      </para>
        </step>
        <step>
          <para>
        Konfigurieren Sie Corosync für die Clusterkommunikation:
      </para>
          <substeps>
            <step>
              <para>
            Geben Sie eine IP-Adresse für den ersten Kommunikationskanal ein (<literal>ring0</literal>). Standardmäßig schlägt das Skript die Adresse der ersten verfügbaren Netzwerkschnittstelle vor. Dabei kann es sich um eine einzelne Schnittstelle oder um ein Bond-Gerät handeln. Akzeptieren Sie diese Adresse oder geben Sie eine andere ein.
          </para>
            </step>
            <step>
              <para>
            Wenn das Skript mehrere Netzwerkschnittstellen erkennt, fragt es, ob Sie einen zweiten Kommunikationskanal konfigurieren möchten (<literal>ring1</literal>). Wenn Sie den ersten Kanal mit einem Bond-Gerät konfiguriert haben, können Sie mit <literal>n</literal> ablehnen. Wenn Sie einen zweiten Kanal konfigurieren müssen, bestätigen Sie mit <literal>y</literal> und geben Sie die IP-Adresse einer anderen Netzwerkschnittstelle ein. Die beiden Schnittstellen müssen sich in unterschiedlichen Teilnetzen befinden.
          </para>
            </step>
          </substeps>
          <para>
        Das Skript konfiguriert die Standard-Firewall-Ports für die Corosync-Kommunikation.
      </para>
        </step>
        <step>
          <para>
        Wählen Sie aus, ob Sie SBD als Knoten-Fencing-Mechanismus einrichten möchten:
      </para>
          <substeps>
            <step>
              <para>
            Bestätigen Sie mit <literal>y</literal>, dass Sie SBD verwenden möchten.</para>
            </step>
            <step>
              <para>
            Wenn Sie nach einem Pfad zu einem Blockgerät gefragt werden, geben Sie <literal>none</literal> ein, um festplattenloses SBD zu konfigurieren.</para>
            </step>
          </substeps>
          <para>
        Das Skript konfiguriert SBD, einschließlich der entsprechenden Zeitüberschreitungseinstellungen. Im Gegensatz zu plattenbasiertem SBD benötigt festplattenloses SBD keine STONITH-Clusterressource.
      </para>
          <para>
        Wenn kein Hardware-Watchdog verfügbar ist, konfiguriert das Skript den Software-Watchdog <systemitem>softdog</systemitem>.
      </para>
        </step>
        <step>
          <para>
        Konfigurieren Sie eine virtuelle IP-Adresse für die Clusterverwaltung mit der Hawk-Weboberfläche:
      </para>
          <substeps>
            <step>
              <para>
            Bestätigen Sie mit <literal>y</literal>, dass Sie eine virtuelle IP-Adresse konfigurieren möchten.
          </para>
            </step>
            <step>
              <para>
            Geben Sie eine nicht verwendete IP-Adresse ein, die als Verwaltungs-IP für Hawk verwendet werden soll.
          </para>
            </step>
          </substeps>
          <para>
        Sie können auch eine Verbindung mit der virtuellen IP-Adresse herstellen, statt sich an einem einzelnen Clusterknoten bei Hawk anzumelden.
      </para>
        </step>
        <step>
          <para>
        Wählen Sie aus, ob QDevice und QNetd konfiguriert werden soll:
      </para>
          <substeps condition="twonode">
            <step>
              <para>
            Bestätigen Sie mit <literal>y</literal>, dass Sie QDevice und QNetd konfigurieren möchten.
          </para>
            </step>
            <step>
              <para>
            Geben Sie die IP-Adresse oder den Hostnamen des QNetd-Servers mit oder ohne Benutzernamen ein.
          </para>
              <itemizedlist>
                <listitem>
                  <para>
                Wenn Sie einen Nicht-<systemitem class="username">root</systemitem>-Benutzernamen einfügen, werden zur Eingabe des Kennworts aufgefordert und das Skript konfiguriert die SSH-Authentifizierung ohne Passwort vom Knoten zum QNetd-Server.
              </para>
                </listitem>
                <listitem>
                  <para>
                Wenn Sie keinen Benutzernamen auslassen, verwendet das Skript standardmäßig den <systemitem class="username">root</systemitem>-Benutzer. Daher muss die SSH-Authentifizierung ohne Passwort bereits für den Knoten konfiguriert sein, um auf den QNetd-Server zugreifen zu können.
              </para>
                </listitem>
              </itemizedlist>
              <para>
            Akzeptieren Sie für die restlichen Felder die Standardwerte:
          </para>
            </step>
            <step>
              <para>
            Übernehmen Sie den vorgeschlagenen Port (<literal>5403</literal>) oder geben Sie einen anderen ein.
          </para>
            </step>
            <step>
              <para>
            Wählen Sie den Algorithmus aus, der bestimmt, wie Stimmen vergeben werden. Der Standardwert ist <literal>ffsplit</literal>. 
          </para>
            </step>
            <step>
              <para>
            Wählen Sie die Methode aus, die verwendet werden soll, wenn ein Tie-Breaker erforderlich ist. Der Standardwert ist <literal>lowest</literal>. 
          </para>
            </step>
            <step>
              <para>
            Wählen Sie aus, ob TLS für die Client-Zertifikatüberprüfung aktiviert werden soll. Der Standardwert ist <literal>on</literal> (Versuchen Sie, eine Verbindung mit TLS herzustellen, stellen Sie jedoch eine Verbindung ohne TLS her, wenn es nicht verfügbar ist.).
          </para>
            </step>
            <step performance="optional">
              <para>
            Geben Sie Heuristikbefehle ein, um die Art und Weise zu beeinflussen, wie Stimmen ermittelt werden. Um diesen Schritt zu überspringen, lassen Sie das Feld leer.
          </para>
            </step>
          </substeps>
          <para condition="twonode">
        Das Skript konfiguriert QDevice und QNetd, einschließlich SSH-Schlüssel, Zertifizierungsstellen- und Serverzertifikaten, und den Firewall-Port. Außerdem aktiviert es die erforderlichen Dienste auf den Clusterknoten und auf dem QNetd-Server.
      </para>
        </step>
      </procedure>
      <para>
    Das Skript startet den Clusterdienst, um den Cluster online zu schalten und Hawk zu aktivieren. Die URL, die für Hawk verwendet werden muss, wird auf dem Bildschirm angezeigt. Sie können den Status des Clusters auch mit dem Befehl <command>crm status</command> überprüfen.
  </para>
      <important>
        <title>Sicheres Passwort für <systemitem>hacluster</systemitem></title>
        <para>
      Das <command>crm cluster init</command>-Skript erstellt einen Standard-Clusterbenutzer und ein Standardpasswort. Ersetzen Sie das Standardpasswort möglichst schnell durch ein sicheres Passwort:
    </para>
        <screen>
          <prompt>&gt; </prompt>
          <command>sudo passwd hacluster</command>
        </screen>
      </important>
    </section>
  </section>
  <section role="task" xml:lang="de" version="5.2" xml:id="ha-adding-nodes">
    <info>
      <title xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude">Hinzufügen des zweiten Knotens</title>
      <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
      <abstract xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">
        <para>
        Fügen Sie dem Cluster mit dem <command>crm cluster join</command>-Skript weitere Knoten hinzu. Das Skript benötigt lediglich Zugriff auf einen vorhandenen Clusterknoten. Es führt die grundlegende Einrichtung auf dem aktuellen Rechner automatisch durch. Führen Sie für weitere Informationen den Befehl <command>crm cluster join --help</command> aus.
      </para>
      </abstract>
    </info>
    <itemizedlist>
      <title>Anforderungen</title>
      <listitem>
        <para>
        SUSE Linux Enterprise High Availability ist installiert und auf dem aktuellen Stand.
      </para>
      </listitem>
      <listitem>
        <para>
        Ein bestehender Cluster wird bereits auf mindestens einem Knoten ausgeführt.
      </para>
      </listitem>
      <listitem>
        <para>
        Alle Knoten verfügen über mindestens zwei Netzwerkschnittstellen oder einen Netzwerk-Bond mit statischen IP-Adressen, die in der Datei <filename>/etc/hosts</filename> zusammen mit dem FQDN und dem kurzen Hostnamen des jeweiligen Knotens aufgeführt sind.
      </para>
      </listitem>
      <listitem>
        <para><emphasis>Wenn Sie sich als <command>sudo</command>-Benutzer anmelden:</emphasis> Auf allen Knoten<phrase condition="twonode"> und dem QNetd-Server</phrase> muss derselbe Benutzer vorhanden sein. Dieser Benutzer muss über das <command>sudo</command>-Recht ohne Passwort verfügen.
      </para>
      </listitem>
      <listitem>
        <para><emphasis>Wenn Sie sich als <systemitem class="username">root</systemitem>-Benutzer anmelden:</emphasis> Die SSH-Authentifizierung ohne Passwort muss auf allen Knoten<phrase condition="twonode"> und dem QNetd-Server</phrase> konfiguriert werden.
      </para>
      </listitem>
    </itemizedlist>
    <para>
    Führen Sie dieses Verfahren für jeden weiteren Knoten aus:
  </para>
    <procedure>
      <step>
        <para>
     Melden Sie sich bei diesem Knoten als derselbe Benutzer an, mit dem Sie den ersten Knoten eingerichtet haben.
    </para>
      </step>
      <step>
        <para>
     Starten Sie das <command>crm cluster join</command>-Skript:
    </para>
        <itemizedlist>
          <listitem>
            <para>
          Wenn Sie den ersten Knoten als <systemitem class="username">root</systemitem>-Benutzer einrichten, können Sie das Skript ohne zusätzliche Parameter starten:
        </para>
            <screen>
              <prompt role="root"># </prompt>
              <command>crm cluster join</command>
            </screen>
          </listitem>
          <listitem>
            <para>
          Wenn Sie den ersten Knoten als <command>sudo</command>-Benutzer einrichten, geben Sie für diesen Benutzer die Option <option>-c</option> an:
        </para>
            <screen>
              <prompt>&gt; </prompt>
              <command>sudo crm cluster join -c <replaceable>USER@NODE1</replaceable></command>
            </screen>
          </listitem>
        </itemizedlist>
        <para>
      Das Skript prüft, ob <systemitem class="resource">chrony</systemitem> ausgeführt wird, öffnet die erforderlichen Firewall-Ports und konfiguriert Csync2.
    </para>
      </step>
      <step>
        <para>
      Wenn Sie für den ersten Knoten noch nicht die Option <option>-c</option> angegeben haben, werden Sie zur Eingabe der IP-Adresse oder des Hostnamens aufgefordert.
    </para>
      </step>
      <step>
        <para>
      Wenn Sie die SSH-Authentifizierung ohne Passwort zwischen den Knoten nicht bereits konfiguriert haben, werden Sie aufgefordert, das <phrase condition="twonode">Passwort für den ersten Knoten</phrase> einzugeben.
      
    </para>
      </step>
      <step>
        <para>
       Konfigurieren Sie Corosync für die Clusterkommunikation:
     </para>
        <substeps>
          <step>
            <para>
           Das Skript schlägt eine IP-Adresse für <literal>ring0</literal> vor. Diese IP-Adresse muss sich in demselben Teilnetz befinden wie die IP-Adresse, die für <literal>ring0</literal> auf dem ersten Knoten verwendet wird. Ist dies nicht der Fall, geben Sie die richtige IP-Adresse ein.
         </para>
          </step>
          <step>
            <para>
           Wenn für den Cluster zwei Corosync-Kommunikationskanäle konfiguriert wurden, fordert das Skript Sie zur Eingabe einer IP-Adresse für <literal>ring1</literal> auf. Diese IP-Adresse muss sich in demselben Teilnetz befinden wie die IP-Adresse, die für <literal>ring1</literal> auf dem ersten Knoten verwendet wird.
         </para>
          </step>
        </substeps>
      </step>
    </procedure>
    <para>
    Das Skript kopiert die Clusterkonfiguration des ersten Knotens, passt die Zeitüberschreitungseinstellungen an, damit der neue Knoten berücksichtigt wird, und schaltet den neuen Knoten online.
    </para>
    <para>
    Sie können den Status des Clusters mit dem Befehl <command>crm status</command> überprüfen.
  </para>
    <important>
      <title>Sicheres Passwort für <systemitem>hacluster</systemitem></title>
      <para>
      Das <command>crm cluster join</command>-Skript erstellt einen Standard-Clusterbenutzer und ein Standardpasswort. Ersetzen Sie das Standardpasswort auf jedem Knoten möglichst schnell durch ein sicheres Passwort:
    </para>
      <screen>
        <prompt>&gt; </prompt>
        <command>sudo passwd hacluster</command>
      </screen>
    </important>
  </section>
  <section role="task" xml:lang="de" version="5.2" xml:id="ha-hawk-logging-in">
    <info>
      <title xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">Anmelden bei Hawk</title>
      <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
      <abstract xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">
        <para>
         Mit Hawk können Sie einen High Availability-Cluster über einen grafischen Webbrowser überwachen und verwalten. Sie können auch eine virtuelle IP-Adresse konfigurieren, über die Clients eine Verbindung mit Hawk herstellen können, und zwar unabhängig davon, auf welchem Knoten es ausgeführt wird.
      </para>
      </abstract>
    </info>
    <itemizedlist>
      <title>Anforderungen</title>
      <listitem>
        <para>
        Der Client-Rechner muss eine Verbindung mit den Clusterknoten herstellen können.
      </para>
      </listitem>
      <listitem>
        <para>
        Der Client-Rechner muss über einen grafischen Webbrowser mit aktiviertem JavaScript und aktivierten Cookies verfügen.
      </para>
      </listitem>
    </itemizedlist>
    <para>
    Sie können dieses Verfahren auf jedem Rechner ausführen, der eine Verbindung mit den Clusterknoten herstellen kann:
  </para>
    <procedure>
      <step>
        <para>
        Starten Sie einen Webbrowser und geben Sie folgende URL ein:
      </para>
        <screen>https://<replaceable>HAWKSERVER</replaceable>:7630/</screen>
        <para>
        Ersetzen Sie <replaceable>HAWKSERVER</replaceable> durch die IP-Adresse oder den Hostnamen eines Clusterknotens oder die virtuelle Hawk-IP-Adresse, wenn eine solche konfiguriert wurde.
      </para>
        <note>
          <title>Warnmeldung bezüglich des Zertifikats</title>
          <para>
          Wenn bei Ihrem ersten Zugriff auf die URL eine Warnmeldung hinsichtlich des Zertifikats angezeigt wird, wird ein eigensigniertes Zertifikat verwendet. Bitten Sie den Clusteroperator um die Details des Zertifikats, damit Sie es überprüfen können. Falls Sie dennoch fortfahren möchten, können Sie im Browser eine Ausnahme hinzufügen und die Warnmeldung auf diese Weise umgehen.
        </para>
        </note>
      </step>
      <step>
        <para>
        Geben Sie auf dem Hawk-Anmeldebildschirm den <guimenu>Benutzernamen</guimenu> und das <guimenu>Passwort</guimenu> des <systemitem class="username">hacluster</systemitem>-Benutzers ein.
      </para>
      </step>
      <step>
        <para>
        Klicken Sie auf <guimenu>Anmelden</guimenu>. Die Hawk-Weboberfläche zeigt standardmäßig den Bildschirm <guimenu>Status</guimenu> an:
      </para>
      </step>
    </procedure>
    <figure xml:id="fig-ha-hawk-status">
      <title>Der Hawk-Bildschirm „Status“</title>
      <mediaobject>
        <imageobject role="fo">
          <imagedata fileref="ha-hawk-status.png" width="100%"/>
        </imageobject>
        <imageobject role="html">
          <imagedata fileref="ha-hawk-status.png" width="100%"/>
        </imageobject>
        <textobject role="description">
          <phrase>Der Bildschirm „Status“ zeigt eine konfigurierte Ressource an: die virtuelle IP-Adresse <literal>admin-ip</literal>, die auf einem Knoten mit dem Namen <literal>alice</literal> ausgeführt wird.</phrase>
        </textobject>
      </mediaobject>
    </figure>
  </section>
  <section role="task" xml:lang="de" version="5.2" xml:id="ha-qdevice-showing-quorum-status">
    <info>
      <title xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">Anzeigen des Quorum-Status</title>
      <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
      <abstract xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">
        <para>
       Sie können den Status von QDevice und QNetd von jedem Knoten im Cluster aus überprüfen. Diese Beispiele zeigen einen Cluster mit zwei Knoten – <systemitem>alice</systemitem> und <systemitem>bob</systemitem>.
      </para>
      </abstract>
    </info>
    <example xml:id="ex-qdevice-status">
      <title>Anzeigen des Status von QDevice</title>
      <screen><prompt>&gt; </prompt><command>sudo crm corosync status quorum</command>
1 alice member
2 bob member

Quorum information
------------------
Date:             [...]
Quorum provider:  corosync_votequorum
Nodes:            2
Node ID:          2
Ring ID:          1.e
Quorate:          Yes

Votequorum information
----------------------
Expected votes:   3
Highest expected: 3
Total votes:      3
Quorum:           2
Flags:            Quorate Qdevice

Membership information
----------------------
    Nodeid      Votes    Qdevice Name
         1          1    A,V,NMW alice
         2          1    A,V,NMW bob (local)
         0          1            Qdevice</screen>
    </example>
    <para>
    In Abschnitt <literal>Membership information</literal> werden die folgenden Statuscodes angezeigt:
  </para>
    <variablelist>
      <varlistentry>
        <term><literal>A</literal> (für „Alive“ – aktiv) oder <literal>NA</literal> (für „Not Alive“ – nicht aktiv)</term>
        <listitem>
          <para>
          Zeigt den Verbindungsstatus zwischen QDevice und Corosync an.
        </para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term><literal>V</literal> (für „Vote“ – Stimme) oder <literal>NV</literal> (für „Non Vote“ – keine Stimme)</term>
        <listitem>
          <para>
          Zeigt an, ob der Knoten eine Stimme hat. <literal>V</literal> bedeutet, dass beide Knoten miteinander kommunizieren können. In einem Split Brain-Szenario wäre ein Knoten auf <literal>V</literal> und der andere Knoten auf <literal>NV</literal> festgelegt.
        </para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term><literal>MW</literal> (für „Master Wins“ – Meister gewinnt) oder <literal>NMW</literal> (für „Not Master Wins“ – Nicht-Meister gewinnt)</term>
        <listitem>
          <para>
          Zeigt an, ob das Flag <parameter>master_wins</parameter> festgelegt wurde. Standardmäßig ist das Flag nicht festgelegt, der Status ist also <literal>NMW</literal>.
        </para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term><literal>NR</literal> (für „Not Registered“ – nicht registriert)</term>
        <listitem>
          <para>
          Zeigt an, dass der Cluster kein Quorum-Gerät verwendet.
        </para>
        </listitem>
      </varlistentry>
    </variablelist>
    <example xml:id="ex-qnetd-status">
      <title>Anzeigen des Status von QNetd</title>
      <screen><prompt>&gt; </prompt><command>sudo crm corosync status qnetd</command>
1 alice member
2 bob member

Cluster "hacluster":
    Algorithm:          Fifty-Fifty split (KAP Tie-breaker)
    Tie-breaker:        Node with lowest node ID
    Node ID 1:
        Client address:         ::ffff:192.168.122.185:45676
        HB interval:            8000ms
        Configured node list:   1, 2
        Ring ID:                1.e
        Membership node list:   1, 2
        Heuristics:             Undefined (membership: Undefined, regular: Undefined)
        TLS active:             Yes (client certificate verified)
        Vote:                   ACK (ACK)
    Node ID 2:
        Client address:         ::ffff:192.168.100.168:55034
        HB interval:            8000ms
        Configured node list:   1, 2
        Ring ID:                1.e
        Membership node list:   1, 2
        Heuristics:             Undefined (membership: Undefined, regular: Undefined)
        TLS active:             Yes (client certificate verified)
        Vote:                   No change (ACK)</screen>
    </example>
  </section>
  <section role="glue" xml:lang="de" version="5.2" xml:id="ha-testing-the-cluster-basic">
    <info>
      <title xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">Testen des Clusters</title>
      <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
    </info>
    <para>
    Mit den folgenden Tests können Sie grundlegende Probleme bei der Einrichtung des Clusters feststellen. Realistische Tests beinhaltet jedoch spezifische Anwendungsfälle und Szenarien. Bevor Sie den Cluster in einer Produktionsumgebung einsetzen, müssen Sie ihn anhand Ihrer Anwendungsfälle gründlich testen.
  </para>
    <section role="task" xml:lang="de" version="5.2" xml:id="ha-testing-resource-failover">
      <info>
        <title xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">Testen des Ressourcen-Failovers</title>
        <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
        <abstract xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">
          <para>
        Überprüfen Sie, ob der Cluster Ressourcen auf einen anderen Knoten verschiebt, wenn der aktuelle Knoten auf <literal>standby</literal> festgelegt ist. Dieses Verfahren verwendet Beispielknoten mit den Namen <systemitem>alice</systemitem> und <systemitem>bob</systemitem> sowie eine virtuelle IP-Ressource mit dem Namen <literal>admin-ip</literal> und der Beispiel-IP-Adresse <literal>192.168.1.10</literal>.
      </para>
        </abstract>
      </info>
      <procedure>
        <step>
          <para>
        Öffnen Sie zwei Terminals.
      </para>
        </step>
        <step>
          <para>
        Pingen Sie auf dem ersten Terminal die virtuelle IP-Adresse an:
      </para>
          <screen>
            <prompt>&gt; </prompt>
            <command>ping 192.168.1.10</command>
          </screen>
        </step>
        <step>
          <para>
        Melden Sie sich auf dem zweiten Terminal bei einem der Clusterknoten an.
      </para>
        </step>
        <step>
          <para>
        Überprüfen Sie, auf welchem Knoten die virtuelle IP-Adresse ausgeführt wird:
      </para>
          <screen><prompt>&gt; </prompt><command>sudo crm status</command>
[..]
Node List:
  * Online: [ alice bob ]

Full List of Resources:
  * admin-ip  (ocf:heartbeat:IPaddr2):    Started alice</screen>
        </step>
        <step>
          <para>
        Versetzen Sie <systemitem>alice</systemitem> in den Standby-Modus:
      </para>
          <screen>
            <prompt>&gt; </prompt>
            <command>sudo crm node standby alice</command>
          </screen>
        </step>
        <step>
          <para>
        Überprüfen Sie den Clusterstatus erneut. Die Ressource <literal>admin-ip</literal> sollte zu <systemitem>bob</systemitem> migriert sein:
      </para>
          <screen><prompt>&gt; </prompt><command>sudo crm status</command>
[...]
Node List:
  * Node alice: standby
  * Online: [ bob ]

Full List of Resources:
  * admin-ip  (ocf:heartbeat:IPaddr2):    Started bob</screen>
        </step>
        <step>
          <para>
        Auf dem ersten Terminal sollte während der Migration ein ununterbrochener Fluss an Ping-Signalen an die virtuelle IP-Adresse zu beobachten sein. Dies zeigt, dass die Clustereinrichtung und die Floating-IP-Adresse ordnungsgemäß funktionieren.
      </para>
        </step>
        <step>
          <para>
        Brechen Sie den Befehl <command>ping</command> mit <keycombo><keycap function="control"></keycap><keycap>C</keycap></keycombo> ab.
      </para>
        </step>
        <step>
          <para>
        Schalten Sie auf dem zweiten Terminal <systemitem>alice</systemitem> wieder online:
      </para>
          <screen>
            <prompt>&gt; </prompt>
            <command>sudo crm node online alice</command>
          </screen>
        </step>
      </procedure>
    </section>
    <section role="task" xml:lang="de" version="5.2" xml:id="ha-testing-cluster-failures">
      <info>
        <title xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">Testen von Clusterausfällen</title>
        <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
        <abstract xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">
          <para>
        Der Befehl <command>crm cluster crash_test</command> simuliert Clusterausfälle und meldet die Ergebnisse.
      </para>
        </abstract>
      </info>
      <para>
    Das Kommando unterstützt folgende Prüfungen:
  </para>
      <variablelist>
        <varlistentry>
          <term>
            <option>--split-brain-iptables</option>
          </term>
          <listitem>
            <para>
          Simuliert ein Split Brain-Szenario, indem es den Corosync-Port blockiert, und überprüft, ob ein Knoten wie erwartet umgrenzt werden kann. Sie müssen <package>iptables</package> installieren, bevor Sie diesen Test ausführen können.
        </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term><option>--kill-sbd</option>/<option>--kill-corosync</option>/ <option>--kill-pacemakerd</option></term>
          <listitem>
            <para>
          Beendet die Daemons für SBD, Corosync oder Pacemaker. Nachdem Sie einen dieser Tests ausgeführt haben, finden Sie einen Bericht im Verzeichnis <filename>/var/lib/crmsh/crash_test/</filename>. Der Bericht enthält eine Testfallbeschreibung, eine Vorgangsprotokollierung und eine Erläuterung möglicher Ergebnisse.
        </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>
            <option>--fence-node <replaceable>NODE</replaceable></option>
          </term>
          <listitem>
            <para>
          Umgrenzt einen spezifischen Knoten, der von der Kommandozeile aus weitergeleitet wurde.
        </para>
          </listitem>
        </varlistentry>
      </variablelist>
      <para>
    Führen Sie für weitere Informationen den Befehl <command>crm cluster crash_test --help</command> aus.
  </para>
      <para>
    Im folgenden Beispiel werden Knoten mit den Namen <systemitem>alice</systemitem> und <systemitem>bob</systemitem> verwendet und das Fencing von <systemitem>bob</systemitem> wird getestet. Um den Änderungsstatus für <systemitem>bob</systemitem> während des Tests zu beobachten, können Sie sich bei Hawk anmelden und zu <menuchoice><guimenu>Status</guimenu><guimenu>Knoten</guimenu></menuchoice> navigieren.
  </para>
      <example>
        <title>Testen des Clusters: Knoten-Fencing</title>
        <screen><prompt>&gt; </prompt><command>sudo crm status</command>
[...]
Node List:
  * Online: [ alice bob ]

Active Resources:
  * admin-ip     (ocf:heartbeat:IPaddr2):    Started alice

<prompt>&gt; </prompt><command>sudo crm cluster crash_test --fence-node bob</command>

==============================================
Testcase:          Fence node bob
Fence action:      reboot
Fence timeout:     95

!!! WARNING WARNING WARNING !!!
THIS CASE MAY LEAD TO NODE BE FENCED.
TYPE Yes TO CONTINUE, OTHER INPUTS WILL CANCEL THIS CASE [Yes/No](No): <command>Yes</command>
INFO: Trying to fence node "bob"
INFO: Waiting 71s for node "bob" reboot...
INFO: Node "bob" will be fenced by "alice"!
INFO: Node "bob" was successfully fenced by "alice"</screen>
      </example>
    </section>
  </section>
  <section role="glue" xml:lang="de" version="5.2" xml:id="ha-installing-cluster-next-steps">
    <info>
      <title xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">Nächste Schritte</title>
      <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
    </info>
    <para>
    Dieses Handbuch beschreibt einen einfachen High Availability-Cluster, der zu Testzwecken verwendet werden kann. Um diesen Cluster für die Verwendung in Produktionsumgebungen zu erweitern, werden weitere Schritte empfohlen:
  </para>
    <variablelist>
      <varlistentry>
        <term>Hinzufügen weiterer Knoten</term>
        <listitem>
          <para>
          Fügen Sie dem Cluster mit dem <command>crm cluster join</command>-Skript weitere Knoten hinzu.
        </para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term>Aktivieren eines Hardware-Watchdog</term>
        <listitem>
          <para>
          Ersetzen Sie <systemitem>softdog</systemitem> durch einen Hardware-Watchdog, bevor Sie den Cluster in einer Produktionsumgebung verwenden.
        </para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term>Hinzufügen weiterer STONITH-Geräte</term>
        <listitem>
          <para>
          Für kritische Workloads werden dringend zwei oder drei STONITH-Geräte empfohlen, wobei entweder physische STONITH-Geräte oder festplattenbasiertes SBD verwendet werden.
        </para>
        </listitem>
      </varlistentry>
    </variablelist>
  </section>
  <section version="5.2" xml:id="legal-disclaimer">
    <info>
      <title xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink">Rechtliche Hinweise</title>
    </info>
    <para> Copyright © 2006–<?dbtimestamp format="Y"?>, SUSE LLC und Mitwirkende. Alle Rechte vorbehalten. </para>
    <para>
    Es wird die Genehmigung erteilt, dieses Dokument unter den Bedingungen der GNU Free Documentation License, Version 1.2 oder (optional) Version 1.3 zu vervielfältigen, zu verbreiten und/oder zu verändern; die unveränderlichen Abschnitte hierbei sind der Urheberrechtshinweis und die Lizenzbedingungen. Eine Kopie dieser Lizenz (Version 1.2) finden Sie in Abschnitt <quote>GNU Free Documentation License</quote>.
  </para>
    <para>
    Die SUSE Marken finden Sie in <link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.suse.com/company/legal/"></link>. Alle anderen Marken von Drittanbietern sind Besitz ihrer jeweiligen Eigentümer. Markensymbole (®, ™ usw.) kennzeichnen Marken von SUSE und ihren Tochtergesellschaften. Sternchen (*) kennzeichnen Marken von Drittanbietern.
  </para>
    <para>
    Alle Informationen in diesem Buch wurden mit größter Sorgfalt zusammengestellt. Auch hierdurch kann jedoch keine hundertprozentige Richtigkeit gewährleistet werden. Weder SUSE LLC noch ihre Tochtergesellschaften noch die Autoren noch die Übersetzer können für mögliche Fehler und deren Folgen haftbar gemacht werden.
  </para>
  </section>
  <appendix xmlns:its="http://www.w3.org/2005/11/its" version="5.2" role="legal" its:translate="no" xml:id="doc-gfdl-license">
    <info>
      <title xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink">GNU Free Documentation License</title>
    </info>
    <para>
  Copyright (C) 2000, 2001, 2002 Free Software Foundation, Inc. 51 Franklin St,
  Fifth Floor, Boston, MA 02110-1301 USA. Everyone is permitted to copy and
  distribute verbatim copies of this license document, but changing it is not
  allowed.
 </para>
    <bridgehead renderas="sect4">
    0. PREAMBLE
  </bridgehead>
    <para>
  The purpose of this License is to make a manual, textbook, or other
  functional and useful document "free" in the sense of freedom: to assure
  everyone the effective freedom to copy and redistribute it, with or without
  modifying it, either commercially or non-commercially. Secondarily, this
  License preserves for the author and publisher a way to get credit for their
  work, while not being considered responsible for modifications made by
  others.
 </para>
    <para>
  This License is a kind of "copyleft", which means that derivative works of
  the document must themselves be free in the same sense. It complements the
  GNU General Public License, which is a copyleft license designed for free
  software.
 </para>
    <para>
  We have designed this License to use it for manuals for free software,
  because free software needs free documentation: a free program should come
  with manuals providing the same freedoms that the software does. But this
  License is not limited to software manuals; it can be used for any textual
  work, regardless of subject matter or whether it is published as a printed
  book. We recommend this License principally for works whose purpose is
  instruction or reference.
 </para>
    <bridgehead renderas="sect4">
    1. APPLICABILITY AND DEFINITIONS
  </bridgehead>
    <para>
  This License applies to any manual or other work, in any medium, that
  contains a notice placed by the copyright holder saying it can be distributed
  under the terms of this License. Such a notice grants a world-wide,
  royalty-free license, unlimited in duration, to use that work under the
  conditions stated herein. The "Document", below, refers to any such manual or
  work. Any member of the public is a licensee, and is addressed as "you". You
  accept the license if you copy, modify or distribute the work in a way
  requiring permission under copyright law.
 </para>
    <para>
  A "Modified Version" of the Document means any work containing the Document
  or a portion of it, either copied verbatim, or with modifications and/or
  translated into another language.
 </para>
    <para>
  A "Secondary Section" is a named appendix or a front-matter section of the
  Document that deals exclusively with the relationship of the publishers or
  authors of the Document to the Document's overall subject (or to related
  matters) and contains nothing that could fall directly within that overall
  subject. (Thus, if the Document is in part a textbook of mathematics, a
  Secondary Section may not explain any mathematics.) The relationship could be
  a matter of historical connection with the subject or with related matters,
  or of legal, commercial, philosophical, ethical or political position
  regarding them.
 </para>
    <para>
  The "Invariant Sections" are certain Secondary Sections whose titles are
  designated, as being those of Invariant Sections, in the notice that says
  that the Document is released under this License. If a section does not fit
  the above definition of Secondary then it is not allowed to be designated as
  Invariant. The Document may contain zero Invariant Sections. If the Document
  does not identify any Invariant Sections then there are none.
 </para>
    <para>
  The "Cover Texts" are certain short passages of text that are listed, as
  Front-Cover Texts or Back-Cover Texts, in the notice that says that the
  Document is released under this License. A Front-Cover Text may be at most 5
  words, and a Back-Cover Text may be at most 25 words.
 </para>
    <para>
  A "Transparent" copy of the Document means a machine-readable copy,
  represented in a format whose specification is available to the general
  public, that is suitable for revising the document straightforwardly with
  generic text editors or (for images composed of pixels) generic paint
  programs or (for drawings) some widely available drawing editor, and that is
  suitable for input to text formatters or for automatic translation to a
  variety of formats suitable for input to text formatters. A copy made in an
  otherwise Transparent file format whose markup, or absence of markup, has
  been arranged to thwart or discourage subsequent modification by readers is
  not Transparent. An image format is not Transparent if used for any
  substantial amount of text. A copy that is not "Transparent" is called
  "Opaque".
 </para>
    <para>
  Examples of suitable formats for Transparent copies include plain ASCII
  without markup, Texinfo input format, LaTeX input format, SGML or XML using a
  publicly available DTD, and standard-conforming simple HTML, PostScript or
  PDF designed for human modification. Examples of transparent image formats
  include PNG, XCF and JPG. Opaque formats include proprietary formats that can
  be read and edited only by proprietary word processors, SGML or XML for which
  the DTD and/or processing tools are not generally available, and the
  machine-generated HTML, PostScript or PDF produced by some word processors
  for output purposes only.
 </para>
    <para>
  The "Title Page" means, for a printed book, the title page itself, plus such
  following pages as are needed to hold, legibly, the material this License
  requires to appear in the title page. For works in formats which do not have
  any title page as such, "Title Page" means the text near the most prominent
  appearance of the work's title, preceding the beginning of the body of the
  text.
 </para>
    <para>
  A section "Entitled XYZ" means a named subunit of the Document whose title
  either is precisely XYZ or contains XYZ in parentheses following text that
  translates XYZ in another language. (Here XYZ stands for a specific section
  name mentioned below, such as "Acknowledgements", "Dedications",
  "Endorsements", or "History".) To "Preserve the Title" of such a section when
  you modify the Document means that it remains a section "Entitled XYZ"
  according to this definition.
 </para>
    <para>
  The Document may include Warranty Disclaimers next to the notice which states
  that this License applies to the Document. These Warranty Disclaimers are
  considered to be included by reference in this License, but only as regards
  disclaiming warranties: any other implication that these Warranty Disclaimers
  may have is void and has no effect on the meaning of this License.
 </para>
    <bridgehead renderas="sect4">
    2. VERBATIM COPYING
  </bridgehead>
    <para>
  You may copy and distribute the Document in any medium, either commercially
  or non-commercially, provided that this License, the copyright notices, and
  the license notice saying this License applies to the Document are reproduced
  in all copies, and that you add no other conditions whatsoever to those of
  this License. You may not use technical measures to obstruct or control the
  reading or further copying of the copies you make or distribute. However, you
  may accept compensation in exchange for copies. If you distribute a large
  enough number of copies you must also follow the conditions in section 3.
 </para>
    <para>
  You may also lend copies, under the same conditions stated above, and you may
  publicly display copies.
 </para>
    <bridgehead renderas="sect4">
    3. COPYING IN QUANTITY
  </bridgehead>
    <para>
  If you publish printed copies (or copies in media that commonly have printed
  covers) of the Document, numbering more than 100, and the Document's license
  notice requires Cover Texts, you must enclose the copies in covers that
  carry, clearly and legibly, all these Cover Texts: Front-Cover Texts on the
  front cover, and Back-Cover Texts on the back cover. Both covers must also
  clearly and legibly identify you as the publisher of these copies. The front
  cover must present the full title with all words of the title equally
  prominent and visible. You may add other material on the covers in addition.
  Copying with changes limited to the covers, as long as they preserve the
  title of the Document and satisfy these conditions, can be treated as
  verbatim copying in other respects.
 </para>
    <para>
  If the required texts for either cover are too voluminous to fit legibly, you
  should put the first ones listed (as many as fit reasonably) on the actual
  cover, and continue the rest onto adjacent pages.
 </para>
    <para>
  If you publish or distribute Opaque copies of the Document numbering more
  than 100, you must either include a machine-readable Transparent copy along
  with each Opaque copy, or state in or with each Opaque copy a
  computer-network location from which the general network-using public has
  access to download using public-standard network protocols a complete
  Transparent copy of the Document, free of added material. If you use the
  latter option, you must take reasonably prudent steps, when you begin
  distribution of Opaque copies in quantity, to ensure that this Transparent
  copy will remain thus accessible at the stated location until at least one
  year after the last time you distribute an Opaque copy (directly or through
  your agents or retailers) of that edition to the public.
 </para>
    <para>
  It is requested, but not required, that you contact the authors of the
  Document well before redistributing any large number of copies, to give them
  a chance to provide you with an updated version of the Document.
 </para>
    <bridgehead renderas="sect4">
    4. MODIFICATIONS
  </bridgehead>
    <para>
  You may copy and distribute a Modified Version of the Document under the
  conditions of sections 2 and 3 above, provided that you release the Modified
  Version under precisely this License, with the Modified Version filling the
  role of the Document, thus licensing distribution and modification of the
  Modified Version to whoever possesses a copy of it. In addition, you must do
  these things in the Modified Version:
 </para>
    <orderedlist numeration="upperalpha" spacing="normal">
      <listitem>
        <para>
    Use in the Title Page (and on the covers, if any) a title distinct from
    that of the Document, and from those of previous versions (which should, if
    there were any, be listed in the History section of the Document). You may
    use the same title as a previous version if the original publisher of that
    version gives permission.
   </para>
      </listitem>
      <listitem>
        <para>
    List on the Title Page, as authors, one or more persons or entities
    responsible for authorship of the modifications in the Modified Version,
    together with at least five of the principal authors of the Document (all
    of its principal authors, if it has fewer than five), unless they release
    you from this requirement.
   </para>
      </listitem>
      <listitem>
        <para>
    State on the Title page the name of the publisher of the Modified Version,
    as the publisher.
   </para>
      </listitem>
      <listitem>
        <para>
    Preserve all the copyright notices of the Document.
   </para>
      </listitem>
      <listitem>
        <para>
    Add an appropriate copyright notice for your modifications adjacent to the
    other copyright notices.
   </para>
      </listitem>
      <listitem>
        <para>
    Include, immediately after the copyright notices, a license notice giving
    the public permission to use the Modified Version under the terms of this
    License, in the form shown in the Addendum below.
   </para>
      </listitem>
      <listitem>
        <para>
    Preserve in that license notice the full lists of Invariant Sections and
    required Cover Texts given in the Document's license notice.
   </para>
      </listitem>
      <listitem>
        <para>
    Include an unaltered copy of this License.
   </para>
      </listitem>
      <listitem>
        <para>
    Preserve the section Entitled "History", Preserve its Title, and add to it
    an item stating at least the title, year, new authors, and publisher of the
    Modified Version as given on the Title Page. If there is no section
    Entitled "History" in the Document, create one stating the title, year,
    authors, and publisher of the Document as given on its Title Page, then add
    an item describing the Modified Version as stated in the previous sentence.
   </para>
      </listitem>
      <listitem>
        <para>
    Preserve the network location, if any, given in the Document for public
    access to a Transparent copy of the Document, and likewise the network
    locations given in the Document for previous versions it was based on.
    These may be placed in the "History" section. You may omit a network
    location for a work that was published at least four years before the
    Document itself, or if the original publisher of the version it refers to
    gives permission.
   </para>
      </listitem>
      <listitem>
        <para>
    For any section Entitled "Acknowledgements" or "Dedications", Preserve the
    Title of the section, and preserve in the section all the substance and
    tone of each of the contributor acknowledgements and/or dedications given
    therein.
   </para>
      </listitem>
      <listitem>
        <para>
    Preserve all the Invariant Sections of the Document, unaltered in their
    text and in their titles. Section numbers or the equivalent are not
    considered part of the section titles.
   </para>
      </listitem>
      <listitem>
        <para>
    Delete any section Entitled "Endorsements". Such a section may not be
    included in the Modified Version.
   </para>
      </listitem>
      <listitem>
        <para>
    Do not retitle any existing section to be Entitled "Endorsements" or to
    conflict in title with any Invariant Section.
   </para>
      </listitem>
      <listitem>
        <para>
    Preserve any Warranty Disclaimers.
   </para>
      </listitem>
    </orderedlist>
    <para>
  If the Modified Version includes new front-matter sections or appendices that
  qualify as Secondary Sections and contain no material copied from the
  Document, you may at your option designate some or all of these sections as
  invariant. To do this, add their titles to the list of Invariant Sections in
  the Modified Version's license notice. These titles must be distinct from any
  other section titles.
 </para>
    <para>
  You may add a section Entitled "Endorsements", provided it contains nothing
  but endorsements of your Modified Version by various parties--for example,
  statements of peer review or that the text has been approved by an
  organization as the authoritative definition of a standard.
 </para>
    <para>
  You may add a passage of up to five words as a Front-Cover Text, and a
  passage of up to 25 words as a Back-Cover Text, to the end of the list of
  Cover Texts in the Modified Version. Only one passage of Front-Cover Text and
  one of Back-Cover Text may be added by (or through arrangements made by) any
  one entity. If the Document already includes a cover text for the same cover,
  previously added by you or by arrangement made by the same entity you are
  acting on behalf of, you may not add another; but you may replace the old
  one, on explicit permission from the previous publisher that added the old
  one.
 </para>
    <para>
  The author(s) and publisher(s) of the Document do not by this License give
  permission to use their names for publicity for or to assert or imply
  endorsement of any Modified Version.
 </para>
    <bridgehead renderas="sect4">
    5. COMBINING DOCUMENTS
  </bridgehead>
    <para>
  You may combine the Document with other documents released under this
  License, under the terms defined in section 4 above for modified versions,
  provided that you include in the combination all of the Invariant Sections of
  all of the original documents, unmodified, and list them all as Invariant
  Sections of your combined work in its license notice, and that you preserve
  all their Warranty Disclaimers.
 </para>
    <para>
  The combined work need only contain one copy of this License, and multiple
  identical Invariant Sections may be replaced with a single copy. If there are
  multiple Invariant Sections with the same name but different contents, make
  the title of each such section unique by adding at the end of it, in
  parentheses, the name of the original author or publisher of that section if
  known, or else a unique number. Make the same adjustment to the section
  titles in the list of Invariant Sections in the license notice of the
  combined work.
 </para>
    <para>
  In the combination, you must combine any sections Entitled "History" in the
  various original documents, forming one section Entitled "History"; likewise
  combine any sections Entitled "Acknowledgements", and any sections Entitled
  "Dedications". You must delete all sections Entitled "Endorsements".
 </para>
    <bridgehead renderas="sect4">
    6. COLLECTIONS OF DOCUMENTS
  </bridgehead>
    <para>
  You may make a collection consisting of the Document and other documents
  released under this License, and replace the individual copies of this
  License in the various documents with a single copy that is included in the
  collection, provided that you follow the rules of this License for verbatim
  copying of each of the documents in all other respects.
 </para>
    <para>
  You may extract a single document from such a collection, and distribute it
  individually under this License, provided you insert a copy of this License
  into the extracted document, and follow this License in all other respects
  regarding verbatim copying of that document.
 </para>
    <bridgehead renderas="sect4">
    7. AGGREGATION WITH INDEPENDENT WORKS
  </bridgehead>
    <para>
  A compilation of the Document or its derivatives with other separate and
  independent documents or works, in or on a volume of a storage or
  distribution medium, is called an "aggregate" if the copyright resulting from
  the compilation is not used to limit the legal rights of the compilation's
  users beyond what the individual works permit. When the Document is included
  in an aggregate, this License does not apply to the other works in the
  aggregate which are not themselves derivative works of the Document.
 </para>
    <para>
  If the Cover Text requirement of section 3 is applicable to these copies of
  the Document, then if the Document is less than one half of the entire
  aggregate, the Document's Cover Texts may be placed on covers that bracket
  the Document within the aggregate, or the electronic equivalent of covers if
  the Document is in electronic form. Otherwise they must appear on printed
  covers that bracket the whole aggregate.
 </para>
    <bridgehead renderas="sect4">
    8. TRANSLATION
  </bridgehead>
    <para>
  Translation is considered a kind of modification, so you may distribute
  translations of the Document under the terms of section 4. Replacing
  Invariant Sections with translations requires special permission from their
  copyright holders, but you may include translations of some or all Invariant
  Sections in addition to the original versions of these Invariant Sections.
  You may include a translation of this License, and all the license notices in
  the Document, and any Warranty Disclaimers, provided that you also include
  the original English version of this License and the original versions of
  those notices and disclaimers. In case of a disagreement between the
  translation and the original version of this License or a notice or
  disclaimer, the original version will prevail.
 </para>
    <para>
  If a section in the Document is Entitled "Acknowledgements", "Dedications",
  or "History", the requirement (section 4) to Preserve its Title (section 1)
  will typically require changing the actual title.
 </para>
    <bridgehead renderas="sect4">
    9. TERMINATION
  </bridgehead>
    <para>
  You may not copy, modify, sublicense, or distribute the Document except as
  expressly provided for under this License. Any other attempt to copy, modify,
  sublicense or distribute the Document is void, and will automatically
  terminate your rights under this License. However, parties who have received
  copies, or rights, from you under this License will not have their licenses
  terminated so long as such parties remain in full compliance.
 </para>
    <bridgehead renderas="sect4">
    10. FUTURE REVISIONS OF THIS LICENSE
  </bridgehead>
    <para>
  The Free Software Foundation may publish new, revised versions of the GNU
  Free Documentation License from time to time. Such new versions will be
  similar in spirit to the present version, but may differ in detail to address
  new problems or concerns. See
  <link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.gnu.org/copyleft/"></link>.
 </para>
    <para>
  Each version of the License is given a distinguishing version number. If the
  Document specifies that a particular numbered version of this License "or any
  later version" applies to it, you have the option of following the terms and
  conditions either of that specified version or of any later version that has
  been published (not as a draft) by the Free Software Foundation. If the
  Document does not specify a version number of this License, you may choose
  any version ever published (not as a draft) by the Free Software Foundation.
 </para>
    <bridgehead renderas="sect4">
    ADDENDUM: How to use this License for your documents
  </bridgehead>
    <screen>Copyright (c) YEAR YOUR NAME.
Permission is granted to copy, distribute and/or modify this document
under the terms of the GNU Free Documentation License, Version 1.2
or any later version published by the Free Software Foundation;
with no Invariant Sections, no Front-Cover Texts, and no Back-Cover Texts.
A copy of the license is included in the section entitled “GNU
Free Documentation License”.</screen>
    <para>
  If you have Invariant Sections, Front-Cover Texts and Back-Cover Texts,
  replace the &#x201C;with...Texts.&#x201D; line with this:
 </para>
    <screen>with the Invariant Sections being LIST THEIR TITLES, with the
Front-Cover Texts being LIST, and with the Back-Cover Texts being LIST.</screen>
    <para>
  If you have Invariant Sections without Cover Texts, or some other combination
  of the three, merge those two alternatives to suit the situation.
 </para>
    <para>
  If your document contains nontrivial examples of program code, we recommend
  releasing these examples in parallel under your choice of free software
  license, such as the GNU General Public License, to permit their use in free
  software.
</para>
  </appendix>
  <glossary role="reference" xml:lang="de" version="5.2" xml:id="ha-glossary">
    <info>
      <title xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">Hochverfügbarkeit – Glossar</title>
      <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
    </info>
    <glossentry>
      <glossterm>aktiv/aktiv, aktiv/passiv</glossterm>
      <glossdef>
        <para>
      Wie die Ressourcen auf den Knoten ausgeführt werden. „Aktiv/passiv“ bedeutet, dass die Ressourcen nur auf dem aktiven Knoten ausgeführt werden, aber auf den passiven Knoten verschoben werden können, wenn der aktive Knoten ausfällt. „Aktiv/aktiv“ bedeutet, dass alle Knoten gleichzeitig aktiv sind und Ressourcen auf jedem Knoten des Clusters ausgeführt werden (und dorthin verschoben werden) können.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-arbitrator">
      <glossterm>Vermittler</glossterm>
      <glossdef>
        <para>
      Ein <emphasis>Vermittler</emphasis> ist ein Rechner, der außerhalb des Clusters ausgeführt wird und eine zusätzliche Instanz für Clusterberechnungen bereitstellt. Zum Beispiel bietet <xref linkend="gloss-qnetd"/> eine Stimme an, damit sich <xref linkend="gloss-qdevice"/> an <xref linkend="gloss-quorum"/>-Entscheidungen beteiligen kann.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Cluster-Informationsdatenbank (CIB, Cluster Information Base):</glossterm>
      <glossdef>
        <para>
      Eine XML-Darstellung der gesamten Clusterkonfiguration und des Clusterstatus (Clusteroptionen, -knoten, -ressourcen, -einschränkungen und die Beziehungen zueinander). Der CIB-Manager (<systemitem>pacemaker-based</systemitem>) sorgt dafür, dass die CIB im gesamten Cluster synchron bleibt, und verarbeitet Änderungsanfragen.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-clone">
      <glossterm>Klon</glossterm>
      <glossdef>
        <para>
      Ein <emphasis>Klon</emphasis> ist eine identische Kopie eines vorhandenen Knotens, um die Bereitstellung mehrerer Knoten zu vereinfachen.
    </para>
        <para>
      Im Kontext einer Cluster-<xref linkend="gloss-resource"/> ist ein Klon eine Ressource, die auf mehreren Knoten aktiv sein kann. Jede Ressource kann geklont werden, wenn ihr Ressourcenagent dies unterstützt.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>cluster</glossterm>
      <glossdef>
        <para>
      Ein <emphasis>Hochverfügbarkeits</emphasis>-Cluster ist eine Gruppe von Servern (physisch oder virtuell), die in erster Linie dazu dient, die höchstmögliche Verfügbarkeit von Daten und Anwendungsdiensten sicherzustellen. Er ist nicht zu verwechseln mit einem <emphasis>Hochleistungs</emphasis>-Cluster, der die Anwendungslast teilt, um schnellere Ergebnisse zu erzielen.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Cluster-Logical Volume Manager (Cluster-LVM)</glossterm>
      <glossdef>
        <para>
      Der Begriff <emphasis>Cluster-LVM</emphasis> gibt an, dass der LVM in einer Clusterumgebung verwendet wird. Dies erfordert Konfigurationsanpassungen zum Schutz der LVM-Metadaten in einem gemeinsam genutzten Speicher.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-clus-part">
      <glossterm>Clusterpartition</glossterm>
      <glossdef>
        <para>
      Eine Clusterpartition entsteht, wenn die Kommunikation zwischen einem oder mehreren Knoten und dem Rest des Clusters ausfällt. Die Knoten werden in Partitionen aufgeteilt, sind aber weiterhin aktiv. Sie können nur mit Knoten in derselben Partition kommunizieren und erkennen die anderen Knoten nicht. Dies wird als <xref linkend="gloss-splitbrain"/>-Szenario bezeichnet.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Clusterstapel</glossterm>
      <glossdef>
        <para>
      Die Gesamtheit der Softwaretechnologien und -komponenten, aus denen ein Cluster besteht.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-col-con">
      <glossterm>Koexistenzeinschränkung</glossterm>
      <glossdef>
        <para>
      Eine Art <xref linkend="gloss-resource-con"/>, die angibt, welche Ressourcen auf einem Knoten zusammen ausgeführt werden können und welche nicht.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Gleichzeitigkeitsverletzung</glossterm>
      <glossdef>
        <para>
      Eine Ressource, die eigentlich nur auf einem Knoten des Clusters ausgeführt werden sollte, wird auf mehreren Knoten ausgeführt.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-corosync">
      <glossterm>Corosync</glossterm>
      <glossdef>
        <para>
      Corosync bietet zuverlässige Messaging-, Mitgliedschafts- und Quorum-Informationen zum Cluster. Dies wird von der Corosync Cluster Engine, einem Gruppenkommunikationssystem, übernommen.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-crm">
      <glossterm>Cluster-Ressourcenmanager (CRM)</glossterm>
      <glossdef>
        <para>
      Die Verwaltungseinheit, die für die Koordinierung aller nicht lokalen Interaktionen in einem High Availability-Cluster zuständig ist. SUSE Linux Enterprise High Availability verwendet <xref linkend="gloss-pacemaker"/> als CRM. Es interagiert mit verschiedenen Komponenten: lokalen Executors auf ihrem eigenen Knoten und auf den anderen Knoten, nicht lokalen CRMs, administrativen Befehlen, der Fencing-Funktion und der Mitgliedschaftsschicht.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm><systemitem>crmsh</systemitem> (CRM-Shell)</glossterm>
      <glossdef>
        <para>
      Das Befehlszeilen-Dienstprogramm <emphasis><systemitem>crmsh</systemitem></emphasis> verwaltet den Cluster, die Knoten und die Ressourcen.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Csync2</glossterm>
      <glossdef>
        <para>
      Ein Synchronisierungswerkzeug zur Replikation von Konfigurationsdateien auf allen Knoten im Cluster.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-dc">
      <glossterm>Designierter Koordinator (DC, Designated Coordinator)</glossterm>
      <glossdef>
        <para>
      Der Daemon <systemitem>pacemaker-controld</systemitem> ist der Cluster-Controller, der alle Aktionen koordiniert. Dieser Daemon verfügt über eine Instanz auf jedem Clusterknoten, aber nur eine Instanz wird als designierter Koordinator gewählt. Der designierte Koordinator wird gewählt, wenn die Clusterdienste starten oder wenn der aktuelle designierte Koordinator ausfällt oder den Cluster verlässt. Der designierte Koordinator entscheidet, ob eine clusterweite Änderung vorgenommen werden muss, z. B. das Fencing eines Knotens oder das Verschieben von Ressourcen.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Disaster</glossterm>
      <glossdef>
        <para>
      Eine unerwartete Unterbrechung der kritischen Infrastruktur, die durch Natur, Menschen, Hardwarefehler oder Softwarefehler verursacht wird.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-dis-rec">
      <glossterm>Fehlerbehebung</glossterm>
      <glossdef>
        <para>
      Der Prozess, durch den eine Funktion nach einem Notfall wieder auf den normalen, stabilen Zustand zurückgesetzt wird.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Fehlerbehebungsplan</glossterm>
      <glossdef>
        <para>
      Eine Strategie zur Wiederherstellung nach einem Notfall mit möglichst geringen Auswirkungen auf die IT-Infrastruktur.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Distributed Lock Manager (DLM)</glossterm>
      <glossdef>
        <para>
      Distributed Lock Manager (DLM) koordiniert die Zugriffe auf gemeinsam genutzte Ressourcen in einem Cluster, z. B. durch die Verwaltung von Dateisperren in geclusterten Dateisystemen, um die Leistung und Verfügbarkeit zu verbessern.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-drbd">
      <glossterm>DRBD</glossterm>
      <glossdef>
        <para><trademark class="registered">DRBD</trademark> ist ein Blockgerät zum Erstellen von High Availability-Clustern. Es repliziert Daten auf einem primären Gerät auf sekundäre Geräte in einer Art und Weise, mit der sichergestellt wird, dass alle Kopien der Daten identisch bleiben.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Bestehender Cluster</glossterm>
      <glossdef>
        <para>
      Der Begriff <emphasis>bestehender Cluster</emphasis> bezieht sich auf jeden Cluster, der aus mindestens einem Knoten besteht. Ein bestehender Cluster verfügt über eine grundlegende <xref linkend="gloss-corosync"/>-Konfiguration, die die Kommunikationskanäle definiert, jedoch noch nicht unbedingt über eine Ressourcenkonfiguration.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="glo-failover">
      <glossterm>Failover</glossterm>
      <glossdef>
        <para>
      Tritt auf, wenn eine Ressource oder ein Knoten auf einem Rechner ausfällt und die betroffenen Ressourcen auf einen anderen Knoten verschoben werden.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Failover-Domäne</glossterm>
      <glossdef>
        <para>
      Eine benannte Teilmenge von Clusterknoten, die zur Ausführung einer Ressource berechtigt sind, wenn ein Knoten ausfällt.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-fencing">
      <glossterm>Fencing</glossterm>
      <glossdef>
        <para>
      Verhindert den Zugriff auf eine gemeinsam genutzte Ressource durch isolierte oder ausgefallene Clustermitglieder. Es gibt zwei Arten von Fencing: Fencing auf <emphasis>Ressourcenebene</emphasis> und Fencing auf <emphasis>Knotenebene</emphasis>. Beim Fencing auf Ressourcenebene wird der exklusive Zugriff auf eine Ressource sichergestellt. Beim Fencing auf Knotenebene wird verhindert, dass ein ausgefallener Knoten auf gemeinsam genutzte Ressourcen zugreift und dass Ressourcen auf einem Knoten mit unsicherem Status ausgeführt werden. Dies geschieht in der Regel durch Zurücksetzen oder Ausschalten des Knotens.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>GFS2</glossterm>
      <glossdef>
        <para>
      Global File System 2 (GFS2) ist ein gemeinsam genutztes Festplattendateisystem für Linux-Computer-Cluster. GFS2 ermöglicht allen Knoten den direkten und gleichzeitigen Zugriff auf denselben gemeinsam genutzten Blockspeicher. GFS2 hat keinen getrennten Betriebsmodus und keine Client- oder Serverrollen. Alle Knoten in einem GFS2-Cluster fungieren als Peers. GFS2 unterstützt bis zu 32 Clusterknoten. Für die Verwendung von GFS2 in einem Cluster muss die Hardware den Zugriff auf den gemeinsam genutzten Speicher zulassen und es ist ein Lock Manager erforderlich, um den Zugriff auf den Speicher zu steuern.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>group</glossterm>
      <glossdef>
        <para>
      Ressourcengruppen enthalten mehrere Ressourcen, die sich an einem gemeinsamen Ort befinden, nacheinander gestartet und in umgekehrter Reihenfolge angehalten werden müssen.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Hawk (HA-Webkonsole)</glossterm>
      <glossdef>
        <para>
      Eine benutzerfreundliche webbasierte Oberfläche zum Überwachen und Verwalten eines High Availability-Clusters von Linux- oder Nicht-Linux-Rechnern aus. Auf Hawk kann von jedem Rechner aus, der eine Verbindung mit den Clusterknoten herstellen kann, über einen grafischen Webbrowser zugegriffen werden.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-heuristics">
      <glossterm>Heuristik</glossterm>
      <glossdef>
        <para><xref linkend="gloss-qdevice"/> unterstützt die Verwendung einer Reihe von Befehlen (<emphasis>Heuristiken</emphasis>), die lokal beim Start von Clusterdiensten, bei einer Änderung der Clustermitgliedschaft, bei einer erfolgreichen Verbindung mit dem <xref linkend="gloss-qnetd"/>-Server oder optional zu regelmäßigen Zeiten ausgeführt werden. Das Ergebnis wird in Berechnungen verwendet, um zu bestimmen, welche Partition über <xref linkend="gloss-quorum"/> verfügen sollte.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>knet (Kronosnet)</glossterm>
      <glossdef>
        <para>
      Eine Netzabstraktionsschicht, die Redundanz, Sicherheit, Fehlertoleranz und schnelles Failover bei Netzverbindungen unterstützt. In SUSE Linux Enterprise High Availability 16 ist <emphasis>knet</emphasis> das Standard-Transportprotokoll für die <xref linkend="gloss-corosync"/>-Kommunikationskanäle.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Lokaler Cluster</glossterm>
      <glossdef>
        <para>
      Ein einzelner Cluster an einem Standort (z. B. alle Knoten befinden sich in einem Rechenzentrum). Die Netzwerklatenz ist minimal. Auf den Speicher wird in der Regel von allen Knoten synchron zugegriffen.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Lokaler Executor</glossterm>
      <glossdef>
        <para>
      Der lokale Executor befindet sich zwischen <xref linkend="gloss-pacemaker"/> und den Ressourcen auf jedem Knoten. Über den Daemon <systemitem class="daemon">pacemaker-execd</systemitem> kann Pacemaker Ressourcen starten, anhalten und überwachen.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>location</glossterm>
      <glossdef>
        <para>
      Im Kontext eines gesamten Clusters kann sich der <emphasis>Standort</emphasis> auf den physischen Standort der Knoten beziehen (z. B. könnten sich alle Knoten im selben Rechenzentrum befinden). Im Kontext einer <xref linkend="gloss-loc-con"/> bezieht sich der <emphasis>Standort</emphasis> auf die Knoten, auf denen eine Ressource ausgeführt werden kann oder nicht.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-loc-con">
      <glossterm>Standorteinschränkung</glossterm>
      <glossdef>
        <para>
      Eine Art <xref linkend="gloss-resource-con"/>, die die Knoten definiert, auf denen eine Ressource ausgeführt werden kann oder nicht.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Meta-Attribute (Ressourcenoptionen)</glossterm>
      <glossdef>
        <para>
      Parameter, die dem <xref linkend="gloss-crm"/> mitteilen, wie eine bestimmte <xref linkend="gloss-resource"/> zu behandeln ist. Sie können zum Beispiel die Priorität oder die Zielrolle einer Ressource definieren.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Metro-Cluster</glossterm>
      <glossdef>
        <para>
      Ein einzelner Cluster, der sich über mehrere Gebäude oder Rechenzentren erstrecken kann, wobei alle Standorte über Fibre Channel verbunden sind. Die Netzwerklatenz ist in der Regel gering. Der Speicher wird häufig durch Spiegelung oder synchrone Reproduktion reproduziert.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Netzwerkgeräte-Bonding (bevorzugt)</glossterm>
      <glossdef>
        <para>
      Beim Netzwerkgeräte-Bonding werden zwei oder mehr Netzwerkschnittstellen in einem einzigen Bond-Gerät kombiniert, um die Bandbreite zu erhöhen und/oder Redundanz bereitzustellen. Bei Verwendung von <xref linkend="gloss-corosync"/> wird das Bond-Gerät nicht von der Clustersoftware verwaltet. Daher muss das Bond-Gerät auf jedem Clusterknoten konfiguriert werden, der möglicherweise darauf zugreifen muss.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Knoten</glossterm>
      <glossdef>
        <para>
      Jeder Server (physisch oder virtuell), der Mitglied eines Clusters ist.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-ord-con">
      <glossterm>Reihenfolgeneinschränkung</glossterm>
      <glossdef>
        <para>
      Eine Art <xref linkend="gloss-resource-con"/>, die die Reihenfolge der Aktionen definiert.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-pacemaker">
      <glossterm>Pacemaker</glossterm>
      <glossdef>
        <para>
      Pacemaker ist der <xref linkend="gloss-crm"/> in SUSE Linux Enterprise High Availability, also das <quote>Gehirn</quote>, das auf Ereignisse im Cluster reagiert. Ereignisse können Knoten sein, die dem Cluster beitreten oder ihn verlassen, der Ausfall von Ressourcen oder geplante Aktivitäten wie Wartungen. Der Daemon <systemitem>pacemakerd</systemitem> startet und überwacht alle anderen zugehörigen Daemons.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Parameter (Instanzattribute)</glossterm>
      <glossdef>
        <para>
      Die Parameter bestimmen, welche Instanz eines Diensts die <xref linkend="gloss-resource"/> steuert.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Scheduler</glossterm>
      <glossdef>
        <para>
      Der Scheduler ist als <systemitem class="daemon">pacemaker-schedulerd</systemitem> implementiert. Wenn ein Clusterwechsel erforderlich ist, berechnet <systemitem class="daemon">pacemaker-schedulerd</systemitem> den erwarteten nächsten Status des Clusters und bestimmt, welche Aktionen geplant werden müssen, um den nächsten Status zu erreichen.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Primitiv</glossterm>
      <glossdef>
        <para>
      Eine primitive Ressource ist der einfachste Typ einer Clusterressource.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-prom-clone">
      <glossterm>Hochstufbarer Klon</glossterm>
      <glossdef>
        <para>
      Hochstufbare Klone sind eine besondere Art von <xref linkend="gloss-clone"/>-Ressourcen, die hochgestuft werden können. Aktive Instanzen dieser Ressourcen werden in zwei Status unterteilt: hochgestuft und nicht hochgestuft (auch bekannt als <quote>aktiv und passiv</quote> oder <quote>primär und sekundär</quote>).
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-qdevice">
      <glossterm>QDevice</glossterm>
      <glossdef>
        <para>
      QDevice und <xref linkend="gloss-qnetd"/> beteiligen sich an <xref linkend="gloss-quorum"/>-Entscheidungen. Der Daemon <systemitem>corosync-qdevice</systemitem> wird auf jedem Clusterknoten ausgeführt und kommuniziert mit QNetd, um eine konfigurierbare Anzahl an Stimmen bereitzustellen, sodass ein Cluster mehr Knotenausfälle bewältigen kann, als die Standard-Quorum-Regeln erlauben.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-qnetd">
      <glossterm>QNetd</glossterm>
      <glossdef>
        <para>
      QNetd ist ein <xref linkend="gloss-arbitrator"/>, der außerhalb des Clusters ausgeführt wird. Der Daemon <systemitem>corosync-qnetd</systemitem> stellt dem Daemon <systemitem>corosync-qdevice</systemitem> auf jedem Knoten eine Stimme bereit, damit dieser sich an Quorum-Entscheidungen beteiligen kann.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-quorum">
      <glossterm>Quorum</glossterm>
      <glossdef>
        <para>
      Eine <xref linkend="gloss-clus-part"/> ist als Quorum (<emphasis>quorumfähig</emphasis>) definiert, wenn sie über die Mehrheit der Knoten (oder <quote>Stimmen</quote>) verfügt. Das Quorum steht genau für eine Partition. Dies ist Teil des Algorithmus, um zu verhindern, dass mehrere nicht verbundene Partitionen oder Knoten (<quote>Split Brain</quote>) fortgesetzt werden und Daten- sowie Dienstbeschädigungen verursachen. Das Quorum ist eine Voraussetzung für das Fencing, das wiederum sicherstellt, dass das Quorum eindeutig ist.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Ressourcenagent (RA)</glossterm>
      <glossdef>
        <para>
      Ein Skript, das als Proxy für die Verwaltung einer <xref linkend="gloss-resource"/> fungiert (z. B. zum Starten, Anhalten oder Überwachen einer Ressource). SUSE Linux Enterprise High Availability unterstützt verschiedene Arten von Ressourcenagenten.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>ReaR (Relax and Recover)</glossterm>
      <glossdef>
        <para>
      Ein Administrator-Werkzeugsatz zum Erstellen von <xref linkend="gloss-dis-rec"/>-Images.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-resource">
      <glossterm>Ressourcen</glossterm>
      <glossdef>
        <para>
      Jede Art von Dienst oder Anwendung, die <xref linkend="gloss-pacemaker"/> bekannt ist, z. B. eine IP-Adresse, ein Dateisystem oder eine Datenbank. Der Begriff <emphasis>Ressource</emphasis> wird auch für <xref linkend="gloss-drbd"/> verwendet, wo er eine Gruppe aus Blockgeräten bezeichnet, die eine gemeinsame Verbindung für die Reproduktion nutzen.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-resource-con">
      <glossterm>Ressourcenbeschränkung</glossterm>
      <glossdef>
        <para>
      Ressourcenbeschränkungen geben an, auf welchen Clusterknotenressourcen ausgeführt werden können, in welcher Reihenfolge Ressourcen geladen werden und von welchen anderen Ressourcen eine bestimmte Ressource abhängig ist.
    </para>
        <para>
      Weitere Informationen finden Sie unter <xref linkend="gloss-col-con"/>, <xref linkend="gloss-loc-con"/> und <xref linkend="gloss-ord-con"/>.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Ressourcensatz</glossterm>
      <glossdef>
        <para>
      Als alternatives Format zum Definieren von Standort-, Koexistenz- oder Reihenfolgeneinschränkungen können Sie <emphasis>Ressourcensätze</emphasis> verwenden, in denen primitive Ressourcen in einem Satz gruppiert sind. Beim Erstellen einer Einschränkung können Sie mehrere Ressourcen angeben, für die die Einschränkung gelten soll.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Ressourcenvorlage</glossterm>
      <glossdef>
        <para>
      Um die Erstellung vieler Ressourcen mit ähnlichen Konfigurationen zu erleichtern, können Sie eine Ressourcenvorlage definieren. Nach dem Definieren kann in primitiven Ressourcen oder in bestimmten Arten von Einschränkungen auf sie verweisen werden. Wenn in einer primitiven Ressourcen auf eine Vorlage verwiesen wird, erbt die primitive Ressource alle in der Vorlage definierten Vorgänge, Instanzattribute (Parameter), Meta-Attribute und Nutzungsattribute.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-sbd">
      <glossterm>SBD (STONITH Block Device)</glossterm>
      <glossdef>
        <para>
      SBD bietet einen <xref linkend="gloss-fencing"/>-Mechanismus für Knoten durch den Austausch von Nachrichten über einen gemeinsam genutzten Blockspeicher. Alternativ kann es auch im festplattenlosen Modus verwendet werden. In jedem Fall ist auf jedem Knoten ein Hardware- oder Software-<xref linkend="gloss-watchdog"/> erforderlich, um sicherzustellen, dass problembehaftete Knoten wirklich angehalten werden.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-splitbrain">
      <glossterm>Split Brain</glossterm>
      <glossdef>
        <para>
      Ein Szenario, bei dem die Clusterknoten in zwei oder mehr Gruppen aufgeteilt sind, die sich gegenseitig nicht erkennen (entweder durch einen Software- oder Hardwarefehler). <xref linkend="gloss-stonith"/> verhindert ein Split Brain-Szenario, das den gesamten Cluster beeinträchtigt. Dies ist auch als Szenario mit <emphasis>partitioniertem Cluster</emphasis> bekannt.
    </para>
        <para>
      Der Begriff <emphasis>Split Brain</emphasis> wird auch in <xref linkend="gloss-drbd"/> verwendet, bedeutet aber, dass die Knoten unterschiedliche Daten enthalten.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>SPOF (Single Point of Failure)</glossterm>
      <glossdef>
        <para>
      Eine beliebige Komponente eines Clusters, die bei einem Ausfall den Ausfall des gesamten Clusters auslöst.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-stonith">
      <glossterm>STONITH</glossterm>
      <glossdef>
        <para>
      Ein Akronym für <emphasis>Shoot the other Node in the Head</emphasis> (Schieß dem anderen Knoten in den Kopf). Es bezieht sich auf den <xref linkend="gloss-fencing"/>-Mechanismus, der einen problembehafteten Knoten abschaltet, um zu verhindern, dass er Probleme in einem Cluster verursacht. In einem <xref linkend="gloss-pacemaker"/>-Cluster wird STONITH vom Fencing-Subsystem <systemitem>pacemaker-fenced</systemitem> verwaltet.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Umschaltung</glossterm>
      <glossdef>
        <para>
      Die geplante Verschiebung von Ressourcen auf andere Knoten in einem Cluster. Siehe auch <xref linkend="glo-failover"/>.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Auslastung</glossterm>
      <glossdef>
        <para>
      Teilt dem CRM mit, welche Kapazität eine bestimmte <xref linkend="gloss-resource"/> von einem Knoten benötigt.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-watchdog">
      <glossterm>watchdog</glossterm>
      <glossdef>
        <para>Für <xref linkend="gloss-sbd"/> ist ein Watchdog erforderlich, um sicherzustellen, dass problembehaftete Knoten wirklich angehalten werden. SBD <quote>füttert</quote> den Watchdog, indem es regelmäßig einen Dienstimpuls an ihn schreibt. Wenn SBD den Watchdog nicht mehr „füttert“, erzwingt die Hardware einen Neustart des Systems. Dies schützt vor Fehlern des SBD-Prozesses selbst, z. B. wenn er bei einem E/A-Fehler hängen bleibt.
    </para>
      </glossdef>
    </glossentry>
  </glossary>
</article>
