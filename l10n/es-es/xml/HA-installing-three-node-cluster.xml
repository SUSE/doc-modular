<?xml version='1.0' encoding='UTF-8'?><article xmlns="http://docbook.org/ns/docbook" version="5.2" xml:id="three-node-cluster-diskless-sbd" xml:lang="es">
  <info>
    <title xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude">Instalación de un clúster de alta disponibilidad básico de tres nodos</title>
    <revhistory xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xml:id="rh-HA-three-node-cluster-diskless-sbd">
      <revision>
        <date>4/11/2025</date>
        <revdescription>
          <para>
              Versión inicial
            </para>
        </revdescription>
      </revision>
    </revhistory>
    <meta xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/> <meta xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" name="architecture">
      <phrase>AMD64/Intel 64</phrase>
      <phrase>POWER</phrase>
      <phrase>IBM Z</phrase>
    </meta> <meta xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" name="productname" its:translate="no">
      <productname version="16.0">SUSE Linux Enterprise High Availability</productname>
    </meta>
    <meta xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" name="title" its:translate="yes">Instalación de un clúster de alta disponibilidad básico de tres nodos</meta>
    <meta xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" name="description" its:translate="yes">Configuración de un clúster de alta disponibilidad básico de tres nodos con fines de prueba</meta>
    <meta xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" name="social-descr" its:translate="yes">Configurar un clúster de HA básico de tres nodos</meta>
    <meta xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" name="category" its:translate="no">
      <phrase>Deployment</phrase>
    </meta> <meta xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" name="task" its:translate="no">
      <phrase>Clustering</phrase>
      <phrase>Configuration</phrase>
      <phrase>Deployment</phrase>
      <phrase>High Availability</phrase>
      <phrase>Installation</phrase>
    </meta>
    <meta xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" name="series">Productos y soluciones</meta>
    <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude">
      <dm:bugtracker>
        <dm:url>https://bugzilla.suse.com/enter_bug.cgi</dm:url>
        <dm:component>Documentation</dm:component>
        <dm:product>
          <dm:product condition="16.0">SUSE Linux Enterprise High Availability 16.0</dm:product>
        </dm:product>
        <dm:assignee>tahlia.richardson@suse.com</dm:assignee>
      </dm:bugtracker>
      <dm:translation>yes</dm:translation>
    </dm:docmanager>
    <abstract xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude">
      <variablelist>
        <varlistentry>
          <term>DESCRIPCIÓN</term>
          <listitem>
            <para>
              Cómo configurar un clúster de alta disponibilidad básico de tres nodos con SBD sin disco y un vigilante de software.
            </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>INTENCIÓN</term>
          <listitem>
            <para>
              Puede utilizar este clúster con fines de prueba o como configuración de clúster mínima que puede ampliar más adelante.
            </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>ESFUERZO</term>
          <listitem>
            <para>
                En configurar un clúster básico de alta disponibilidad se tardan aproximadamente 15 minutos, dependiendo de la velocidad de la conexión de red.
              </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>OBJETIVO</term>
          <listitem>
            <para>
                Empezar a usar SUSE Linux Enterprise High Availability de forma rápida y sencilla.
              </para>
          </listitem>
        </varlistentry>
      </variablelist>
    </abstract>
  </info>
  <section role="concept" xml:lang="es" version="5.2" xml:id="ha-installing-cluster-usage-scenario">
    <info>
      <title xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">Ejemplo de uso</title>
      <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
    </info>
    <para>
    En esta guía se describe la configuración de un clúster de alta disponibilidad mínimo con las siguientes propiedades:
  </para>
    <itemizedlist>
      <listitem>
        <para condition="threenode">
        Tres nodos de clúster con acceso SSH sin contraseña entre sí. Se requieren tres nodos para esta configuración, de modo que SBD sin disco pueda manejar escenarios de nodos malinformados (split-brain) sin la ayuda de QDevice.
      </para>
      </listitem>
      <listitem>
        <para>
        Una dirección IP virtual flotante que permita a los clientes conectarse a la herramienta de gestión gráfica Hawk independientemente del nodo en el que se esté ejecutando el servicio.
      </para>
      </listitem>
      <listitem>
        <para>
        SBD (STONITH Block Device, dispositivo de bloques STONITH) sin disco y un vigilante (watchdog) de software utilizado como mecanismo de fencing de nodos para evitar situaciones de nodos malinformados.
      </para>
      </listitem>
      <listitem>
        <para>
        Failover de recursos de un nodo a otro si el host activo se interrumpe (configuración <emphasis>activa/pasiva</emphasis>).
      </para>
      </listitem>
    </itemizedlist>
    <para>
    Se trata de una configuración de clúster sencilla con requisitos externos mínimos. Puede utilizar este clúster con fines de prueba o como configuración de clúster mínima que puede ampliar más adelante para un entorno de producción.
  </para>
  </section>
  <section role="glue" xml:lang="es" version="5.2" xml:id="ha-installing-cluster-overview">
    <info>
      <title xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">Descripción general de la instalación</title>
      <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
    </info>
    <para>
    Para instalar el clúster de alta disponibilidad descrito en la <xref linkend="ha-installing-cluster-usage-scenario"/>, debe realizar las siguientes tareas:
  </para>
    <orderedlist>
      <listitem>
        <para>
        Revise la <xref linkend="ha-requirements"/> para asegurarse de tener todo lo que necesita.
      </para>
      </listitem>
      <listitem>
        <para>
        Instale SUSE Linux Enterprise High Availability en los nodos del clúster (<xref linkend="ha-enabling-extension"/>).
      </para>
      </listitem>
      <listitem>
        <para>
        Inicialice el clúster en el primer nodo (<xref linkend="ha-setting-up-first-node"/>).
      </para>
      </listitem>
      <listitem>
        <para>
        Añada más nodos al clúster (<xref linkend="ha-adding-nodes"/>).
      </para>
      </listitem>
      <listitem>
        <para>
        Inicie sesión en la interfaz Web de Hawk para supervisar el clúster (<xref linkend="ha-hawk-logging-in"/>).
      </para>
      </listitem>
      <listitem>
        <para>
        Realice pruebas básicas para asegurarse de que el clúster funciona según lo esperado (<xref linkend="ha-testing-the-cluster-basic"/>).
      </para>
      </listitem>
      <listitem>
        <para>
        Revise la <xref linkend="ha-installing-cluster-next-steps"/> para averiguar cómo expandir el clúster para un entorno de producción.
      </para>
      </listitem>
    </orderedlist>
  </section>
  <section role="reference" xml:lang="es" version="5.2" xml:id="ha-requirements">
    <info>
      <title xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude">Requisitos del sistema</title>
      <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="" its:translate="no"/>
      <abstract xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">
        <para>
       En esta sección se describen los requisitos del sistema para una configuración mínima de SUSE Linux Enterprise High Availability.
      </para>
      </abstract>
    </info>
    <section xml:id="ha-requirements-hardware">
      <title>Requisitos de hardware</title>
      <variablelist>
        <varlistentry>
          <term>Servidores</term>
          <listitem>
            <para condition="threenode">
            Tres servidores que actúen como nodos de clúster.
          </para>
            <para>
            Los servidores pueden ser equipos desde cero o máquinas virtuales. No es necesario que el hardware sea idéntico (memoria, espacio de disco, etc.), pero debe tener la misma arquitectura. No se admiten clústeres de distintas plataformas.
          </para>
            <para>
            Consulte la sección <citetitle>System Requirements</citetitle> en <link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.suse.com/download/sle-ha/"></link> para obtener más información sobre el hardware del servidor.
          </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Tarjetas de interfaz de red</term>
          <listitem>
            <para>
            Al menos dos tarjetas de interfaz de red por nodo de clúster. Esto le permite configurar dos o más canales de comunicación para el clúster, utilizando uno de los siguientes métodos:
          </para>
            <itemizedlist>
              <listitem>
                <para>
                Combine las tarjetas de interfaz de red en una vinculación de red (método preferido). En este caso, debe configurar el dispositivo vinculado en cada nodo antes de inicializar el clúster.
              </para>
              </listitem>
              <listitem>
                <para>
                Cree un segundo canal de comunicación en Corosync. Esto se puede configurar mediante el guion de configuración del clúster. En este caso, las dos tarjetas de interfaz de red deben estar en subredes diferentes.
              </para>
              </listitem>
            </itemizedlist>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>STONITH (fencing de nodos)</term>
          <listitem>
            <para>
            Para que sean compatibles, todos los clústeres de SUSE Linux Enterprise High Availability <emphasis>deben</emphasis> tener al menos un dispositivo de fencing (STONITH) para evitar situaciones de nodos malinformados. Puede ser un dispositivo físico (un conmutador de alimentación) o un dispositivo SBD en combinación con un vigilante. El SBD se puede utilizar con almacenamiento compartido o en modo sin disco.
          </para>
            <para>
            La configuración mínima descrita en esta guía utiliza un vigilante de software y un SBD sin disco, por lo que no se requiere hardware adicional. Antes de usar este clúster en un entorno de producción, sustituya el vigilante de software por un vigilante de hardware.
          </para>
          </listitem>
        </varlistentry>
      </variablelist>
    </section>
    <section xml:id="ha-requirements-software">
      <title>Requisitos de software</title>
      <variablelist>
        <varlistentry>
          <term>Sistema operativo</term>
          <listitem>
            <para>
            Todos los nodos deben tener SUSE Linux Enterprise Server instalado y registrado.
          </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Extensión de High Availability</term>
          <listitem>
            <para>
            La extensión de SUSE Linux Enterprise High Availability requiere un código de registro adicional.
          </para>
            <para>
            Esta extensión se puede habilitar durante la instalación de SLES, o más adelante en un sistema en ejecución. En esta guía se explica cómo habilitar y registrar la extensión en un sistema en ejecución.
          </para>
          </listitem>
        </varlistentry>
      </variablelist>
    </section>
    <section xml:id="ha-requirements-network">
      <title>Requisitos de red</title>
      <variablelist>
        <varlistentry>
          <term>Sincronización horaria</term>
          <listitem>
            <para>
            Todos los sistemas deben sincronizarse con un servidor NTP externo al clúster. SUSE Linux Enterprise Server usa <systemitem class="resource">chrony</systemitem> para NTP. Al inicializar el clúster, se le advierte si <systemitem class="resource">chrony</systemitem> no se está ejecutando.
          </para>
            <para>
            Incluso si los nodos están sincronizados, los archivos de registro y los informes de clúster pueden resultar difíciles de analizar si los nodos tienen diferentes zonas horarias configuradas.
          </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Nombre del host y dirección IP</term>
          <listitem>
            <para>
            Todos los nodos del clúster deben ser capaces de encontrar a los demás por su nombre. Use los siguientes métodos para resolver los nombres de forma fiable:
          </para>
            <itemizedlist>
              <listitem>
                <para>
                Utilice direcciones IP estáticas.
              </para>
              </listitem>
              <listitem>
                <para>
                Muestre todos los nodos del archivo <filename>/etc/hosts</filename> con su dirección IP, el nombre de dominio completo y el nombre de host corto.
              </para>
              </listitem>
            </itemizedlist>
            <para>
            En cada tarjeta de interfaz de red solo se admite la dirección IP principal.
          </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>SSH</term>
          <listitem>
            <para>
            Todos los nodos del clúster deben ser capaces de acceder a los demás mediante SSH. Ciertas operaciones de clúster también requieren autenticación SSH sin contraseña. Al inicializar el clúster, el guion de configuración comprueba si hay claves SSH existentes y las genera si no existen.
          </para>
            <important>
              <title>acceso SSH de <systemitem class="username">root</systemitem> en SUSE Linux Enterprise 16</title>
              <para>
              En SUSE Linux Enterprise 16, el inicio de sesión SSH de <systemitem class="username">root</systemitem> con contraseña está inhabilitado por defecto.
            </para>
              <para>
              En cada nodo, cree un usuario con privilegios de <command>sudo</command> o configure la autenticación SSH sin contraseña para el usuario <systemitem class="username">root</systemitem> antes de inicializar el clúster.
            </para>
              <para>
              Si inicializa el clúster con un usuario <command>sudo</command>, ciertos comandos de <systemitem>crmsh</systemitem> también requieren permiso de <command>sudo</command> sin contraseña.
            </para>
            </important>
          </listitem>
        </varlistentry>
      </variablelist>
    </section>
  </section>
  <section role="task" xml:lang="es" version="5.2" xml:id="ha-enabling-extension">
    <info>
      <title xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">Habilitación de la extensión de High Availability</title>
      <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
      <abstract xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">
        <para>
        En este procedimiento se explica cómo instalar SUSE Linux Enterprise High Availability en una instancia de SUSE Linux Enterprise Server existente. Puede omitir este procedimiento si ya ha instalado la extensión y los paquetes de High Availability durante la instalación de SLES con Agama.
      </para>
      </abstract>
    </info>
    <itemizedlist>
      <title>Requisitos</title>
      <listitem>
        <para>
        SUSE Linux Enterprise Server se instala y se registra en el Centro de servicios al cliente de SUSE.
      </para>
      </listitem>
      <listitem>
        <para>
        Debe tener un código de registro adicional para SUSE Linux Enterprise High Availability.
      </para>
      </listitem>
    </itemizedlist>
    <para>
    Realice este procedimiento en todos los equipos que desee utilizar como nodos de clúster:
  </para>
    <procedure>
      <step>
        <para>
        Inicie sesión como usuario <systemitem class="username">root</systemitem> o como usuario con privilegios de <command>sudo</command>.
      </para>
      </step>
      <step>
        <para>
        Compruebe si la extensión de High Availability ya está habilitada:
      </para>
        <screen>
          <prompt>&gt; </prompt>
          <command>sudo SUSEConnect --list-extensions</command>
        </screen>
      </step>
      <step>
        <para>
        Compruebe si los paquetes de High Availability ya están instalados:
      </para>
        <screen>
          <prompt>&gt; </prompt>
          <command>zypper search ha_sles</command>
        </screen>
      </step>
      <step>
        <para>
        Habilite la extensión de SUSE Linux Enterprise High Availability:
      </para>
        <screen>
          <prompt>&gt; </prompt>
          <command>sudo SUSEConnect -p sle-ha/<phrase><phrase os="sleha">16.0</phrase></phrase>/x86_64 -r <replaceable>HA_REGCODE</replaceable></command>
        </screen>
      </step>
      <step>
        <para>
        Instale los paquetes de High Availability:</para>
        <screen>
          <prompt>&gt; </prompt>
          <command>sudo zypper install -t pattern ha_sles</command>
        </screen>
      </step>
    </procedure>
  </section>
  <section role="glue" xml:lang="es" version="5.2" xml:id="ha-setting-up-first-node">
    <info>
      <title xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">Configuración del primer nodo</title>
      <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
    </info>
    <para>
    SUSE Linux Enterprise High Availability incluye guiones de configuración para simplificar la instalación de un clúster. Para configurar el clúster en el primer nodo, use el guion <command>crm cluster init</command>.
  </para>
    <section role="reference" xml:lang="es" version="5.2" xml:id="ha-crmsh-overview-init-script">
      <info>
        <title xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">Descripción del guion <command>crm cluster init</command></title>
        <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
        <abstract xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">
          <para>
       El comando <command>crm cluster init</command> inicia un guion que define los parámetros básicos necesarios para la comunicación del clúster, lo que da como resultado un clúster en el que se ejecuta un nodo.
      </para>
        </abstract>
      </info>
      <para>
    El guion comprueba y configura los siguientes componentes:
  </para>
      <variablelist>
        <varlistentry>
          <term>NTP</term>
          <listitem>
            <para>
          Comprueba si <systemitem class="resource">chrony</systemitem> está configurado para iniciarse en el momento del arranque. Si no es así, aparece un mensaje.
        </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>SSH</term>
          <listitem>
            <para>
          Detecta o genera claves SSH para el inicio de sesión sin contraseña entre los nodos del clúster.
        </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Cortafuegos</term>
          <listitem>
            <para>
          Abre los puertos del cortafuegos necesarios para la comunicación del clúster.
        </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Csync2</term>
          <listitem>
            <para>
          Configura Csync2 para replicar los archivos de configuración en todos los nodos de un clúster.
        </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Corosync</term>
          <listitem>
            <para>
          Configura el sistema de comunicación del clúster.
        </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>SBD/vigilante</term>
          <listitem>
            <para>
          Comprueba si existe un vigilante y pregunta si desea configurar el SBD como mecanismo de fencing de nodos.
        </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>Administración de clúster de Hawk</term>
          <listitem>
            <para>
          Habilita el servicio Hawk y muestra la URL de la interfaz Web de Hawk.
        </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>IP virtual flotante</term>
          <listitem>
            <para>
          Pregunta si se debe configurar una dirección IP virtual para la interfaz Web de Hawk.
        </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>QDevice/QNetd</term>
          <listitem>
            <para>
          Pregunta si desea configurar QDevice/QNetd para participar en las decisiones de quórum. Se recomienda para clústeres con un número par de nodos, y especialmente para clústeres de dos nodos.
        </para>
          </listitem>
        </varlistentry>
      </variablelist>
      <note>
        <title>ajustes por defecto de Pacemaker</title>
        <para>
      Las opciones definidas por el guion <command>crm cluster init</command> pueden no ser las mismas que los ajustes por defecto de Pacemaker. Puede comprobar qué ajustes ha cambiado el guion en <filename>/var/log/crmsh/crmsh.log</filename>. Todas las opciones que se establecen durante el proceso de arranque se pueden modificar más adelante con <systemitem>crmsh</systemitem>.
    </para>
      </note>
      <note>
        <title>configuración del clúster para distintas plataformas</title>
        <para>
      El guión <command>crm cluster init</command> detecta el entorno del sistema (por ejemplo, Microsoft Azure) y ajusta determinados valores de clúster en función del perfil de ese entorno. Si desea información adicional, consulte el archivo <filename>/etc/crm/profiles.yml</filename>.
    </para>
      </note>
    </section>
    <section role="task" xml:lang="es" version="5.2" xml:id="ha-initializing-cluster">
      <info>
        <title xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude">Inicialización del clúster en el primer nodo</title>
        <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
        <abstract xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">
          <para>
        Configure el clúster en el primer nodo con el guion <command>crm cluster init</command>. El guion solicita información básica sobre el clúster y configura los ajustes y servicios necesarios. Para obtener más información, ejecute el comando <command>crm cluster init --help</command>.
      </para>
        </abstract>
      </info>
      <itemizedlist>
        <title>Requisitos</title>
        <listitem>
          <para>
        SUSE Linux Enterprise High Availability debe estar instalado y actualizado.
      </para>
        </listitem>
        <listitem>
          <para>
        Todos los nodos deben tener al menos dos interfaces de red o una vinculación de red, con direcciones IP estáticas mostradas en el archivo <filename>/etc/hosts</filename> junto con el nombre de dominio completo y el nombre de host corto de cada nodo.
      </para>
        </listitem>
      </itemizedlist>
      <para>
    Realice este procedimiento en un solo nodo:
  </para>
      <procedure>
        <step>
          <para>
        Inicie sesión en el primer nodo como usuario <systemitem class="username">root</systemitem> o como usuario con privilegios de <command>sudo</command>.
      </para>
        </step>
        <step>
          <para>
        Inicie el guion <command>crm cluster init</command>:
      </para>
          <screen>
            <prompt>&gt; </prompt>
            <command>sudo crm cluster init</command>
          </screen>
          <para>
        El guion comprueba si <systemitem class="resource">chrony</systemitem> se está ejecutando, abre los puertos del firewall necesarios, configura Csync2 y comprueba si hay claves SSH. Si no hay claves SSH disponibles, el guion las genera.
      </para>
        </step>
        <step>
          <para>
        Configure Corosync para la comunicación del clúster:
      </para>
          <substeps>
            <step>
              <para>
            Introduzca una dirección IP para el primer canal de comunicación (<literal>ring0</literal>). Por defecto, el guion propone la dirección de la primera interfaz de red disponible. Puede ser una interfaz individual o un dispositivo vinculado. Acepte esta dirección o introduzca otra.
          </para>
            </step>
            <step>
              <para>
            Si el guion detecta varias interfaces de red, pregunta si desea configurar un segundo canal de comunicación (<literal>ring1</literal>). Si ha configurado el primer canal con un dispositivo vinculado, puede rechazar la acción con <literal>n</literal>. Si necesita configurar un segundo canal, confirme con <literal>y</literal> e introduzca la dirección IP de otra interfaz de red. Las dos interfaces deben estar en subredes diferentes.
          </para>
            </step>
          </substeps>
          <para>
        El guion configura los puertos de firewall predeterminados para la comunicación de Corosync.
      </para>
        </step>
        <step>
          <para>
        Seleccione si desea configurar el SBD como mecanismo de fencing de nodos:
      </para>
          <substeps>
            <step>
              <para>
            Confirme con <literal>y</literal> que desea utilizar el SBD.</para>
            </step>
            <step>
              <para>
            Cuando se le solicite una vía a un dispositivo de bloques, introduzca <literal>none</literal> para configurar el SBD sin disco.</para>
            </step>
          </substeps>
          <para>
        El guion configura el SBD, incluida la configuración de tiempo límite relevante. A diferencia del SBD basado en disco, el SBD sin disco no requiere un recurso de clúster STONITH.
      </para>
          <para>
        Si no hay ningún vigilante de hardware disponible, el guion configura el vigilante de software <systemitem>softdog</systemitem>.
      </para>
        </step>
        <step>
          <para>
        Configure una dirección IP virtual para la administración del clúster con la interfaz Web de Hawk:
      </para>
          <substeps>
            <step>
              <para>
            Confirme con <literal>y</literal> que desea configurar una dirección IP virtual.
          </para>
            </step>
            <step>
              <para>
            Introduzca una dirección IP no utilizada que desee usar como IP de administración para Hawk.
          </para>
            </step>
          </substeps>
          <para>
        En lugar de iniciar sesión en Hawk en un nodo de clúster individual, puede conectarse a la dirección IP virtual.
      </para>
        </step>
        <step>
          <para>
        Elija si desea configurar QDevice y Qnetd:
      </para>
          <para condition="threenode">
        Para la instalación mínima descrita en este documento, rechace la acción con <literal>n</literal>.
      </para>
        </step>
      </procedure>
      <para>
    El guion inicia los servicios de clúster para conectar el clúster y habilitar Hawk. La URL que se utilizará para Hawk se muestra en la pantalla. También puede comprobar el estado del clúster con el comando <command>crm status</command>.
  </para>
      <important>
        <title>contraseña segura para <systemitem>hacluster</systemitem></title>
        <para>
      El guion <command>crm cluster init</command> crea un usuario y una contraseña de clúster por defecto. Sustituya la contraseña por defecto por una segura tan pronto como sea posible:
    </para>
        <screen>
          <prompt>&gt; </prompt>
          <command>sudo passwd hacluster</command>
        </screen>
      </important>
    </section>
  </section>
  <section role="task" xml:lang="es" version="5.2" xml:id="ha-adding-nodes">
    <info>
      <title xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude">Adición del segundo y el tercer nodo</title>
      <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
      <abstract xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">
        <para>
        Añada más nodos al clúster con el guion <command>crm cluster join</command>. El guion solo necesita acceso a un nodo de clúster existente y finaliza automáticamente la configuración básica en el equipo actual. Para obtener más información, ejecute el comando <command>crm cluster join --help</command>.
      </para>
      </abstract>
    </info>
    <itemizedlist>
      <title>Requisitos</title>
      <listitem>
        <para>
        SUSE Linux Enterprise High Availability debe estar instalado y actualizado.
      </para>
      </listitem>
      <listitem>
        <para>
        Debe haber ya un clúster en ejecución en al menos un nodo.
      </para>
      </listitem>
      <listitem>
        <para>
        Todos los nodos deben tener al menos dos interfaces de red o una vinculación de red, con direcciones IP estáticas mostradas en el archivo <filename>/etc/hosts</filename> junto con el nombre de dominio completo y el nombre de host corto de cada nodo.
      </para>
      </listitem>
      <listitem>
        <para><emphasis>Si inicia sesión como usuario <command>sudo</command>:</emphasis> el mismo usuario debe existir en todos los nodos. Este usuario debe tener permiso de <command>sudo</command> sin contraseña.
      </para>
      </listitem>
      <listitem>
        <para><emphasis>Si inicia sesión como el usuario <systemitem class="username">root</systemitem>:</emphasis> la autenticación SSH sin contraseña debe configurarse en todos los nodos.
      </para>
      </listitem>
    </itemizedlist>
    <para>
    Realice este procedimiento en cada nodo adicional:
  </para>
    <procedure>
      <step>
        <para>
     Inicie sesión en este nodo como el mismo usuario con el que configuró el primer nodo.
    </para>
      </step>
      <step>
        <para>
     Inicie el guion <command>crm cluster join</command>:
    </para>
        <itemizedlist>
          <listitem>
            <para>
          Si configura el primer nodo como <systemitem class="username">root</systemitem>, puede iniciar el guion sin parámetros adicionales:
        </para>
            <screen>
              <prompt role="root"># </prompt>
              <command>crm cluster join</command>
            </screen>
          </listitem>
          <listitem>
            <para>
          Si configura el primer nodo como usuario <command>sudo</command>, debe especificar ese usuario con la opción <option>-c</option>:
        </para>
            <screen>
              <prompt>&gt; </prompt>
              <command>sudo crm cluster join -c <replaceable>USER@NODE1</replaceable></command>
            </screen>
          </listitem>
        </itemizedlist>
        <para>
      El guion comprueba si <systemitem class="resource">chrony</systemitem> se está ejecutando, abre los puertos del firewall necesarios y configura Csync2.
    </para>
      </step>
      <step>
        <para>
      Si aún no ha especificado el primer nodo con <option>-c</option>, se le solicita su dirección IP o el nombre de host.
    </para>
      </step>
      <step>
        <para>
      Si aún no ha configurado la autenticación SSH sin contraseña entre los nodos, se le solicitarán las <phrase condition="threenode">contraseñas de cada uno de los nodos existentes</phrase>.
    </para>
      </step>
      <step>
        <para>
       Configure Corosync para la comunicación del clúster:
     </para>
        <substeps>
          <step>
            <para>
           El guion propone una dirección IP para <literal>ring0</literal>. Esta dirección IP debe estar en la misma subred que la dirección IP usada para <literal>ring0</literal> en el primer nodo. Si no es así, introduzca la dirección IP correcta.
         </para>
          </step>
          <step>
            <para>
           Si el clúster tiene dos canales de comunicación Corosync configurados, el guion le solicita una dirección IP para <literal>ring1</literal>. Esta dirección IP debe estar en la misma subred que la dirección IP usada para <literal>ring1</literal> en el primer nodo.
         </para>
          </step>
        </substeps>
      </step>
    </procedure>
    <para>
    El guion copia la configuración del clúster del primer nodo, ajusta la configuración del tiempo límite para considerar el nuevo nodo y pone el nuevo nodo en línea.
    </para>
    <para>
    Puede comprobar el estado del clúster con el comando <command>crm status</command>.
  </para>
    <important>
      <title>contraseña segura para <systemitem>hacluster</systemitem></title>
      <para>
      El guion <command>crm cluster join</command> crea un usuario y una contraseña de clúster por defecto. En cada nodo, sustituya la contraseña por defecto por una segura tan pronto como sea posible:
    </para>
      <screen>
        <prompt>&gt; </prompt>
        <command>sudo passwd hacluster</command>
      </screen>
    </important>
  </section>
  <section role="task" xml:lang="es" version="5.2" xml:id="ha-hawk-logging-in">
    <info>
      <title xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">Inicio de sesión en Hawk</title>
      <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
      <abstract xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">
        <para>
         Hawk le permite supervisar y administrar un clúster de alta disponibilidad mediante un navegador Web gráfico. También puede configurar una dirección IP virtual que permita a los clientes conectarse a Hawk independientemente del nodo en el que se esté ejecutando.
      </para>
      </abstract>
    </info>
    <itemizedlist>
      <title>Requisitos</title>
      <listitem>
        <para>
        El equipo cliente debe poder conectarse a los nodos del clúster.
      </para>
      </listitem>
      <listitem>
        <para>
        El equipo cliente debe tener un navegador Web gráfico con JavaScript y cookies habilitados.
      </para>
      </listitem>
    </itemizedlist>
    <para>
    Puede realizar este procedimiento en cualquier equipo que pueda conectarse a los nodos del clúster:
  </para>
    <procedure>
      <step>
        <para>
        Inicie un navegador Web e introduzca la URL siguiente:
      </para>
        <screen>https://<replaceable>HAWKSERVER</replaceable>:7630/</screen>
        <para>
        Sustituya <replaceable>HAWKSERVER</replaceable> con la dirección IP o el nombre de host de un nodo de clúster, o la dirección IP virtual de Hawk si está configurada.
      </para>
        <note>
          <title>advertencia de certificado</title>
          <para>
          Si aparece una advertencia de certificado cuando accede a la URL por primera vez, se debe a que se está usando un certificado autofirmado. Consulte a su operador de clúster los detalles del certificado para verificarlo. Si desea continuar de todas formas, puede añadir una excepción en el navegador para omitir la advertencia.
        </para>
        </note>
      </step>
      <step>
        <para>
        En la pantalla de inicio de sesión de Hawk, introduzca el <guimenu>Nombre de usuario</guimenu> y la <guimenu>Contraseña</guimenu> del usuario <systemitem class="username">hacluster</systemitem>.
      </para>
      </step>
      <step>
        <para>
        Haga clic en <guimenu>Iniciar sesión</guimenu>. La interfaz Web de Hawk muestra por defecto la pantalla <guimenu>Estado</guimenu>:
      </para>
      </step>
    </procedure>
    <figure xml:id="fig-ha-hawk-status">
      <title>La pantalla Estado de Hawk</title>
      <mediaobject>
        <imageobject role="fo">
          <imagedata fileref="ha-hawk-status.png" width="100%"/>
        </imageobject>
        <imageobject role="html">
          <imagedata fileref="ha-hawk-status.png" width="100%"/>
        </imageobject>
        <textobject role="description">
          <phrase> La pantalla Estado muestra un recurso configurado: la dirección IP virtual <literal>admin-ip</literal>, que se ejecuta en un nodo llamado <literal>alice</literal>. </phrase>
        </textobject>
      </mediaobject>
    </figure>
  </section>
  <section role="glue" xml:lang="es" version="5.2" xml:id="ha-testing-the-cluster-basic">
    <info>
      <title xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">Comprobación del clúster</title>
      <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
    </info>
    <para>
    Las siguientes pruebas pueden ayudarle a identificar problemas con la configuración del clúster. Sin embargo, una prueba realista implica casos de uso y situaciones específicos. Antes de utilizar el clúster en un entorno de producción, pruébelo exhaustivamente en consonancia con sus casos de uso.
  </para>
    <section role="task" xml:lang="es" version="5.2" xml:id="ha-testing-resource-failover">
      <info>
        <title xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">Prueba de failover de recursos</title>
        <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
        <abstract xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">
          <para>
        Compruebe si el clúster mueve recursos a otro nodo si el nodo actual tiene el estado <literal>standby</literal>. Este procedimiento usa nodos de ejemplo llamados <systemitem>alice</systemitem> y <systemitem>bob</systemitem>, y un recurso de IP virtual llamado <literal>admin-ip</literal> con la dirección IP de ejemplo <literal>192.168.1.10</literal>.
      </para>
        </abstract>
      </info>
      <procedure>
        <step>
          <para>
        Abra dos terminales.
      </para>
        </step>
        <step>
          <para>
        En el primero, haga ping a la dirección IP virtual:
      </para>
          <screen>
            <prompt>&gt; </prompt>
            <command>ping 192.168.1.10</command>
          </screen>
        </step>
        <step>
          <para>
        En el segundo terminal, inicie sesión en uno de los nodos del clúster.
      </para>
        </step>
        <step>
          <para>
        Compruebe en qué nodo se ejecuta la dirección IP virtual:
      </para>
          <screen><prompt>&gt; </prompt><command>sudo crm status</command>
[..]
Node List:
  * Online: [ alice bob ]

Full List of Resources:
  * admin-ip  (ocf:heartbeat:IPaddr2):    Started alice</screen>
        </step>
        <step>
          <para>
        Ponga <systemitem>alice</systemitem> en modo En espera:
      </para>
          <screen>
            <prompt>&gt; </prompt>
            <command>sudo crm node standby alice</command>
          </screen>
        </step>
        <step>
          <para>
        Compruebe de nuevo el estado del clúster. El recurso <literal>admin-ip</literal> debería haber migrado a <systemitem>bob</systemitem>:
      </para>
          <screen><prompt>&gt; </prompt><command>sudo crm status</command>
[...]
Node List:
  * Node alice: standby
  * Online: [ bob ]

Full List of Resources:
  * admin-ip  (ocf:heartbeat:IPaddr2):    Started bob</screen>
        </step>
        <step>
          <para>
        Durante la migración, en el primer terminal, se mostrará un flujo ininterrumpido de pings a la dirección IP virtual. Esto muestra que la configuración del clúster y la dirección IP flotante funcionan correctamente.
      </para>
        </step>
        <step>
          <para>
        Cancele el comando <command>ping</command> con <keycombo> <keycap function="control"></keycap><keycap>C</keycap> </keycombo>.
      </para>
        </step>
        <step>
          <para>
        En el segundo terminal, vuelva a poner <systemitem>alice</systemitem> en línea:
      </para>
          <screen>
            <prompt>&gt; </prompt>
            <command>sudo crm node online alice</command>
          </screen>
        </step>
      </procedure>
    </section>
    <section role="task" xml:lang="es" version="5.2" xml:id="ha-testing-cluster-failures">
      <info>
        <title xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">Prueba de errores del clúster</title>
        <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
        <abstract xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">
          <para>
        El comando <command>crm cluster crash_test</command> simula fallos de clúster e informa de los resultados.
      </para>
        </abstract>
      </info>
      <para>
    El comando admite las siguientes comprobaciones:
  </para>
      <variablelist>
        <varlistentry>
          <term>
            <option>--split-brain-iptables</option>
          </term>
          <listitem>
            <para>
          Simula una situación de nodos malinformados bloqueando el puerto Corosync y comprueba si se puede aplicar fencing a un nodo como se esperaba. Debe instalar <package>iptables</package> antes de poder ejecutar esta prueba.
        </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term><option>--kill-sbd</option>/<option>--kill-corosync</option>/ <option>--kill-pacemakerd</option></term>
          <listitem>
            <para>
          Interrumpe los daemons de SBD, Corosync o Pacemaker. Después de ejecutar una de estas pruebas, encontrará un informe en el directorio <filename>/var/lib/crmsh/crash_test/</filename>. El informe incluye una descripción del caso de prueba, un registro de acciones y una explicación de los posibles resultados.
        </para>
          </listitem>
        </varlistentry>
        <varlistentry>
          <term>
            <option>--fence-node <replaceable>NODE</replaceable></option>
          </term>
          <listitem>
            <para>
          Delimita el nodo concreto que se ha pasado desde la línea de comandos.
        </para>
          </listitem>
        </varlistentry>
      </variablelist>
      <para>
    Para obtener más información, ejecute el comando <command>crm cluster crash_test --help</command>.
  </para>
      <para>
    En el ejemplo siguiente se usan nodos llamados <systemitem>alice</systemitem> y <systemitem>bob</systemitem>, y se prueba el fencing de <systemitem>bob</systemitem>. Para observar cómo cambia de estado de <systemitem>bob</systemitem> durante la prueba, inicie sesión en Hawk y diríjase a <menuchoice><guimenu>Estado</guimenu><guimenu>Nodos</guimenu></menuchoice>.
  </para>
      <example>
        <title>prueba del clúster: "fencing" de nodo</title>
        <screen><prompt>&gt; </prompt><command>sudo crm status</command>
[...]
Node List:
  * Online: [ alice bob ]

Active Resources:
  * admin-ip     (ocf:heartbeat:IPaddr2):    Started alice

<prompt>&gt; </prompt><command>sudo crm cluster crash_test --fence-node bob</command>

==============================================
Testcase:          Fence node bob
Fence action:      reboot
Fence timeout:     95

!!! WARNING WARNING WARNING !!!
THIS CASE MAY LEAD TO NODE BE FENCED.
TYPE Yes TO CONTINUE, OTHER INPUTS WILL CANCEL THIS CASE [Yes/No](No): <command>Yes</command>
INFO: Trying to fence node "bob"
INFO: Waiting 71s for node "bob" reboot...
INFO: Node "bob" will be fenced by "alice"!
INFO: Node "bob" was successfully fenced by "alice"</screen>
      </example>
    </section>
  </section>
  <section role="glue" xml:lang="es" version="5.2" xml:id="ha-installing-cluster-next-steps">
    <info>
      <title xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">Pasos siguientes</title>
      <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
    </info>
    <para>
    En esta guía se describe un clúster básico de alta disponibilidad que se puede usar con fines de prueba. Para expandir este clúster para su uso en entornos de producción, se recomiendan más pasos:
  </para>
    <variablelist>
      <varlistentry>
        <term>Adición de más nodos</term>
        <listitem>
          <para>
          Añada más nodos al clúster con el guion <command>crm cluster join</command>.
        </para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term>Habilitación de un vigilante de hardware</term>
        <listitem>
          <para>
          Antes de usar este clúster en un entorno de producción, sustituya el <systemitem>softdog</systemitem> con un vigilante de hardware.
        </para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term>Adición de más dispositivos STONITH</term>
        <listitem>
          <para>
          Para cargas de trabajo críticas, se recomienda encarecidamente tener dos o tres dispositivos STONITH, y usar dispositivos STONITH físicos o SBD basados en disco.
        </para>
        </listitem>
      </varlistentry>
      <varlistentry condition="threenode">
        <term>Configuración de QDevice</term>
        <listitem>
          <para>
          QDevice y QNetd participan en las decisiones de quórum. Con la ayuda del arbitro QNetd, QDevice proporciona un número configurable de votos. Esto permite que los clústeres soporten más errores de nodo de los que permiten las reglas de quórum estándar. Se recomienda desplegar QDevice y QNetd en clústeres con un número par de nodos, y especialmente en clústeres de dos nodos.
        </para>
        </listitem>
      </varlistentry>
    </variablelist>
  </section>
  <section version="5.2" xml:id="legal-disclaimer">
    <info>
      <title xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink">Información legal</title>
    </info>
    <para> Copyright© 2006–<?dbtimestamp format="Y"?> SUSE LLC y colaboradores. Reservados todos los derechos. </para>
    <para>
    Está permitido copiar, distribuir y modificar este documento según los términos de la licencia de documentación gratuita GNU, versión 1.2 o (según su criterio) versión 1.3. Esta información de copyright y licencia deberán permanecer inalterados. En la sección titulada <quote>GNU Free Documentation License</quote> (Licencia de documentación gratuita GNU) se incluye una copia de la versión 1.2 de la licencia.
  </para>
    <para>
    Para obtener información sobre las marcas comerciales de SUSE, consulte <link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.suse.com/company/legal/"></link>. Todas las marcas comerciales de otros fabricantes son propiedad de sus respectivas empresas. Los símbolos de marcas comerciales (®, ™, etc.) indican marcas comerciales de SUSE y sus filiales. Los asteriscos (*) indican marcas comerciales de otros fabricantes.
  </para>
    <para>
    Toda la información recogida en esta publicación se ha compilado prestando toda la atención posible al más mínimo detalle. Sin embargo, esto no garantiza una precisión total. Ni SUSE LLC, ni sus filiales, ni los autores o traductores serán responsables de los posibles errores o las consecuencias que de ellos pudieran derivarse.
  </para>
  </section>
  <appendix xmlns:its="http://www.w3.org/2005/11/its" version="5.2" role="legal" its:translate="no" xml:id="doc-gfdl-license">
    <info>
      <title xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink">GNU Free Documentation License</title>
    </info>
    <para>
  Copyright (C) 2000, 2001, 2002 Free Software Foundation, Inc. 51 Franklin St,
  Fifth Floor, Boston, MA 02110-1301 USA. Everyone is permitted to copy and
  distribute verbatim copies of this license document, but changing it is not
  allowed.
 </para>
    <bridgehead renderas="sect4">
    0. PREAMBLE
  </bridgehead>
    <para>
  The purpose of this License is to make a manual, textbook, or other
  functional and useful document "free" in the sense of freedom: to assure
  everyone the effective freedom to copy and redistribute it, with or without
  modifying it, either commercially or non-commercially. Secondarily, this
  License preserves for the author and publisher a way to get credit for their
  work, while not being considered responsible for modifications made by
  others.
 </para>
    <para>
  This License is a kind of "copyleft", which means that derivative works of
  the document must themselves be free in the same sense. It complements the
  GNU General Public License, which is a copyleft license designed for free
  software.
 </para>
    <para>
  We have designed this License to use it for manuals for free software,
  because free software needs free documentation: a free program should come
  with manuals providing the same freedoms that the software does. But this
  License is not limited to software manuals; it can be used for any textual
  work, regardless of subject matter or whether it is published as a printed
  book. We recommend this License principally for works whose purpose is
  instruction or reference.
 </para>
    <bridgehead renderas="sect4">
    1. APPLICABILITY AND DEFINITIONS
  </bridgehead>
    <para>
  This License applies to any manual or other work, in any medium, that
  contains a notice placed by the copyright holder saying it can be distributed
  under the terms of this License. Such a notice grants a world-wide,
  royalty-free license, unlimited in duration, to use that work under the
  conditions stated herein. The "Document", below, refers to any such manual or
  work. Any member of the public is a licensee, and is addressed as "you". You
  accept the license if you copy, modify or distribute the work in a way
  requiring permission under copyright law.
 </para>
    <para>
  A "Modified Version" of the Document means any work containing the Document
  or a portion of it, either copied verbatim, or with modifications and/or
  translated into another language.
 </para>
    <para>
  A "Secondary Section" is a named appendix or a front-matter section of the
  Document that deals exclusively with the relationship of the publishers or
  authors of the Document to the Document's overall subject (or to related
  matters) and contains nothing that could fall directly within that overall
  subject. (Thus, if the Document is in part a textbook of mathematics, a
  Secondary Section may not explain any mathematics.) The relationship could be
  a matter of historical connection with the subject or with related matters,
  or of legal, commercial, philosophical, ethical or political position
  regarding them.
 </para>
    <para>
  The "Invariant Sections" are certain Secondary Sections whose titles are
  designated, as being those of Invariant Sections, in the notice that says
  that the Document is released under this License. If a section does not fit
  the above definition of Secondary then it is not allowed to be designated as
  Invariant. The Document may contain zero Invariant Sections. If the Document
  does not identify any Invariant Sections then there are none.
 </para>
    <para>
  The "Cover Texts" are certain short passages of text that are listed, as
  Front-Cover Texts or Back-Cover Texts, in the notice that says that the
  Document is released under this License. A Front-Cover Text may be at most 5
  words, and a Back-Cover Text may be at most 25 words.
 </para>
    <para>
  A "Transparent" copy of the Document means a machine-readable copy,
  represented in a format whose specification is available to the general
  public, that is suitable for revising the document straightforwardly with
  generic text editors or (for images composed of pixels) generic paint
  programs or (for drawings) some widely available drawing editor, and that is
  suitable for input to text formatters or for automatic translation to a
  variety of formats suitable for input to text formatters. A copy made in an
  otherwise Transparent file format whose markup, or absence of markup, has
  been arranged to thwart or discourage subsequent modification by readers is
  not Transparent. An image format is not Transparent if used for any
  substantial amount of text. A copy that is not "Transparent" is called
  "Opaque".
 </para>
    <para>
  Examples of suitable formats for Transparent copies include plain ASCII
  without markup, Texinfo input format, LaTeX input format, SGML or XML using a
  publicly available DTD, and standard-conforming simple HTML, PostScript or
  PDF designed for human modification. Examples of transparent image formats
  include PNG, XCF and JPG. Opaque formats include proprietary formats that can
  be read and edited only by proprietary word processors, SGML or XML for which
  the DTD and/or processing tools are not generally available, and the
  machine-generated HTML, PostScript or PDF produced by some word processors
  for output purposes only.
 </para>
    <para>
  The "Title Page" means, for a printed book, the title page itself, plus such
  following pages as are needed to hold, legibly, the material this License
  requires to appear in the title page. For works in formats which do not have
  any title page as such, "Title Page" means the text near the most prominent
  appearance of the work's title, preceding the beginning of the body of the
  text.
 </para>
    <para>
  A section "Entitled XYZ" means a named subunit of the Document whose title
  either is precisely XYZ or contains XYZ in parentheses following text that
  translates XYZ in another language. (Here XYZ stands for a specific section
  name mentioned below, such as "Acknowledgements", "Dedications",
  "Endorsements", or "History".) To "Preserve the Title" of such a section when
  you modify the Document means that it remains a section "Entitled XYZ"
  according to this definition.
 </para>
    <para>
  The Document may include Warranty Disclaimers next to the notice which states
  that this License applies to the Document. These Warranty Disclaimers are
  considered to be included by reference in this License, but only as regards
  disclaiming warranties: any other implication that these Warranty Disclaimers
  may have is void and has no effect on the meaning of this License.
 </para>
    <bridgehead renderas="sect4">
    2. VERBATIM COPYING
  </bridgehead>
    <para>
  You may copy and distribute the Document in any medium, either commercially
  or non-commercially, provided that this License, the copyright notices, and
  the license notice saying this License applies to the Document are reproduced
  in all copies, and that you add no other conditions whatsoever to those of
  this License. You may not use technical measures to obstruct or control the
  reading or further copying of the copies you make or distribute. However, you
  may accept compensation in exchange for copies. If you distribute a large
  enough number of copies you must also follow the conditions in section 3.
 </para>
    <para>
  You may also lend copies, under the same conditions stated above, and you may
  publicly display copies.
 </para>
    <bridgehead renderas="sect4">
    3. COPYING IN QUANTITY
  </bridgehead>
    <para>
  If you publish printed copies (or copies in media that commonly have printed
  covers) of the Document, numbering more than 100, and the Document's license
  notice requires Cover Texts, you must enclose the copies in covers that
  carry, clearly and legibly, all these Cover Texts: Front-Cover Texts on the
  front cover, and Back-Cover Texts on the back cover. Both covers must also
  clearly and legibly identify you as the publisher of these copies. The front
  cover must present the full title with all words of the title equally
  prominent and visible. You may add other material on the covers in addition.
  Copying with changes limited to the covers, as long as they preserve the
  title of the Document and satisfy these conditions, can be treated as
  verbatim copying in other respects.
 </para>
    <para>
  If the required texts for either cover are too voluminous to fit legibly, you
  should put the first ones listed (as many as fit reasonably) on the actual
  cover, and continue the rest onto adjacent pages.
 </para>
    <para>
  If you publish or distribute Opaque copies of the Document numbering more
  than 100, you must either include a machine-readable Transparent copy along
  with each Opaque copy, or state in or with each Opaque copy a
  computer-network location from which the general network-using public has
  access to download using public-standard network protocols a complete
  Transparent copy of the Document, free of added material. If you use the
  latter option, you must take reasonably prudent steps, when you begin
  distribution of Opaque copies in quantity, to ensure that this Transparent
  copy will remain thus accessible at the stated location until at least one
  year after the last time you distribute an Opaque copy (directly or through
  your agents or retailers) of that edition to the public.
 </para>
    <para>
  It is requested, but not required, that you contact the authors of the
  Document well before redistributing any large number of copies, to give them
  a chance to provide you with an updated version of the Document.
 </para>
    <bridgehead renderas="sect4">
    4. MODIFICATIONS
  </bridgehead>
    <para>
  You may copy and distribute a Modified Version of the Document under the
  conditions of sections 2 and 3 above, provided that you release the Modified
  Version under precisely this License, with the Modified Version filling the
  role of the Document, thus licensing distribution and modification of the
  Modified Version to whoever possesses a copy of it. In addition, you must do
  these things in the Modified Version:
 </para>
    <orderedlist numeration="upperalpha" spacing="normal">
      <listitem>
        <para>
    Use in the Title Page (and on the covers, if any) a title distinct from
    that of the Document, and from those of previous versions (which should, if
    there were any, be listed in the History section of the Document). You may
    use the same title as a previous version if the original publisher of that
    version gives permission.
   </para>
      </listitem>
      <listitem>
        <para>
    List on the Title Page, as authors, one or more persons or entities
    responsible for authorship of the modifications in the Modified Version,
    together with at least five of the principal authors of the Document (all
    of its principal authors, if it has fewer than five), unless they release
    you from this requirement.
   </para>
      </listitem>
      <listitem>
        <para>
    State on the Title page the name of the publisher of the Modified Version,
    as the publisher.
   </para>
      </listitem>
      <listitem>
        <para>
    Preserve all the copyright notices of the Document.
   </para>
      </listitem>
      <listitem>
        <para>
    Add an appropriate copyright notice for your modifications adjacent to the
    other copyright notices.
   </para>
      </listitem>
      <listitem>
        <para>
    Include, immediately after the copyright notices, a license notice giving
    the public permission to use the Modified Version under the terms of this
    License, in the form shown in the Addendum below.
   </para>
      </listitem>
      <listitem>
        <para>
    Preserve in that license notice the full lists of Invariant Sections and
    required Cover Texts given in the Document's license notice.
   </para>
      </listitem>
      <listitem>
        <para>
    Include an unaltered copy of this License.
   </para>
      </listitem>
      <listitem>
        <para>
    Preserve the section Entitled "History", Preserve its Title, and add to it
    an item stating at least the title, year, new authors, and publisher of the
    Modified Version as given on the Title Page. If there is no section
    Entitled "History" in the Document, create one stating the title, year,
    authors, and publisher of the Document as given on its Title Page, then add
    an item describing the Modified Version as stated in the previous sentence.
   </para>
      </listitem>
      <listitem>
        <para>
    Preserve the network location, if any, given in the Document for public
    access to a Transparent copy of the Document, and likewise the network
    locations given in the Document for previous versions it was based on.
    These may be placed in the "History" section. You may omit a network
    location for a work that was published at least four years before the
    Document itself, or if the original publisher of the version it refers to
    gives permission.
   </para>
      </listitem>
      <listitem>
        <para>
    For any section Entitled "Acknowledgements" or "Dedications", Preserve the
    Title of the section, and preserve in the section all the substance and
    tone of each of the contributor acknowledgements and/or dedications given
    therein.
   </para>
      </listitem>
      <listitem>
        <para>
    Preserve all the Invariant Sections of the Document, unaltered in their
    text and in their titles. Section numbers or the equivalent are not
    considered part of the section titles.
   </para>
      </listitem>
      <listitem>
        <para>
    Delete any section Entitled "Endorsements". Such a section may not be
    included in the Modified Version.
   </para>
      </listitem>
      <listitem>
        <para>
    Do not retitle any existing section to be Entitled "Endorsements" or to
    conflict in title with any Invariant Section.
   </para>
      </listitem>
      <listitem>
        <para>
    Preserve any Warranty Disclaimers.
   </para>
      </listitem>
    </orderedlist>
    <para>
  If the Modified Version includes new front-matter sections or appendices that
  qualify as Secondary Sections and contain no material copied from the
  Document, you may at your option designate some or all of these sections as
  invariant. To do this, add their titles to the list of Invariant Sections in
  the Modified Version's license notice. These titles must be distinct from any
  other section titles.
 </para>
    <para>
  You may add a section Entitled "Endorsements", provided it contains nothing
  but endorsements of your Modified Version by various parties--for example,
  statements of peer review or that the text has been approved by an
  organization as the authoritative definition of a standard.
 </para>
    <para>
  You may add a passage of up to five words as a Front-Cover Text, and a
  passage of up to 25 words as a Back-Cover Text, to the end of the list of
  Cover Texts in the Modified Version. Only one passage of Front-Cover Text and
  one of Back-Cover Text may be added by (or through arrangements made by) any
  one entity. If the Document already includes a cover text for the same cover,
  previously added by you or by arrangement made by the same entity you are
  acting on behalf of, you may not add another; but you may replace the old
  one, on explicit permission from the previous publisher that added the old
  one.
 </para>
    <para>
  The author(s) and publisher(s) of the Document do not by this License give
  permission to use their names for publicity for or to assert or imply
  endorsement of any Modified Version.
 </para>
    <bridgehead renderas="sect4">
    5. COMBINING DOCUMENTS
  </bridgehead>
    <para>
  You may combine the Document with other documents released under this
  License, under the terms defined in section 4 above for modified versions,
  provided that you include in the combination all of the Invariant Sections of
  all of the original documents, unmodified, and list them all as Invariant
  Sections of your combined work in its license notice, and that you preserve
  all their Warranty Disclaimers.
 </para>
    <para>
  The combined work need only contain one copy of this License, and multiple
  identical Invariant Sections may be replaced with a single copy. If there are
  multiple Invariant Sections with the same name but different contents, make
  the title of each such section unique by adding at the end of it, in
  parentheses, the name of the original author or publisher of that section if
  known, or else a unique number. Make the same adjustment to the section
  titles in the list of Invariant Sections in the license notice of the
  combined work.
 </para>
    <para>
  In the combination, you must combine any sections Entitled "History" in the
  various original documents, forming one section Entitled "History"; likewise
  combine any sections Entitled "Acknowledgements", and any sections Entitled
  "Dedications". You must delete all sections Entitled "Endorsements".
 </para>
    <bridgehead renderas="sect4">
    6. COLLECTIONS OF DOCUMENTS
  </bridgehead>
    <para>
  You may make a collection consisting of the Document and other documents
  released under this License, and replace the individual copies of this
  License in the various documents with a single copy that is included in the
  collection, provided that you follow the rules of this License for verbatim
  copying of each of the documents in all other respects.
 </para>
    <para>
  You may extract a single document from such a collection, and distribute it
  individually under this License, provided you insert a copy of this License
  into the extracted document, and follow this License in all other respects
  regarding verbatim copying of that document.
 </para>
    <bridgehead renderas="sect4">
    7. AGGREGATION WITH INDEPENDENT WORKS
  </bridgehead>
    <para>
  A compilation of the Document or its derivatives with other separate and
  independent documents or works, in or on a volume of a storage or
  distribution medium, is called an "aggregate" if the copyright resulting from
  the compilation is not used to limit the legal rights of the compilation's
  users beyond what the individual works permit. When the Document is included
  in an aggregate, this License does not apply to the other works in the
  aggregate which are not themselves derivative works of the Document.
 </para>
    <para>
  If the Cover Text requirement of section 3 is applicable to these copies of
  the Document, then if the Document is less than one half of the entire
  aggregate, the Document's Cover Texts may be placed on covers that bracket
  the Document within the aggregate, or the electronic equivalent of covers if
  the Document is in electronic form. Otherwise they must appear on printed
  covers that bracket the whole aggregate.
 </para>
    <bridgehead renderas="sect4">
    8. TRANSLATION
  </bridgehead>
    <para>
  Translation is considered a kind of modification, so you may distribute
  translations of the Document under the terms of section 4. Replacing
  Invariant Sections with translations requires special permission from their
  copyright holders, but you may include translations of some or all Invariant
  Sections in addition to the original versions of these Invariant Sections.
  You may include a translation of this License, and all the license notices in
  the Document, and any Warranty Disclaimers, provided that you also include
  the original English version of this License and the original versions of
  those notices and disclaimers. In case of a disagreement between the
  translation and the original version of this License or a notice or
  disclaimer, the original version will prevail.
 </para>
    <para>
  If a section in the Document is Entitled "Acknowledgements", "Dedications",
  or "History", the requirement (section 4) to Preserve its Title (section 1)
  will typically require changing the actual title.
 </para>
    <bridgehead renderas="sect4">
    9. TERMINATION
  </bridgehead>
    <para>
  You may not copy, modify, sublicense, or distribute the Document except as
  expressly provided for under this License. Any other attempt to copy, modify,
  sublicense or distribute the Document is void, and will automatically
  terminate your rights under this License. However, parties who have received
  copies, or rights, from you under this License will not have their licenses
  terminated so long as such parties remain in full compliance.
 </para>
    <bridgehead renderas="sect4">
    10. FUTURE REVISIONS OF THIS LICENSE
  </bridgehead>
    <para>
  The Free Software Foundation may publish new, revised versions of the GNU
  Free Documentation License from time to time. Such new versions will be
  similar in spirit to the present version, but may differ in detail to address
  new problems or concerns. See
  <link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.gnu.org/copyleft/"></link>.
 </para>
    <para>
  Each version of the License is given a distinguishing version number. If the
  Document specifies that a particular numbered version of this License "or any
  later version" applies to it, you have the option of following the terms and
  conditions either of that specified version or of any later version that has
  been published (not as a draft) by the Free Software Foundation. If the
  Document does not specify a version number of this License, you may choose
  any version ever published (not as a draft) by the Free Software Foundation.
 </para>
    <bridgehead renderas="sect4">
    ADDENDUM: How to use this License for your documents
  </bridgehead>
    <screen>Copyright (c) YEAR YOUR NAME.
Permission is granted to copy, distribute and/or modify this document
under the terms of the GNU Free Documentation License, Version 1.2
or any later version published by the Free Software Foundation;
with no Invariant Sections, no Front-Cover Texts, and no Back-Cover Texts.
A copy of the license is included in the section entitled “GNU
Free Documentation License”.</screen>
    <para>
  If you have Invariant Sections, Front-Cover Texts and Back-Cover Texts,
  replace the &#x201C;with...Texts.&#x201D; line with this:
 </para>
    <screen>with the Invariant Sections being LIST THEIR TITLES, with the
Front-Cover Texts being LIST, and with the Back-Cover Texts being LIST.</screen>
    <para>
  If you have Invariant Sections without Cover Texts, or some other combination
  of the three, merge those two alternatives to suit the situation.
 </para>
    <para>
  If your document contains nontrivial examples of program code, we recommend
  releasing these examples in parallel under your choice of free software
  license, such as the GNU General Public License, to permit their use in free
  software.
</para>
  </appendix>
  <glossary role="reference" xml:lang="es" version="5.2" xml:id="ha-glossary">
    <info>
      <title xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion">Glosario de HA (alta disponibilidad)</title>
      <meta xmlns:its="http://www.w3.org/2005/11/its" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:trans="http://docbook.org/ns/transclusion" name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
    </info>
    <glossentry>
      <glossterm>activo/activo y activo/pasivo</glossterm>
      <glossdef>
        <para>
      Cómo se ejecutan los recursos en los nodos. Activo/pasivo significa que los recursos solo se ejecutan en el nodo activo, pero pueden moverse al nodo pasivo si se produce un error en el nodo activo. Activo/activo significa que todos los nodos están activos a la vez y los recursos pueden ejecutarse en (y moverse a) cualquier nodo del clúster.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-arbitrator">
      <glossterm>árbitro</glossterm>
      <glossdef>
        <para>
      Un <emphasis>árbitro</emphasis> es una máquina que se ejecuta fuera del clúster para proporcionar una instancia adicional para los cálculos del clúster. Por ejemplo, <xref linkend="gloss-qnetd"/> proporciona un voto para ayudar a <xref linkend="gloss-qdevice"/> a participar en las decisiones de <xref linkend="gloss-quorum"/>.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>CIB (base de información del clúster)</glossterm>
      <glossdef>
        <para>
      Una representación XML de toda la configuración y el estado del clúster (opciones del clúster, nodos, recursos, restricciones y las relaciones entre sí). El gestor de CIB (<systemitem>pacemaker-based</systemitem>) mantiene el CIB sincronizado en todo el clúster y gestiona las solicitudes para modificarlo.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-clone">
      <glossterm>clon</glossterm>
      <glossdef>
        <para>
      Un <emphasis>clon</emphasis> es una copia idéntica de un nodo existente, que se utiliza para simplificar el despliegue de varios nodos.
    </para>
        <para>
      En el contexto de un <xref linkend="gloss-resource"/> de clúster, un clon es un recurso que puede estar activo en varios nodos. Cualquier recurso se puede clonar si su agente de recursos lo admite.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>clúster</glossterm>
      <glossdef>
        <para>
      Un clúster de <emphasis>alta disponibilidad</emphasis> es un grupo de servidores (físicos o virtuales) diseñados principalmente para asegurar la mayor disponibilidad posible de los datos, las aplicaciones y los servicios. No debe confundirse con un clúster <emphasis>de alto rendimiento</emphasis>, que comparte la carga de la aplicación para lograr resultados más rápidos.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>gestor de volúmenes lógicos del clúster (LVM del clúster)</glossterm>
      <glossdef>
        <para>
      El término <emphasis>LVM del clúster</emphasis> indica que se está usando gestión de volúmenes lógicos en un entorno de clústeres. Esto requiere ajustes de configuración para proteger los metadatos de LVM en el almacenamiento compartido.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-clus-part">
      <glossterm>partición del clúster</glossterm>
      <glossdef>
        <para>
      Una partición del clúster se produce cuando hay un error en la comunicación entre uno o varios nodos y el resto del clúster. Los nodos se dividen en particiones pero siguen activos. Solo pueden comunicarse con nodos de la misma partición y no reconocen los nodos de otras particiones. Esto se conoce como una situación de <xref linkend="gloss-splitbrain"/>.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>pila de clúster</glossterm>
      <glossdef>
        <para>
      El conjunto de tecnologías de software y componentes que componen un clúster.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-col-con">
      <glossterm>restricción de colocación</glossterm>
      <glossdef>
        <para>
      Un tipo de <xref linkend="gloss-resource-con"/> que especifica qué recursos pueden o no ejecutarse juntos en un nodo.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>infracción de simultaneidad</glossterm>
      <glossdef>
        <para>
      Un recurso que debería ejecutarse solo en un nodo del clúster se ejecuta en varios nodos.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-corosync">
      <glossterm>Corosync</glossterm>
      <glossdef>
        <para>
      Corosync proporciona un sistema confiable de mensajería, pertenencia a grupos y quórum sobre el clúster. Esa información se gestiona mediante Corosync Cluster Engine, un sistema de comunicación grupal.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-crm">
      <glossterm>CRM (gestor de recursos del clúster)</glossterm>
      <glossdef>
        <para>
      La entidad de gestión responsable de coordinar todas las interacciones no locales en un clúster de alta disponibilidad. SUSE Linux Enterprise High Availability usa <xref linkend="gloss-pacemaker"/> como CRM. Interactúa con varios componentes: ejecutores locales en su propio nodo y en los otros nodos, CRM no locales, comandos administrativos, la funcionalidad de fencing y la capa de pertenencia a grupos.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm><systemitem>crmsh</systemitem> (shell CRM)</glossterm>
      <glossdef>
        <para>
      La utilidad de línea de comandos <emphasis><systemitem>crmsh</systemitem></emphasis> gestiona el clúster, los nodos y los recursos.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Csync2</glossterm>
      <glossdef>
        <para>
      Una herramienta de sincronización para replicar archivos de configuración en todos los nodos del clúster.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-dc">
      <glossterm>DC (coordinador designado)</glossterm>
      <glossdef>
        <para>
      El daemon <systemitem>pacemaker-controld</systemitem> es el controlador del clúster, que coordina todas las acciones. Este daemon tiene una instancia en cada nodo del clúster, pero solo se elige una instancia para que actúe como coordinador designado. El coordinador designado se elige cuando se inician los servicios de clúster, o si el coordinador designado falla o abandona el clúster. El coordinador designado decide si se debe realizar un cambio en todo el clúster, como aplicar fencing en un nodo o mover recursos.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>desastre</glossterm>
      <glossdef>
        <para>
      Una interrupción inesperada de la infraestructura crítica causada por la naturaleza, acción humana, fallos de hardware o errores de software.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-dis-rec">
      <glossterm>recuperación tras desastre</glossterm>
      <glossdef>
        <para>
      El proceso por el cual una función se restaura al estado normal y estable después de un desastre.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>plan de recuperación tras desastre</glossterm>
      <glossdef>
        <para>
      Una estrategia para recuperarse de un desastre con el mínimo impacto en la infraestructura de TI.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>DLM (gestor de bloqueo distribuido)</glossterm>
      <glossdef>
        <para>
      El gestor de bloqueo distribuido coordina los accesos a los recursos compartidos de un clúster, por ejemplo, administrando el bloqueo de archivos en sistemas de archivos en clúster para aumentar el rendimiento y la disponibilidad.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-drbd">
      <glossterm>DRBD</glossterm>
      <glossdef>
        <para><trademark class="registered">DRBD</trademark> es un dispositivo de bloques diseñado para crear clústeres de alta disponibilidad. Replica los datos de un dispositivo primario en dispositivos secundarios de una manera que garantiza que todas las copias de los datos permanezcan idénticas.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>clúster existente</glossterm>
      <glossdef>
        <para>
      El término <emphasis>clúster existente</emphasis> se utiliza para hacer referencia a cualquier clúster que conste de al menos un nodo. Un clúster existente tiene una configuración de <xref linkend="gloss-corosync"/> básica que define los canales de comunicación, pero que aún no tiene necesariamente una configuración de recursos.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="glo-failover">
      <glossterm>failover</glossterm>
      <glossdef>
        <para>
      Se produce cuando hay un error en un recurso o nodo en un equipo y los recursos afectados se mueven a otro nodo.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>dominio de failover</glossterm>
      <glossdef>
        <para>
      Un subconjunto con nombre de nodos de clúster que son aptos para ejecutar un recurso si se produce un error en un nodo.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-fencing">
      <glossterm>fencing</glossterm>
      <glossdef>
        <para>
      Una técnica que impide el acceso a un recurso compartido por parte de miembros del clúster aislados o con errores. Hay dos clases de fencing: de <emphasis>nivel de recursos</emphasis> y de <emphasis>nivel de nodo</emphasis>. El fencing de nivel de recursos garantiza el acceso exclusivo a un recurso. El de nivel de nodo evita que un nodo fallido acceda a los recursos compartidos y evita que los recursos se ejecuten en un nodo con un estado incierto. Esto generalmente se hace reiniciando o apagando el nodo.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>GFS2</glossterm>
      <glossdef>
        <para>
      Global File System 2 (GFS2, sistema de archivos global 2) es un sistema de archivos de disco compartido para clústeres de equipos Linux. GFS2 permite que todos los nodos tengan acceso directo y simultáneo al mismo almacenamiento en bloques compartido. GFS2 no tiene modo de funcionamiento sin conexión ni roles de cliente o servidor. Todos los nodos de un clúster GFS2 funcionan como pares. GFS2 admite hasta 32 nodos de clúster El uso de GFS2 en un clúster requiere hardware para permitir el acceso al almacenamiento compartido y un gestor de bloqueo para controlar el acceso al almacenamiento.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>grupo</glossterm>
      <glossdef>
        <para>
      Los grupos de recursos contienen varios recursos que deben ubicarse juntos, iniciarse secuencialmente y detenerse en orden inverso.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>Hawk (HA Web Konsole)</glossterm>
      <glossdef>
        <para>
      Una interfaz basada en Web fácil de usar para supervisar y administrar un clúster de alta disponibilidad desde equipos Linux o no Linux. Se puede acceder a Hawk desde cualquier equipo que pueda conectarse a los nodos del clúster utilizando un navegador Web gráfico.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-heuristics">
      <glossterm>heurística</glossterm>
      <glossdef>
        <para><xref linkend="gloss-qdevice"/> admite el uso de un conjunto de comandos (<emphasis>heurística</emphasis>) que se ejecutan localmente al iniciar los servicios de clúster, el cambio de pertenencia al clúster, la conexión correcta al servidor <xref linkend="gloss-qnetd"/> o, opcionalmente, de forma periódica. El resultado se usa en los cálculos para determinar qué partición debe tener <xref linkend="gloss-quorum"/>.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>knet (kronosnet)</glossterm>
      <glossdef>
        <para>
      Una capa de abstracción de red que admite redundancia, seguridad, tolerancia a fallos y failover rápido de los enlaces de red. En SUSE Linux Enterprise High Availability 16, <emphasis>knet</emphasis> es el protocolo de transporte por defecto para los canales de comunicación de <xref linkend="gloss-corosync"/>.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>clúster local</glossterm>
      <glossdef>
        <para>
      Un único clúster en una ubicación (por ejemplo, todos los nodos se encuentran en un centro de datos). La latencia de red es mínima. Normalmente, todos los nodos acceden al almacenamiento de forma sincrónica.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>ejecutor local</glossterm>
      <glossdef>
        <para>
      El ejecutor local se encuentra entre <xref linkend="gloss-pacemaker"/> y los recursos de cada nodo. Mediante el daemon <systemitem class="daemon">pacemaker-execd</systemitem>, Pacemaker puede iniciar, detener y supervisar recursos.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>ubicación</glossterm>
      <glossdef>
        <para>
      En el contexto de un clúster completo, la <emphasis>ubicación</emphasis> hace referencia a la localización física de los nodos (por ejemplo, todos los nodos pueden estar ubicados en el mismo centro de datos). En el contexto de <xref linkend="gloss-loc-con"/>, una <emphasis>ubicación</emphasis> son los nodos en los que se puede ejecutar o no un recurso.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-loc-con">
      <glossterm>restricción de ubicación</glossterm>
      <glossdef>
        <para>
      Un tipo de <xref linkend="gloss-resource-con"/> que define los nodos en los que se puede ejecutar o no un recurso.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>atributos meta (opciones de recursos)</glossterm>
      <glossdef>
        <para>
      Los parámetros que indican a <xref linkend="gloss-crm"/> cómo tratar un <xref linkend="gloss-resource"/> específico. Por ejemplo, puede definir la prioridad o el rol de destino de un recurso.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>clúster metro</glossterm>
      <glossdef>
        <para>
      Un único clúster que puede extenderse por varios edificios o centros de datos, con todos los sitios conectados mediante Fibre Channel. La latencia de red suele ser baja. El almacenamiento se replica con frecuencia mediante la duplicación o la réplica sincrónica.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>vínculo de dispositivos de red</glossterm>
      <glossdef>
        <para>
      En la combinación de dispositivos de red se combinan dos o más interfaces de red en un solo dispositivo vinculado para aumentar el ancho de banda o proporcionar redundancia. Al usar <xref linkend="gloss-corosync"/>, el software del clúster no gestiona el dispositivo vinculado. Por lo tanto, el dispositivo vinculado debe configurarse en cada nodo de clúster que pueda necesitar acceder a él.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>nodo</glossterm>
      <glossdef>
        <para>
      Cualquier servidor (físico o virtual) que sea miembro de un clúster.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-ord-con">
      <glossterm>restricción de rango</glossterm>
      <glossdef>
        <para>
      Un tipo de <xref linkend="gloss-resource-con"/> que define la secuencia de acciones.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-pacemaker">
      <glossterm>Pacemaker</glossterm>
      <glossdef>
        <para>
      Pacemaker es el <xref linkend="gloss-crm"/> en SUSE Linux Enterprise High Availability, o el <quote>cerebro</quote> que reacciona a los eventos que ocurren en el clúster. Los eventos pueden ser nodos que se unen o abandonan el clúster, fallos de recursos o actividades programadas como el mantenimiento, por ejemplo. El daemon <systemitem>pacemakerd</systemitem> inicia y supervisa todos los demás daemons relacionados.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>parámetros (atributos de instancia)</glossterm>
      <glossdef>
        <para>
      Los parámetros determinan qué instancia de un servicio controla el <xref linkend="gloss-resource"/>.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>programador</glossterm>
      <glossdef>
        <para>
      El programador se implementa como <systemitem class="daemon">pacemaker-schedulerd</systemitem>. Cuando se necesita una transición de clúster, <systemitem class="daemon">pacemaker-schedulerd</systemitem> calcula el siguiente estado esperado del clúster y determina qué acciones deben programarse para lograr el siguiente estado.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>primitivo</glossterm>
      <glossdef>
        <para>
      Un recurso primitivo es el tipo más básico de recurso de clúster.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-prom-clone">
      <glossterm>clon promocionable</glossterm>
      <glossdef>
        <para>
      Los clones promocionables son un tipo especial de recurso de <xref linkend="gloss-clone"/> que se puede promocionar. Las instancias activas de estos recursos se dividen en dos estados: promocionado y no promocionado (también conocidos como <quote>activo y pasivo</quote> o <quote>primario y secundario</quote>).
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-qdevice">
      <glossterm>QDevice</glossterm>
      <glossdef>
        <para>
      QDevice y <xref linkend="gloss-qnetd"/> participan en las decisiones de <xref linkend="gloss-quorum"/>. El daemon <systemitem>corosync-qdevice</systemitem> se ejecuta en cada nodo del clúster y se comunica con QNetd para proporcionar un número configurable de votos, lo que permite que un clúster mantenga más fallos de nodo de los que permiten las reglas de quórum estándar.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-qnetd">
      <glossterm>QNetd</glossterm>
      <glossdef>
        <para>
      QNetd es un <xref linkend="gloss-arbitrator"/> que se ejecuta fuera del clúster. El daemon <systemitem>corosync-qnetd</systemitem> proporciona un voto al daemon <systemitem>corosync-qdevice</systemitem> en cada nodo para ayudarlo a participar en las decisiones de quórum.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-quorum">
      <glossterm>quórum</glossterm>
      <glossdef>
        <para>
      Se define que una <xref linkend="gloss-clus-part"/> <emphasis>tiene quórum</emphasis> si tiene la mayoría de los nodos (o de los <quote>votos</quote>). El quórum distingue exactamente una partición. Esto es parte del algoritmo para evitar que haya varias particiones o nodos desconectados (<quote>malinformados</quote>) y se produzcan daños en los datos y servicios. El quórum es un requisito previo para el fencing, que a su vez garantiza que el quórum sea único.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>RA (agente de recursos)</glossterm>
      <glossdef>
        <para>
      Un guion que actúa como proxy para gestionar un <xref linkend="gloss-resource"/> (por ejemplo, para iniciar, detener o supervisar un recurso). SUSE Linux Enterprise High Availability admite diferentes tipos de agentes de recursos.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>ReaR (Relax and Recover)</glossterm>
      <glossdef>
        <para>
      Un conjunto de herramientas de administrador para crear imágenes de <xref linkend="gloss-dis-rec"/>.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-resource">
      <glossterm>recurso</glossterm>
      <glossdef>
        <para>
      Cualquier tipo de servicio o aplicación que <xref linkend="gloss-pacemaker"/> conozca; por ejemplo, una dirección IP, un sistema de archivos o una base de datos. El término <emphasis>recurso</emphasis> también se utiliza en <xref linkend="gloss-drbd"/>, donde nombra un conjunto de dispositivos de bloque que usan una conexión común para la réplica.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-resource-con">
      <glossterm>restricción de recursos</glossterm>
      <glossdef>
        <para>
      Las restricciones de recursos especifican en qué nodos del clúster se pueden ejecutar los recursos, en qué orden se cargan los recursos y de qué otros recursos depende un recurso específico.
    </para>
        <para>
      Consulte también <xref linkend="gloss-col-con"/>, <xref linkend="gloss-loc-con"/> y <xref linkend="gloss-ord-con"/>.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>conjunto de recursos</glossterm>
      <glossdef>
        <para>
      Como formato alternativo para definir restricciones de ubicación, colocación o rango, puede usar <emphasis>conjuntos de recursos</emphasis>, donde los recursos primitivos se agrupan en un conjunto. Al crear una restricción, puede especificar varios recursos a los que se aplicará la restricción.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>plantilla de recurso</glossterm>
      <glossdef>
        <para>
      Para ayudar a crear muchos recursos con configuraciones similares, puede definir una plantilla de recurso. Una vez definida, se puede hacer referencia a la plantilla en los recursos primitivos o en ciertos tipos de restricciones. Si se hace referencia a una plantilla en un recurso primitivo, este hereda todas las operaciones, los atributos de instancia (parámetros), los metaatributos y los atributos de utilización definidos en la plantilla.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-sbd">
      <glossterm>SBD (dispositivo de bloques STONITH)</glossterm>
      <glossdef>
        <para>
      SBD proporciona un mecanismo de <xref linkend="gloss-fencing"/> de nodos mediante el intercambio de mensajes a través del almacenamiento en bloques compartido. Como alternativa, se puede usar en modo sin disco. En cualquier caso, necesita un <xref linkend="gloss-watchdog"/> de hardware o software en cada nodo para garantizar que los nodos que se comportan mal se detengan.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-splitbrain">
      <glossterm>nodo malinformado</glossterm>
      <glossdef>
        <para>
      Una situación en la que los nodos del clúster se dividen en dos o más grupos que no se reconocen entre sí (ya sea por un error de software o de hardware). <xref linkend="gloss-stonith"/> evita que un escenario de este tipo afecte gravemente a todo el clúster. También se conoce como <emphasis>clúster particionado</emphasis>.
    </para>
        <para>
      El término <emphasis>nodo malinformado</emphasis> también se utiliza en <xref linkend="gloss-drbd"/>, pero significa que los nodos contienen datos diferentes.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>punto único de fallo</glossterm>
      <glossdef>
        <para>
      Cualquier componente de un clúster que, si falla, desencadena que todo el clúster falle.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-stonith">
      <glossterm>STONITH</glossterm>
      <glossdef>
        <para>
      Un acrónimo en inglés de <emphasis>interrumpir completamente el otro nodo</emphasis>. Se refiere al mecanismo de <xref linkend="gloss-fencing"/> que apaga un nodo que se comporta mal para evitar que cause problemas en un clúster. En un clúster de <xref linkend="gloss-pacemaker"/>, STONITH se gestiona con el subsistema de fencing <systemitem>pacemaker-fenced</systemitem>.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>switchover</glossterm>
      <glossdef>
        <para>
      El traslado planeado de recursos a otros nodos de un clúster. Consulte también <xref linkend="glo-failover"/>.
    </para>
      </glossdef>
    </glossentry>
    <glossentry>
      <glossterm>utilización</glossterm>
      <glossdef>
        <para>
      Indica al gestor de recursos del clúster qué capacidad debe tener un <xref linkend="gloss-resource"/> concreto de un nodo.
    </para>
      </glossdef>
    </glossentry>
    <glossentry xml:id="gloss-watchdog">
      <glossterm>vigilante (watchdog)</glossterm>
      <glossdef>
        <para><xref linkend="gloss-sbd"/> necesita un vigilante en cada nodo para garantizar que los nodos que se comportan mal se detengan. SBD <quote>alimenta</quote> al vigilante escribiéndole regularmente un pulso de servicio. Si SBD deja de alimentar al vigilante, el hardware exige un reinicio del sistema. Esto protege contra fallos del proceso SBD en sí, como que se quede atascado en un error de E/S.
    </para>
      </glossdef>
    </glossentry>
  </glossary>
</article>
