<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE glossary
[
  <!ENTITY % entities SYSTEM "../common/generic-entities.ent">
    %entities;
]>
<glossary version="5.2" xml:lang="en"
          xmlns:xlink="http://www.w3.org/1999/xlink"
          xmlns:trans="http://docbook.org/ns/transclusion"
          xmlns:its="http://www.w3.org/2005/11/its"
          xmlns:xi="http://www.w3.org/2001/XInclude"
          xmlns="http://docbook.org/ns/docbook">
  <title>Glossary</title>
  <glossentry xml:id="gt-air-gapped"><glossterm>Air gap</glossterm>
    <glossdef>
      <para>
        A security measure where a computer network is physically isolated from
        unsecured networks, including the public Internet.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-ai"><glossterm>AI, artificial intelligence</glossterm>
    <glossdef>
      <para>
        Refers to the simulation of human intelligence in machines that are
        designed to learn and solve problems like humans. Enables computers to
        understand language, make decisions and improve from experience.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-batch-size"><glossterm>Batch size</glossterm>
    <glossdef>
      <para>
        The number of samples processed simultaneously during model inference,
        affecting processing speed and resource utilization.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-byo"><glossterm>BYOC, bring your own certificate</glossterm>
    <glossdef>
      <para>
        A practice allowing users to provide their own SSL/TLS certificates for
        securing communications instead of using default or auto-generated ones.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-ca"><glossterm>CA, certification authority</glossterm>
    <glossdef>
      <para>
        An entity that issues digital certificates to verify the identity of
        certificate holders and ensure secure communications.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-chat-template"><glossterm>Chat template</glossterm>
    <glossdef>
      <para>
        A structured format for organizing conversations between users and AI
        models, defining how system prompts, user inputs, and AI responses are
        formatted and processed.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-context-window"><glossterm>Context window</glossterm>
    <glossdef>
      <para>
        The maximum amount of text (tokens) that an AI model can process at
        once, including both the input prompt and generated response.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-cot"><glossterm>Chain-of-thought (CoT) prompting</glossterm>
    <glossdef>
      <para>
        A prompting technique that guides AI models to break down complex
        problems into step-by-step reasoning processes, improving response
        accuracy and transparency.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-crd"><glossterm>CRD, custom resource definitions</glossterm>
    <glossdef>
      <para>
        Extensions of the Kubernetes API that allow users to define custom
        resources and their controllers in a Kubernetes cluster.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-cuda"><glossterm>CUDA, Compute Unified Device Architecture</glossterm>
    <glossdef>
      <para>
        &nvidia;'s parallel computing platform and programming model used to
        accelerate AI workloads on GPU hardware.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-data-leakage"><glossterm>Data leakage</glossterm>
    <glossdef>
      <para>
        The unintended exposure of sensitive information through AI model
        responses, potentially compromising data security and privacy.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-embeddings"><glossterm>Embeddings</glossterm>
    <glossdef>
      <para>
        Numerical representations of data (text, images, etc.) in a
        high-dimensional space that capture semantic relationships and enable AI
        models to process information effectively.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-fine-tuning"><glossterm>Fine-tuning</glossterm>
    <glossdef>
      <para>
        The process of further training a pre-trained AI model on specific data
        to adapt it for particular tasks or domains, improving its performance
        for targeted applications.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-genai"><glossterm>GenAI, generative AI</glossterm>
    <glossdef>
      <para>
        A type of artificial intelligence that can create new content such as
        text, images or music.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-gpu"><glossterm>GPU, graphics processing unit</glossterm>
    <glossdef>
      <para>
        Specialized hardware designed for parallel processing. In AI
        applications, GPUs accelerate model training and inference tasks.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-hallucination"><glossterm>Hallucination</glossterm>
    <glossdef>
      <para>
        An AI behavior where the model generates false or unsupported
        information that appears plausible but has no basis in provided context
        or real facts.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-helm"><glossterm>&helm;</glossterm>
    <glossdef>
      <para>
        A package manager for Kubernetes that helps install and manage
        applications. &helm; uses charts to define, install and upgrade complex
        Kubernetes applications.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-helm-chart"><glossterm>&helm; chart</glossterm>
    <glossdef>
      <para>
        A package format for Kubernetes applications that contains all resource
        definitions needed to deploy and configure application workloads.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-iac"><glossterm>IaC, infrastructure as code</glossterm>
    <glossdef>
      <para>
        The practice of managing and provisioning infrastructure through
        machine-readable definition files rather than manual processes.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-inference"><glossterm>Inference</glossterm>
    <glossdef>
      <para>
        The process of using a trained AI model to make predictions or generate
        outputs based on new input data.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-kubernetes-pods"><glossterm>&kube; pods</glossterm>
    <glossdef>
      <para>
        The smallest deployable units in Kubernetes that can host one or more
        containers, sharing networking and storage resources.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-llm"><glossterm>LLM, large language model</glossterm>
    <glossdef>
      <para>
        An advanced AI model trained on amounts of text data to understand and
        generate human-like text. Can perform tasks like translation,
        summarization and answering questions.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-model-weights"><glossterm>Model weights</glossterm>
    <glossdef>
      <para>
        The learned parameters of an AI model that determine how it processes
        inputs and generates outputs. These weights are adjusted during training
        to optimize model performance.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-nlg"><glossterm>NLG, natural language generation</glossterm>
    <glossdef>
      <para>
        A process of automatically generating human-like text from structured
        data or other forms of input. Designed to convert raw data into coherent
        and meaningful language easily understood by humans.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-nlu"><glossterm>NLU, natural language understanding</glossterm>
    <glossdef>
      <para>
        A process AI uses to analyze and understand the meaning of the input
        query.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-nvidia-gpu-driver"><glossterm>&nvidia; GPU driver</glossterm>
    <glossdef>
      <para>
        Software that enables communication between the operating system and
        &nvidia; graphics hardware, essential for GPU-accelerated AI workloads.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-nvidia-gpu-operator"><glossterm>&nvoperator;</glossterm>
    <glossdef>
      <para>
        A Kubernetes operator that automates the management of &nvidia; GPUs in
        container environments, handling driver deployment, runtime
        configuration, and monitoring.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-ollama"><glossterm>&ollama;</glossterm>
    <glossdef>
      <para>
        An open source framework for running and serving AI models locally.
        &ollama; simplifies the process of downloading, running and managing
        large language models.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-opengl"><glossterm>OpenGL</glossterm>
    <glossdef>
      <para>
        A cross-platform API for rendering 2D and 3D graphics, commonly used in
        visualization applications and GPU-accelerated computing.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-prompt-engineering"><glossterm>Prompt Engineering</glossterm>
    <glossdef>
      <para>
        The practice of crafting effective input queries to AI models to obtain
        desired and accurate outputs. Good prompt engineering helps prevent
        hallucinations and improves response quality.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-prompt-injection"><glossterm>Prompt injection</glossterm>
    <glossdef>
      <para>
        A security vulnerability where malicious inputs attempt to override or
        bypass an AI model's system prompt or safety constraints.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-quantization"><glossterm>Quantization</glossterm>
    <glossdef>
      <para>
        A technique to reduce AI model size and computational requirements by
        converting model parameters to lower precision formats while maintaining
        acceptable performance.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-rag"><glossterm>RAG, retrieval-augmented generation</glossterm>
    <glossdef>
      <para>
        A technique that enhances AI responses by retrieving relevant
        information from a knowledge base before generating answers, improving
        accuracy and reducing hallucinations.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-rbac"><glossterm>RBAC, role-based access control</glossterm>
    <glossdef>
      <para>
        A security model that restricts system access based on roles assigned to
        users, managing permissions and authorization in Kubernetes clusters.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-semantic-search"><glossterm>Semantic search</glossterm>
    <glossdef>
      <para>
        A search method using AI to understand the meaning and context of
        queries rather than just matching keywords, enabling more relevant
        results.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-system-prompt"><glossterm>System prompt</glossterm>
    <glossdef>
      <para>
        Initial instructions given to an AI model that define its behavior, role
        and response parameters. System prompts help maintain consistent and
        appropriate AI responses.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-temperature"><glossterm>Temperature</glossterm>
    <glossdef>
      <para>
        A parameter controlling the randomness in AI model outputs. Lower values
        produce more focused and deterministic responses, while higher values
        increase creativity and variability.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-token"><glossterm>Token</glossterm>
    <glossdef>
      <para>
        The basic unit of text processing in AI models, representing parts of
        words, characters or symbols. Models process text by breaking it into
        tokens for analysis and generation.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-top-k"><glossterm>Top-K</glossterm>
    <glossdef>
      <para>
        A parameter that limits token selection during text generation to the K
        most likely next tokens, helping control output quality and relevance.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-top-p"><glossterm>Top-P</glossterm>
    <glossdef>
      <para>
        Also known as nucleus sampling, a parameter that selects from the
        smallest set of tokens whose cumulative probability exceeds P, providing
        dynamic control over text generation diversity.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-vector-db"><glossterm>Vector database</glossterm>
    <glossdef>
      <para>
        A specialized database designed to store and efficiently query
        high-dimensional vectors that represent data in AI applications,
        enabling similarity searches and semantic operations.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-vector-store"><glossterm>Vector store</glossterm>
    <glossdef>
      <para>
        A specialized storage system optimized for managing and querying vector
        embeddings, essential for semantic search and RAG implementations in AI
        applications.
      </para>
    </glossdef>
  </glossentry>
</glossary>
