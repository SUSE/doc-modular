<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE glossary
[
  <!ENTITY % entities SYSTEM "../common/generic-entities.ent">
    %entities;
]>
<glossary version="5.2" xml:lang="en"
          xmlns:xlink="http://www.w3.org/1999/xlink"
          xmlns:trans="http://docbook.org/ns/transclusion"
          xmlns:its="http://www.w3.org/2005/11/its"
          xmlns:xi="http://www.w3.org/2001/XInclude"
          xmlns="http://docbook.org/ns/docbook">
  <title>Glossary</title>
  <glossentry xml:id="gt-ai"><glossterm>AI</glossterm>
    <glossdef>
      <para>
        <emphasis>Artificial Intelligence</emphasis> (AI) refers to the
        simulation of human intelligence in machines that are designed to learn
        and solve problems like humans. AI enables computers to understand
        language, make decisions and improve from experience.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-genai"><glossterm>GenAI</glossterm>
    <glossdef>
      <para>
        <emphasis>Generative AI</emphasis> (GenAI) is a type of artificial
        intelligence that can create new content such as text, images or music.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-nlg"><glossterm>NLG</glossterm>
    <glossdef>
      <para>
        <emphasis>Natural Language Generation</emphasis> (NLG) is a process of
        automatically generating human-like text from structured data or other
        forms of input. NLG systems are designed to convert raw data into
        coherent and meaningful language easily understood by humans.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-nlu"><glossterm>NLU</glossterm>
    <glossdef>
      <para>
        <emphasis>Natural Language Understanding</emphasis> (NLU) is a process
        AI uses to analyze and understand the meaning of the input query.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-llm"><glossterm>LLM</glossterm>
    <glossdef>
      <para>
        <emphasis>Large Language Model</emphasis> (LLM) is an advanced AI model
        trained on amounts of text data to understand and generate human-like
        text. LLMs can perform tasks like translation, summarization and
        answering questions.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-gpu"><glossterm>GPU</glossterm>
    <glossdef>
      <para>
        <emphasis>Graphics Processing Unit</emphasis> (GPU) is specialized
        hardware designed for parallel processing. In AI applications, GPUs
        accelerate model training and inference tasks.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-prompt-engineering"><glossterm>Prompt Engineering</glossterm>
    <glossdef>
      <para>
        The practice of crafting effective input queries to AI models to obtain
        desired and accurate outputs. Good prompt engineering helps prevent
        hallucinations and improves response quality.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-system-prompt"><glossterm>System Prompt</glossterm>
    <glossdef>
      <para>
        Initial instructions given to an AI model that define its behavior, role
        and response parameters. System prompts help maintain consistent and
        appropriate AI responses.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-hallucination"><glossterm>Hallucination</glossterm>
    <glossdef>
      <para>
        An AI behavior where the model generates false or unsupported
        information that appears plausible but has no basis in provided context
        or real facts.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-vector-db"><glossterm>Vector Database</glossterm>
    <glossdef>
      <para>
        A specialized database designed to store and efficiently query
        high-dimensional vectors that represent data in AI applications,
        enabling similarity searches and semantic operations.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-inference"><glossterm>Inference</glossterm>
    <glossdef>
      <para>
        The process of using a trained AI model to make predictions or generate
        outputs based on new input data.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-embeddings"><glossterm>Embeddings</glossterm>
    <glossdef>
      <para>
        Numerical representations of data (text, images, etc.) in a
        high-dimensional space that capture semantic relationships and enable AI
        models to process information effectively.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-rag"><glossterm>RAG</glossterm>
    <glossdef>
      <para>
        <emphasis>Retrieval-Augmented Generation</emphasis> (RAG) is a technique
        that enhances AI responses by retrieving relevant information from a
        knowledge base before generating answers, improving accuracy and
        reducing hallucinations.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-fine-tuning"><glossterm>Fine-tuning</glossterm>
    <glossdef>
      <para>
        The process of further training a pre-trained AI model on specific data
        to adapt it for particular tasks or domains, improving its performance
        for targeted applications.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-context-window"><glossterm>Context Window</glossterm>
    <glossdef>
      <para>
        The maximum amount of text (tokens) that an AI model can process at
        once, including both the input prompt and generated response.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-token"><glossterm>Token</glossterm>
    <glossdef>
      <para>
        The basic unit of text processing in AI models, representing parts of
        words, characters or symbols. Models process text by breaking it into
        tokens for analysis and generation.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-quantization"><glossterm>Quantization</glossterm>
    <glossdef>
      <para>
        A technique to reduce AI model size and computational requirements by
        converting model parameters to lower precision formats while maintaining
        acceptable performance.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-vector-store"><glossterm>Vector Store</glossterm>
    <glossdef>
      <para>
        A specialized storage system optimized for managing and querying vector
        embeddings, essential for semantic search and RAG implementations in AI
        applications.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-chat-template"><glossterm>Chat Template</glossterm>
    <glossdef>
      <para>
        A structured format for organizing conversations between users and AI
        models, defining how system prompts, user inputs, and AI responses are
        formatted and processed.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-temperature"><glossterm>Temperature</glossterm>
    <glossdef>
      <para>
        A parameter controlling the randomness in AI model outputs. Lower values
        produce more focused and deterministic responses, while higher values
        increase creativity and variability.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-model-weights"><glossterm>Model Weights</glossterm>
    <glossdef>
      <para>
        The learned parameters of an AI model that determine how it processes
        inputs and generates outputs. These weights are adjusted during training
        to optimize model performance.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-cuda"><glossterm>CUDA</glossterm>
    <glossdef>
      <para>
        <emphasis>Compute Unified Device Architecture</emphasis> (CUDA) is
        NVIDIA's parallel computing platform and programming model used to
        accelerate AI workloads on GPU hardware.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-top-k"><glossterm>Top-K</glossterm>
    <glossdef>
      <para>
        A parameter that limits token selection during text generation to the K
        most likely next tokens, helping control output quality and relevance.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-top-p"><glossterm>Top-P</glossterm>
    <glossdef>
      <para>
        Also known as nucleus sampling, a parameter that selects from the
        smallest set of tokens whose cumulative probability exceeds P, providing
        dynamic control over text generation diversity.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-prompt-injection"><glossterm>Prompt Injection</glossterm>
    <glossdef>
      <para>
        A security vulnerability where malicious inputs attempt to override or
        bypass an AI model's system prompt or safety constraints.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-semantic-search"><glossterm>Semantic Search</glossterm>
    <glossdef>
      <para>
        A search method using AI to understand the meaning and context of
        queries rather than just matching keywords, enabling more relevant
        results.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-batch-size"><glossterm>Batch Size</glossterm>
    <glossdef>
      <para>
        The number of samples processed simultaneously during model inference,
        affecting processing speed and resource utilization.
      </para>
    </glossdef>
  </glossentry>
  <glossentry xml:id="gt-data-leakage"><glossterm>Data Leakage</glossterm>
    <glossdef>
      <para>
        The unintended exposure of sensitive information through AI model
        responses, potentially compromising data security and privacy.
      </para>
    </glossdef>
  </glossentry>
</glossary>
