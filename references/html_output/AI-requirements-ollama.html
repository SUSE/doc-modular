<FONT
COLOR="RED"
>&#13;  <FONT
COLOR="RED"
>&#13;    <P
><B
>Ollama requirements</B
></P
>
    <FONT
COLOR="RED"
></FONT
>
    <BLOCKQUOTE
CLASS="ABSTRACT"
><DIV
CLASS="abstract"
><P
></P
><A
NAME="AEN5"
></A
>
      <P
>&#13;        The version of Ollama provided with <SPAN
CLASS="phrase"
><SPAN
CLASS="phrase"
><SPAN
CLASS="phrase"
><SPAN
CLASS="phrase"
>SUSE AI</SPAN
></SPAN
><SPAN
CLASS="phrase"
><SPAN
CLASS="phrase"
>SUSE Linux Micro</SPAN
></SPAN
><SPAN
CLASS="phrase"
><SPAN
CLASS="phrase"
>SUSE Linux Micro</SPAN
></SPAN
><SPAN
CLASS="phrase"
><SPAN
CLASS="phrase"
>SUSE Linux Enterprise Server</SPAN
></SPAN
><SPAN
CLASS="phrase"
><SPAN
CLASS="phrase"
>SUSE Linux Enterprise Server for SAP applications</SPAN
></SPAN
><SPAN
CLASS="phrase"
><SPAN
CLASS="phrase"
>SUSE Linux Enterprise High Availability</SPAN
></SPAN
></SPAN
></SPAN
> is optimized for
        NVIDIA GPU hardware. This section guides you through the steps for
        configuring Ollama on an NVIDIA-enabled system, including necessary
        configurations for both the hardware and software.
      </P
>
    <P
></P
></DIV
></BLOCKQUOTE
>
  </FONT
>
  <DIV
CLASS="tip"
><P
></P
><TABLE
CLASS="tip"
WIDTH="100%"
BORDER="0"
><TR
><TD
WIDTH="25"
ALIGN="CENTER"
VALIGN="TOP"
><IMG
SRC="../images/tip.gif"
HSPACE="5"
ALT="Tip"></TD
><TH
ALIGN="LEFT"
VALIGN="MIDDLE"
><B
>General recommendations</B
></TH
></TR
><TR
><TD
>&nbsp;</TD
><TD
ALIGN="LEFT"
VALIGN="TOP"
>&#13;    
    <P
></P
><UL
><LI
>&#13;        <P
>&#13;          <SPAN
CLASS="bold"
><B
CLASS="emphasis"
>Run Ollama on NVIDIA GPU nodes.</B
></SPAN
>
          Since Ollama is GPU-optimized, using the power of NVIDIA GPUs is
          essential for maximum performance. This ensures that the application
          runs efficiently and fully uses the hardware capabilities.
        </P
>
      </LI
><LI
>&#13;        <P
>&#13;          <SPAN
CLASS="bold"
><B
CLASS="emphasis"
>Assign applications to specific
          nodes.</B
></SPAN
> <SPAN
CLASS="phrase"
><SPAN
CLASS="phrase"
><SPAN
CLASS="phrase"
><SPAN
CLASS="phrase"
>SUSE AI</SPAN
></SPAN
><SPAN
CLASS="phrase"
><SPAN
CLASS="phrase"
>SUSE Linux Micro</SPAN
></SPAN
><SPAN
CLASS="phrase"
><SPAN
CLASS="phrase"
>SUSE Linux Micro</SPAN
></SPAN
><SPAN
CLASS="phrase"
><SPAN
CLASS="phrase"
>SUSE Linux Enterprise Server</SPAN
></SPAN
><SPAN
CLASS="phrase"
><SPAN
CLASS="phrase"
>SUSE Linux Enterprise Server for SAP applications</SPAN
></SPAN
><SPAN
CLASS="phrase"
><SPAN
CLASS="phrase"
>SUSE Linux Enterprise High Availability</SPAN
></SPAN
></SPAN
></SPAN
> provides a mechanism to assign
          applications, such as Ollama, to specific nodes. For more details,
          refer to
          .
        </P
>
      </LI
></UL
>
  </TD
></TR
></TABLE
></DIV
>
  <DIV
CLASS="section"
><HR><H2
CLASS="section"
><A
NAME="AEN31"
>1. Hardware requirements</A
></H2
>
    
    <P
></P
><DIV
CLASS="variablelist"
><DL
><DT
>NVIDIA GPU</DT
><DD
>&#13;          <P
></P
><UL
><LI
>&#13;              <P
>&#13;                The recommended GPU models include Tesla, A100, V100, RTX 30
                series, or other compatible NVIDIA GPUs.
              </P
>
            </LI
><LI
>&#13;              <P
>&#13;                Ensure that the CUDA Compute Capability of your GPU is
                compatible with the required version of Ollama.
              </P
>
            </LI
></UL
>
        </DD
><DT
>RAM</DT
><DD
>&#13;          <P
>&#13;            At least 16 GB of RAM is recommended. However, higher amounts
            (32 GB or more) may be necessary for larger models or
            workloads.
          </P
>
        </DD
><DT
>Disk space</DT
><DD
>&#13;          <P
>&#13;            At least 50 GB of free disk space is recommended for storing
            the container images and any data files processed by Ollama.
          </P
>
        </DD
></DL
></DIV
>
  </DIV
>
  <DIV
CLASS="section"
><HR><H2
CLASS="section"
><A
NAME="AEN50"
>2. Software requirements</A
></H2
>
    
    <P
></P
><DIV
CLASS="variablelist"
><DL
><DT
>NVIDIA Docker (nvidia-docker)</DT
><DD
>&#13;          <P
></P
><UL
><LI
>&#13;              <P
>&#13;                You must install <FONT
COLOR="RED"
>nvidia-docker</FONT
> (the NVIDIA
                Container Toolkit) to allow Docker containers to use the GPU.
                Refer to
                
                for more details.
              </P
>
            </LI
></UL
>
        </DD
><DT
>CUDA Toolkit</DT
><DD
>&#13;          <P
>&#13;            You must install the CUDA version supported by your GPU model. For
            most recent GPUs, CUDA 11.0 or later is required. Refer to
            CUDA
            Toolkit installation guide for more details.
          </P
>
        </DD
><DT
>NVIDIA driver</DT
><DD
>&#13;          <P
>&#13;            Install the NVIDIA driver compatible with your GPU model. Its
            version must be compatible with the installed CUDA toolkit.
          </P
>
          <DIV
CLASS="tip"
><P
></P
><TABLE
CLASS="tip"
WIDTH="100%"
BORDER="0"
><TR
><TD
WIDTH="25"
ALIGN="CENTER"
VALIGN="TOP"
><IMG
SRC="../images/tip.gif"
HSPACE="5"
ALT="Tip"></TD
><TD
ALIGN="LEFT"
VALIGN="TOP"
>&#13;            <P
>&#13;              You can check your GPU driver version by running the
              <B
CLASS="command"
>nvidia-smi</B
> command.
            </P
>
          </TD
></TR
></TABLE
></DIV
>
        </DD
></DL
></DIV
>
  </DIV
>
</FONT
>