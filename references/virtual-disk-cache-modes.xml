<?xml version="1.0" encoding="UTF-8"?>
<!-- This file originates from the project https://github.com/openSUSE/doc-kit -->
<!-- This file can be edited downstream. -->
<!DOCTYPE topic
[
  <!ENTITY % entities SYSTEM "../common/generic-entities.ent">
    %entities;
]>
<!-- refers to legacy doc: <add github link to legacy doc piece, if applicable> -->
<!-- point back to this document with a similar comment added to your legacy doc piece -->
<!-- refer to README.md for file and id naming conventions -->
<!-- metadata is dealt with on the assembly level -->
<topic xml:id="virtual-disk-cache-modes"
 role="reference" xml:lang="en"
 xmlns="http://docbook.org/ns/docbook" version="5.2"
 xmlns:its="http://www.w3.org/2005/11/its"
 xmlns:xi="http://www.w3.org/2001/XInclude"
 xmlns:xlink="http://www.w3.org/1999/xlink"
 xmlns:trans="http://docbook.org/ns/transclusion">
  <info>
    <title>Virtual disk cache modes</title>
    <meta name="maintainer" content="tbazant@suse.com" its:translate="no"/>
    <abstract>
      <para>
        A virtual disk is an essential part of a virtual machine (VM). To speed up disk reading and
        writing operations, you can enable a caching mechanism. This article describes available
        disk caching modes and how they behave with regards to data integrity and live migration of
        VMs. The cache modes are sorted from the safest one to the least safe one.
      </para>
    </abstract>
  </info>
  <important>
    <para>
      If you do not specify a cache mode, <literal>writeback</literal> is used by default.
    </para>
  </important>
  <variablelist>
    <title>Virtual disk cache modes</title>
    <varlistentry xml:id="cache-none">
      <term>none</term>
      <listitem>
        <para>
          The host cache is bypassed, and reads and writes happen directly between the hypervisor
          and the storage device. Because the actual storage device may report a write as completed
          when the data is still placed in its write queue only, the guest's virtual storage
          adapter is informed that there is a <emphasis>writeback</emphasis> cache. This mode is
          equivalent to direct access to the host's disk.
        </para>
      </listitem>
    </varlistentry>
    <varlistentry xml:id="cache-writethrough">
      <term>writethrough</term>
      <listitem>
        <para>
          Writes are reported as completed only when the data has been written to the storage
          device, which happens immediately. The guest's virtual storage adapter is informed that
          there is no <emphasis>writeback</emphasis> cache, so the guest does not need to send
          flush commands to manage data integrity.
        </para>
      </listitem>
    </varlistentry>
    <varlistentry xml:id="cache-directsync">
      <term>directsync</term>
      <listitem>
        <para>
          Similar to <emphasis>writethrough</emphasis> but the host cache is bypassed.
        </para>
      </listitem>
    </varlistentry>
    <varlistentry xml:id="cache-writeback">
      <term>writeback</term>
      <listitem>
        <para>
          <literal>writeback</literal> uses the host disk cache. Writes are reported to the guest
          as completed when they are placed in the host cache. Cache management handles writing
          cached data to the storage device, which can happen later. The guest's virtual storage
          adapter is informed of the <emphasis>writeback</emphasis> cache and therefore expected to
          send flush commands as needed to manage data integrity.
        </para>
      </listitem>
    </varlistentry>
    <varlistentry xml:id="cache-unsafe">
      <term>unsafe</term>
      <listitem>
        <para>
          Similar to the <emphasis>writeback</emphasis> mode, except all flush commands from the
          guests are ignored. Using this mode implies that the user prioritizes performance gain
          over data security.
        </para>
        <xi:include href="../snippets/unsafe-cache-mode-warning.xml"/>
      </listitem>
    </varlistentry>
    <varlistentry xml:id="cache-default">
      <term>default</term>
      <listitem>
        <para>
          The default cache mode of the used hypervisor is enabled.
        </para>
      </listitem>
    </varlistentry>
  </variablelist>
  <section xml:id="cache-modes-data-integrity">
    <title>Cache modes and data integrity</title>
    <variablelist>
      <varlistentry>
        <term>writethrough, none, directsync</term>
        <listitem>
          <para>
            These modes are considered to be the safest when the guest operating system uses
            flushes as needed. For unsafe or unstable guests, use <emphasis>writethrough</emphasis>
            or <emphasis>directsync</emphasis>.
          </para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term>writeback</term>
        <listitem>
          <para>
            This mode informs the guest of the presence of a write cache, and it relies on the
            guest to send flush commands as needed to maintain data integrity within its disk
            image.
          </para>
          <warning>
            <para>
              Using the <emphasis>writeback</emphasis> mode exposes the guest to data loss in case
              of a host failure. It is caused by the gap between when a write is reported as
              completed and when it is written to the storage device.
            </para>
          </warning>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term>unsafe</term>
        <listitem>
          <para>
            This mode is similar to <emphasis>writeback</emphasis> caching, except the guest flush
            commands are ignored.
          </para>
          <xi:include href="../snippets/unsafe-cache-mode-warning.xml"/>
        </listitem>
      </varlistentry>
    </variablelist>
  </section>
  <section xml:id="cache-modes-live-migration">
    <title>Cache modes and live migration</title>
    <para>
      The caching of storage data restricts the configurations that support live migration.
      Currently, only <literal>raw</literal> and <literal>qcow2</literal> image formats can be used
      for live migration. If a clustered file system is used, all cache modes support live
      migration. Otherwise, the only cache mode that supports live migration on read/write shared
      storage is <literal>none</literal>.
    </para>
    <para>
      The &libvirt; management layer includes checks for migration compatibility based on several
      factors. If the guest storage is hosted on a clustered file system, is read-only, or is
      marked shareable, then the cache mode is ignored when determining if migration can be
      allowed. Otherwise, &libvirt; does not allow migration unless the cache mode is set to
      <literal>none</literal>.
    </para>
    <warning>
      <title>Unsafe live migration</title>
      <para>
        If you need to do a live migration with a different cache mode than
        <literal>none</literal>, use the <option>--unsafe</option> option, for example:
      </para>
<screen>&prompt.user;virsh migrate --live --unsafe</screen>
      <para>
        Be aware that this option may cause loss of data that the migrated VM is caching.
      </para>
    </warning>
    <tip>
      <para>
        When using the <literal>native</literal> asynchronous I/O mode (AIO) in &libvirt;, the
        cache mode <literal>none</literal> is required. Using a different caching mode switches the
        AIO mode back to the default <literal>threads</literal>.
      </para>
    </tip>
  </section>
</topic>
