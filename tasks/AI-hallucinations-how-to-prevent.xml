<?xml version="1.0" encoding="UTF-8"?>
<!-- This file originates from the project https://github.com/openSUSE/doc-kit -->
<!-- This file can be edited downstream. -->
<!DOCTYPE topic
[
  <!ENTITY % entities SYSTEM "../common/generic-entities.ent">
    %entities;
]>
<topic xml:id="ai-hallucinations-how-to-prevent"
 role="concept" xml:lang="en"
 xmlns="http://docbook.org/ns/docbook" version="5.2"
 xmlns:its="http://www.w3.org/2005/11/its"
 xmlns:xi="http://www.w3.org/2001/XInclude"
 xmlns:xlink="http://www.w3.org/1999/xlink"
 xmlns:trans="http://docbook.org/ns/transclusion">
  <info>
    <title>How can I prevent AI from generating hallucinations?</title>
    <meta name="maintainer" content="tbazant@suse.com" its:translate="no"/>
    <abstract>
      <para>
        You can help the AI model generate more reliable and precise content by
        creating effective prompts. This process is called <emphasis>prompt
        engineering</emphasis>. This section outlines several techniques to
        create a good prompt with real-life examples.
      </para>
    </abstract>
  </info>
  <section xml:id="ai-clear-expectations">
    <title>Set clear expectations</title>
    <para>
      The clearer the prompt, the less the LLM relies on assumptions or
      creativity. A well-defined prompt guides the model toward specific
      information, reducing the likelihood of hallucinations.
    </para>
    <itemizedlist>
      <title>Techniques:</title>
      <listitem>
        <para>
          Use <emphasis role="bold">specific language</emphasis> that guides the
          model.
        </para>
      </listitem>
      <listitem>
        <para>
          Focus on <emphasis role="bold">known data sources</emphasis> or real
          events.
        </para>
      </listitem>
      <listitem>
        <para>
          Request <emphasis role="bold">summaries</emphasis> or
          <emphasis>paraphrasing</emphasis> from established sources.
        </para>
      </listitem>
    </itemizedlist>
    <itemizedlist>
      <title>Example</title>
      <listitem>
        <para>
          <emphasis role="bold">Ambiguous prompt:</emphasis> <quote>Tell me
          about space.</quote>
        </para>
      </listitem>
      <listitem>
        <para>
          <emphasis role="bold">Clearer prompt:</emphasis> <quote>Give me a
          summary of NASA's recent Mars missions, including factual details from
          their official reports.</quote>
        </para>
      </listitem>
    </itemizedlist>
    <itemizedlist>
      <title>Example</title>
      <listitem>
        <para>
          <emphasis role="bold">Ambiguous prompt:</emphasis> <quote>What is
          quantum computing?</quote>
        </para>
      </listitem>
      <listitem>
        <para>
          <emphasis role="bold">Clearer prompt: </emphasis> <quote>Explain the
          basic principles of quantum computing, specifically how qubits work
          compared to classical bits.</quote>
        </para>
      </listitem>
    </itemizedlist>
  </section>
  <section xml:id="ai-break-complex">
    <title>Break down complex prompts</title>
    <para>
      Break down complex or broad prompts into manageable pieces. This keeps the
      language model focused on a narrower scope and reduces the chance of
      hallucination.
    </para>
    <itemizedlist>
      <title>Example</title>
      <listitem>
        <para>
          <emphasis role="bold">Complex query:</emphasis> <quote>Explain AI and
          how it can change the world.</quote>
        </para>
      </listitem>
      <listitem>
        <para>
          <emphasis role="bold">Broken down prompt:</emphasis> <quote>What are
          the most recent advancements in AI? How are these advancements being
          applied in the healthcare industry?</quote>
        </para>
      </listitem>
    </itemizedlist>
  </section>
  <section xml:id="ai-rag">
    <title>Use retrieval-augmented generation (RAG)</title>
    <para>
      When crafting prompts, encourage the model to retrieve relevant
      information instead of generating from scratch. Integrating a RAG system
      allows the LLM to query a specific database or resource.
    </para>
    <itemizedlist>
      <title>Techniques</title>
      <listitem>
        <para>
          Include context cues, for example, <quote>Based on the following
          document</quote> or <quote>From the official Web site</quote> to point
          the model toward facts.
        </para>
      </listitem>
      <listitem>
        <para>
          If using a tool like &milvus; or &chromadb;, structure your prompt to
          refer to specific collections or documents. This reduces hallucination
          by grounding the LLM in real data.
        </para>
      </listitem>
    </itemizedlist>
    <itemizedlist>
      <title>Example</title>
      <listitem>
        <para>
          <emphasis role="bold">Prompt without RAG:</emphasis> <quote>Tell me
          about the company's AI products.</quote>
        </para>
      </listitem>
      <listitem>
        <para>
          <emphasis role="bold">Prompt with RAG:</emphasis> <quote>Based on the
          <quote>technical-info</quote> collection in &milvus;, provide details
          about the company's AI product line.</quote>
        </para>
      </listitem>
    </itemizedlist>
  </section>
  <section xml:id="ai-contrain">
    <title>Constrain the output</title>
    <para>
      Limit the length or scope of the language model's response. Shorter, more
      direct answers reduce the chances of the model drifting off-topic or
      hallucinating extra details.
    </para>
    <itemizedlist>
      <title>Technique</title>
      <listitem>
        <para>
          Use <emphasis>tokens</emphasis> or <emphasis>word limits</emphasis>
          where possible to enforce the output length.
        </para>
      </listitem>
    </itemizedlist>
    <itemizedlist>
      <title>Example</title>
      <listitem>
        <para>
          <emphasis role="bold">Unconstrained prompt:</emphasis> <quote>Give me
          a detailed report on quantum mechanics.</quote>
        </para>
      </listitem>
      <listitem>
        <para>
          <emphasis role="bold">Prompt with limited output:</emphasis> <quote>In
          100 words or fewer, explain the main concept of quantum
          entanglement.</quote>
        </para>
      </listitem>
    </itemizedlist>
  </section>
  <section xml:id="ai-prompt-verification">
    <title>Prompt for verification</title>
    <para>
      You can structure prompts to ask the LLM for clarification or to cite the
      source of its statements. This leads the model to produce more grounded
      and reliable responses.
    </para>
    <itemizedlist>
      <title>Examples</title>
      <listitem>
        <para>
          <quote>Where did you find this information?</quote>
        </para>
      </listitem>
      <listitem>
        <para>
          <quote>Verify this answer against known historical facts about the
          event.</quote>
        </para>
      </listitem>
    </itemizedlist>
  </section>
  <section xml:id="ai-cot">
    <title>Use chain-of-thought (CoT) prompting</title>
    <para>
      By guiding the model through logical steps, you can control the reasoning
      path and help the model arrive at accurate conclusions. This method is
      especially helpful when asking the model to explain complex processes.
    </para>
    <itemizedlist>
      <title>Example</title>
      <listitem>
        <para>
          <emphasis role="bold">Step-by-step prompt: </emphasis> <quote>Explain
          the following concepts step by step: 1. How do neural networks learn
          from data? 2. How is backpropagation used in this process?</quote>
        </para>
      </listitem>
    </itemizedlist>
  </section>
  <section xml:id="ai-prompt-template">
    <title>Use templates for complex tasks</title>
    <para>
      For complex tasks, for example, answering requests for proposals or
      technical questions, templates help provide a structure that minimizes
      hallucinations. This is achieved by making the desired format and content
      explicit.
    </para>
    <itemizedlist>
      <title>Example</title>
      <listitem>
        <para>
          <quote>Based on the document provided, summarize the key technical
          features of the product. Format the response as: 1. Feature, 2.
          Benefit, 3. Use case. Use only factual information.</quote>
        </para>
      </listitem>
    </itemizedlist>
  </section>
  <section xml:id="ai-system-prompts-formoreinfo">
    <title>For more information</title>
    <itemizedlist>
      <listitem>
        <para>
          Find good examples of system prompts in
          <link xlink:href="&dsc;/suse-ai/1.0/html/AI-system-prompts/index.html"/>.
        </para>
      </listitem>
    </itemizedlist>
  </section>
</topic>
