<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic
[
  <!ENTITY % entities SYSTEM "../common/generic-entities.ent">
    %entities;
]>

<!-- refers to legacy doc: https://github.com/SUSE/doc-sleha/blob/main/xml/ha_managing_resources.xml -->

<topic xml:id="ha-resources-cleaning-up"
 role="task" xml:lang="en"
 xmlns="http://docbook.org/ns/docbook" version="5.2"
 xmlns:its="http://www.w3.org/2005/11/its"
 xmlns:xi="http://www.w3.org/2001/XInclude"
 xmlns:xlink="http://www.w3.org/1999/xlink"
 xmlns:trans="http://docbook.org/ns/transclusion">
  <info>
    <title>Cleaning up failed resources</title>
    <meta name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
    <abstract>
      <para>
   A resource is automatically restarted if it fails, but each failure
   increases the resource's fail count.
  </para>
  <para>
   If a <literal>migration-threshold</literal> has been set for the resource,
   the node can no longer run the resource when the number of failures reaches
   the migration threshold.
  </para>
  <para>
   By default, fail counts are not automatically reset. You can configure a fail count
   to be reset automatically by setting a <literal>failure-timeout</literal> option for the
   resource, or you can manually reset the fail count using either &hawk; or &crmsh;.
  </para>
    </abstract>
  </info>

<section xml:id="sec-conf-hawk2-manage-cleanup">
  <title>Cleaning up cluster resources with &hawk;</title>
  <procedure xml:id="pro-hawk2-clean">
   <title>Cleaning up a resource</title>
   <step>
    <para>
     Log in to &hawk;:
    </para>
<screen>https://<replaceable>HAWKSERVER</replaceable>:7630/</screen>
   </step>
   <step>
    <para>
     From the left navigation bar, select <guimenu>Status</guimenu>. The list of
     <guimenu>Resources</guimenu> also shows the <guimenu>Status</guimenu>.
    </para>
   </step>
   <step>
    <para>
     Go to the resource to clean up. In the <guimenu>Operations</guimenu>
     column, click the arrow down button and select <guimenu>Cleanup</guimenu>.
     To continue, confirm the message that appears.
    </para>
    <para>
     This executes the command <command>crm resource cleanup</command> and
     cleans up the resource on all nodes.
    </para>
   </step>
  </procedure>
  </section>

  <section xml:id="sec-ha-manual-config-cleanup">
   <title>Cleaning up cluster resources with &crmsh;</title>
   <procedure>
    <title>Cleaning up a resource with &crmsh;</title>
    <step>
     <para>
      Open a shell and log in as user &rootuser;.
     </para>
    </step>
    <step>
     <para>
      Get a list of all your resources:
     </para>
 <screen>&prompt.root;<command>crm resource status</command>
Full List of Resources
   * admin-ip      (ocf:heartbeat:IPaddr2):    Started
   * stonith-sbd   (stonith:external/sbd):     Started
   * Resource Group: dlm-clvm:
     * dlm:        (ocf:pacemaker:controld)    Started
     * clvm:       (ocf:heartbeat:lvmlockd)    Started</screen>
    </step>
    <step>
      <para>
        Show the fail count of a resource:
      </para>
<screen>&prompt.root;<command>crm resource failcount <replaceable>RESOURCE</replaceable> show <replaceable>NODE</replaceable></command></screen>
      <para>
        For example, to show the fail count of the resource <literal>dlm</literal> on node
        <literal>&node1;</literal>:
      </para>
<screen>&prompt.root;<command>crm resource failcount dlm show &node1;</command>
scope=status name=fail-count-dlm value=2</screen>
    </step>
    <step>
     <para>
      Clean up the resource:
     </para>
 <screen>&prompt.root;<command>crm resource cleanup <replaceable>RESOURCE</replaceable></command></screen>
      <para>
        This command cleans up the resource on all nodes. If the resource is part of a group,
        &crmsh; also cleans up the other resources in the group.
      </para>
    </step>
   </procedure>
  </section>
</topic>
