<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic
[
  <!ENTITY % entities SYSTEM "../common/generic-entities.ent">
    %entities;
]>

<topic xml:id="ha-sbd-replacing-existing-device-with-new-device"
 role="task" xml:lang="en"
 xmlns="http://docbook.org/ns/docbook" version="5.2"
 xmlns:its="http://www.w3.org/2005/11/its"
 xmlns:xi="http://www.w3.org/2001/XInclude"
 xmlns:xlink="http://www.w3.org/1999/xlink"
 xmlns:trans="http://docbook.org/ns/transclusion">
  <info>
    <title>Replacing an existing &sbd; device with a new device</title>
    <meta name="maintainer" content="tahlia.richardson@suse.com" its:translate="no"/>
    <abstract>
      <para>
        TODO: If you need to replace an &sbd; device, you can use <command>crm sbd device add</command> to add a new device, and <command>crm sbd device remove</command> to remove the old device. The order of these commands depends on how many &sbd; devices the cluster currently has.
      </para>
    </abstract>
  </info>

  <para>
    TODO: Add cluster restart warning when available.
  </para>
  <itemizedlist>
    <title>Requirements</title>
    <listitem>
      <para>
        Disk-based &sbd; is already configured and running with at least one device.
      </para>
    </listitem>
    <listitem>
      <para>
        An additional shared storage device is accessible from all cluster nodes.
      </para>
    </listitem>
  </itemizedlist>
  <para>
    Perform this procedure on only one node in the cluster:
  </para>
  <procedure>
    <step>
      <para>
        Log in either as the &rootuser; user or as a user with <command>sudo</command> privileges.
      </para>
    </step>
    <step>
      <para>
        Check which device or devices are already configured for use with &sbd;:
      </para>
<screen>&prompt.user;<command>sudo crm sbd configure show sysconfig</command></screen>
      <para>
        The output shows one or more device IDs in the <literal>SBD_DEVICE</literal> line.
      </para>
      <tip>
        <title>Order of next steps </title>
        <para>
          The cluster cannot have more than three &sbd; devices. If the cluster already has three
          devices, you must remove the old device before you can add the new device.
        </para>
      </tip>
    </step>
    <step>
      <para>
        Add the new device to the existing &sbd; configuration:
      </para>
<screen>&prompt.user;<command>sudo crm sbd device add /dev/disk/by-id/<replaceable>DEVICE_ID</replaceable></command></screen>
      <para>
        The script might warn you to manually restart the cluster services, but you do not need to
        do this until after you remove the old device.
      </para>
    </step>
    <step>
      <para>
        Remove the old device from the &sbd; configuration:
      </para>
<screen>&prompt.user;<command>sudo crm sbd device remove /dev/disk/by-id/<replaceable>DEVICE_ID</replaceable></command></screen>
      <para>
        The script updates the &sbd; configuration file and checks whether it is safe to restart
        the cluster services automatically. If any non-&stonith; resources are running, the script
        warns you to restart the cluster services manually.
      </para>
    </step>
    <step>
      <para>
        TODO: Add cluster restart steps when available
      </para>
    </step>
    <step>
      <para>
        Check the &sbd; configuration again:
      </para>
<screen>&prompt.user;<command>sudo crm sbd configure show sysconfig</command></screen>
      <para>
        The output should now show the new device in the <literal>SBD_DEVICE</literal> line.
      </para>
    </step>
    <step>
      <para>
        Check the status of &sbd; to make sure the correct device is listed:
      </para>
<screen>&prompt.user;<command>sudo crm sbd status</command></screen>
    </step>
  </procedure>
</topic>
