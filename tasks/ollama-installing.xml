<?xml version="1.0" encoding="UTF-8"?>
<!-- This file originates from the project https://github.com/openSUSE/doc-kit -->
<!-- This file can be edited downstream. -->
<!DOCTYPE topic
[
  <!ENTITY % entities SYSTEM "../common/generic-entities.ent">
    %entities;
]>
<topic xml:id="ollama-installing"
 role="task" xml:lang="en"
 xmlns="http://docbook.org/ns/docbook" version="5.2"
 xmlns:its="http://www.w3.org/2005/11/its"
 xmlns:xi="http://www.w3.org/2001/XInclude"
 xmlns:xlink="http://www.w3.org/1999/xlink"
 xmlns:trans="http://docbook.org/ns/transclusion">
  <info>
    <title>Installing &ollama;</title>
    <meta name="maintainer" content="tbazant@suse.com" its:translate="no"/>
    <abstract>
      <para>
        &ollama; is a tool for running and managing language models locally on
        your computer. It offers a simple interface to download, run and
        interact with models without relying on cloud resources.
      </para>
    </abstract>
  </info>
  <tip os="suseai">
    <para>
      When installing &suseai;, &ollama; is installed by the &owui; installation
      by default. If you decide to install &ollama; separately, disable its
      installation during the installation of &owui; as outlined in
      <xref
      linkend="owui-ollama-deploy-separate"/>.
    </para>
  </tip>
  <section xml:id="ollama-installing-app-details">
    <title>Details about the &ollama; application</title>
    <para>
      Before deploying &ollama;, it is important to know more about the
      supported configurations and documentation. The following command provides
      the corresponding details:
    </para>
<screen>helm show values oci://dp.apps.rancher.io/charts/ollama</screen>
    <para>
      Alternatively, you can also refer to the &ollama; &helm; chart page on the
      &rancherappco; site at
      <link xlink:href="https://apps.rancher.io/applications/ollama"/>. It
      contains the available versions and a link to pull the &ollama; container
      image.
    </para>
  </section>
  <section xml:id="ollama-installing-procedure">
    <title>&ollama; installation procedure</title>
    <procedure>
      <itemizedlist>
        <title>Requirements</title>
        <para>
          To install &ollama;, you need to have the following:
        </para>
        <listitem>
          <para>
            The <command>helm</command> command properly installed.
          </para>
        </listitem>
        <listitem>
          <para>
            A running &kube; cluster, such as &k3s;.
          </para>
        </listitem>
      </itemizedlist>
      <step>
        <para>
          Visit the &rancherappco;, sign in, and get the access token as
          described in
          <link
        xlink:href="https://docs.apps.rancher.io/get-started/authentication/"/>.
        </para>
      </step>
      <step performance="optional">
        <para>
          Create a &kube; namespace if it does not already exist. The steps in
          this procedure assume that all containers are deployed into the same
          namespace referred to as <replaceable>SUSE_AI_NAMESPACE</replaceable>.
          Replace its name to match your preferences.
        </para>
<screen>&prompt.user;<command>kubectl create namespace <replaceable>SUSE_AI_NAMESPACE</replaceable></command></screen>
      </step>
      <step>
        <para>
          Create the &rancherappco; secret.
        </para>
<screen>&prompt.user;<command>kubectl create secret docker-registry application-collection \
  --docker-server=dp.apps.rancher.io \
  --docker-username=<replaceable>APPCO_USERNAME</replaceable> \
  --docker-password=<replaceable>APPCO_USER_TOKEN</replaceable> \
  -n <replaceable>SUSE_AI_NAMESPACE</replaceable></command></screen>
      </step>
      <step>
        <para>
          Log in to the &helm; registry.
        </para>
<screen>&prompt.user;<command>helm registry login dp.apps.rancher.io/charts \
  -u <replaceable>APPCO_USERNAME</replaceable> \
  -p <replaceable>APPCO_USER_TOKEN</replaceable></command></screen>
      </step>
      <step>
        <para>
          Create the <filename>ollama_custom_overrides.yaml</filename> file to
          override the values of the parent &helm; chart. Refer to
          <xref
          linkend="ollama-helmchart"/> for more details.
        </para>
      </step>
      <step>
        <para>
          Install the &ollama; &helm; chart using the
          <filename>ollama-custom-overrides.yaml</filename> override file.
        </para>
<screen>&prompt.user;<command>helm upgrade --install ollama oci://dp.apps.rancher.io/charts/ollama \
  -n <replaceable>SUSE_AI_NAMESPACE</replaceable> \
  --version 0.54.0 -f <replaceable>ollama_custom_overrides.yaml</replaceable></command></screen>
      </step>
    </procedure>
  </section>
  <section xml:id="ollama-uninstalling">
    <title>Uninstalling &ollama;</title>
    <para>
      To uninstall &ollama;, run the following command:
    </para>
<screen>&prompt.user;<command>helm uninstall ollama -n <replaceable>SUSE_AI_NAMESPACE</replaceable></command></screen>
  </section>
  <section xml:id="ollama-upgrading">
    <title>Upgrading &ollama;</title>
    <para>
      You can upgrade &ollama; to a specific version by running the following
      command:
    </para>
<screen>&prompt.user;<command>helm upgrade ollama oci://dp.apps.rancher.io/charts/ollama \
  -n <replaceable>SUSE_AI_NAMESPACE</replaceable> \
  --version <replaceable>OLLAMA_VERSION_NUMBER</replaceable> -f <replaceable>ollama_custom_overrides.yaml</replaceable></command></screen>
    <para>
      If you ommit the <option>--version</option> option, &ollama; gets upgraded
      to the latest available version.
    </para>
    <section xml:id="ollama-upgrading-0-to-1">
      <title>Upgrading from version 0.x.x to 1.x.x</title>
      <para>
        The version 1.x.x introduces the ability to load models in memory at
        startup. To reflect this, change <option>ollama.models</option> to
        <option>ollama.models.pull</option> in the &ollama; &helm; chart to
        avoid errors before upgrading, for example:
      </para>
      <example>
      <title>&ollama; &helm; chart version 0.x.x</title>
<screen>
[...]
ollama:
  models:
    - "gemma:2b"
    - "llama3.1"</screen>
      </example>
      <example>
      <title>&ollama; &helm; chart version 1.x.x</title>
<screen>
[...]
ollama:
  models:
    pull:
      - "gemma:2b"
      - "llama3.1"</screen>
      </example>
    <para>
      Without this change you may experience the following error when trying to
      upgrade from 0.x.x to 1.x.x.
    </para>
<screen>coalesce.go:286: warning: cannot overwrite table with non table for
ollama.ollama.models (map[pull:[] run:[]])
Error: UPGRADE FAILED: template: ollama/templates/deployment.yaml:145:27:
executing "ollama/templates/deployment.yaml" at &lt;.Values.ollama.models.pull&gt;:
can't evaluate field pull in type interface {}</screen>
    </section>
  </section>
</topic>
