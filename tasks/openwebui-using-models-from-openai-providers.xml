<?xml version="1.0" encoding="UTF-8"?>
<!-- This file originates from the project https://github.com/openSUSE/doc-kit -->
<!-- This file can be edited downstream. -->
<!DOCTYPE topic
[
  <!ENTITY % entities SYSTEM "../common/generic-entities.ent">
    %entities;
]>
<!-- refers to legacy doc: <add github link to legacy doc piece, if applicable> -->
<!-- point back to this document with a similar comment added to your legacy doc piece -->
<!-- refer to README.md for file and id naming conventions -->
<!-- metadata is dealt with on the assembly level -->
<topic xml:id="openwebui-using-models-from-openai-providers"
 role="task" xml:lang="en"
 xmlns="http://docbook.org/ns/docbook" version="5.2"
 xmlns:its="http://www.w3.org/2005/11/its"
 xmlns:xi="http://www.w3.org/2001/XInclude"
 xmlns:xlink="http://www.w3.org/1999/xlink"
 xmlns:trans="http://docbook.org/ns/transclusion">
  <info>
    <title>Using AI models from &openai;-compatible providers</title>
    <meta name="maintainer" content="tbazant@suse.com" its:translate="no"/>
    <abstract>
      <para>
        Instead of downloading AI models locally, you can use
        &openai;-compatible API to access models from model providers. These
        providers include both local instances of servers such as
        <link xlink:href="https://localai.io/">LocalAI</link> or
        <link xlink:href="https://github.com/Mozilla-Ocho/llamafile">llamafile</link>,
        and cloud providers such as
        <link xlink:href="https://groq.com/">Groq</link> or
        <link xlink:href="https://openai.com/api/">&openai;</link>. This
        procedure describes how to configure the Groq provider API from the
        &owui; interface.
      </para>
    </abstract>
  </info>
  <procedure>
    <itemizedlist>
      <title>Requirements</title>
      <listitem>
        <xi:include href="../snippets/openwebui-requirement-admin-privileges.xml"/>
      </listitem>
    </itemizedlist>
    <step>
      <para>
        Navigate your Web browser to
        <link
        xlink:href="https://huggingface.co/models"/> and in the
        left <guimenu>Libraries</guimenu> section, click <guimenu>GGUF</guimenu>
        to include only GGUF models to choose from, for example,
        <guimenu>gemma-7b</guimenu>.
      </para>
      <figure xml:id="fig-huggingface-selecting-model">
        <title>Finding models on &huggingface;</title>
        <mediaobject>
          <imageobject role="fo">
            <imagedata fileref="huggingface-selecting-model.png" width="75%"/>
          </imageobject>
          <imageobject role="html">
            <imagedata fileref="huggingface-selecting-model.png" width="75%"/>
          </imageobject>
          <textobject role="description"><phrase>Finding models on &huggingface;</phrase>
          </textobject>
        </mediaobject>
      </figure>
    </step>
    <step>
      <para>
        Click the model name to open its model card and select
        <menuchoice><guimenu>Use this
        model</guimenu><guimenu>Ollama</guimenu></menuchoice>
      </para>
      <figure xml:id="fig-huggingface-model-card">
        <title>&huggingface; model card</title>
        <mediaobject>
          <imageobject role="fo">
            <imagedata fileref="huggingface-mode-card.png" width="100%"/>
          </imageobject>
          <imageobject role="html">
            <imagedata fileref="huggingface-mode-card.png" width="100%"/>
          </imageobject>
          <textobject role="description"><phrase>&huggingface; model card</phrase>
          </textobject>
        </mediaobject>
      </figure>
    </step>
    <step>
      <para>
        From the <guimenu>How to use</guimenu> pop-up, select the full path to
        the model, for example, <literal>hf.co/google/gemma-7b</literal>.
      </para>
      <figure xml:id="fig-huggingface-model-ollama">
        <title>&ollama; download on &huggingface;</title>
        <mediaobject>
          <imageobject role="fo">
            <imagedata fileref="huggingface-ollama-download.png" width="50%"/>
          </imageobject>
          <imageobject role="html">
            <imagedata fileref="huggingface-ollama-download.png" width="50%"/>
          </imageobject>
          <textobject role="description"><phrase>&ollama; download on &huggingface;</phrase>
          </textobject>
        </mediaobject>
      </figure>
    </step>
    <step>
      <para>
        In the bottom left of the &owui; window, click your avatar icon to open
        the user menu and select <guimenu>Admin Panel</guimenu>.
      </para>
    </step>
    <step>
      <para>
        Click the <guimenu>Settings</guimenu> tab and select
        <guimenu>Connections</guimenu> from the left menu.
      </para>
    </step>
    <step>
      <para>
        In the right of the <guimenu>Manage Ollama API Connections</guimenu>,
        click the small <quote>download</quote> icon to open the <guimenu>Manage
        Ollama</guimenu> screen.
      </para>
      <figure xml:id="fig-owui-dld-ollama-model-hf">
        <title>Downloading &ollama; models from &huggingface;</title>
        <mediaobject>
          <imageobject role="fo">
            <imagedata fileref="owui-dld-ollama-huggingface.png" width="100%"/>
          </imageobject>
          <imageobject role="html">
            <imagedata fileref="owui-dld-ollama-huggingface.png" width="100%"/>
          </imageobject>
          <textobject role="description"><phrase>Downloading &ollama; models from &huggingface;</phrase>
          </textobject>
        </mediaobject>
      </figure>
    </step>
    <step>
      <para>
        Paste the full path to the model tag from &huggingface; in the
        <guimenu>Pull a model from Ollama.com</guimenu> input field and confirm
        by clicking the small download button on the right.
      </para>
      <figure xml:id="fig-owui-dld-model-tag-hf">
        <title>Entering model tag to download</title>
        <mediaobject>
          <imageobject role="fo">
            <imagedata fileref="owui-dld-ollama-huggingface-popup.png" width="75%"/>
          </imageobject>
          <imageobject role="html">
            <imagedata fileref="owui-dld-ollama-huggingface-popup.png" width="75%"/>
          </imageobject>
          <textobject role="description"><phrase>Entering model tag to download</phrase>
          </textobject>
        </mediaobject>
      </figure>
      <para>
        The model download starts and after it is finished, the model will be
        available as a base model for AI interaction.
      </para>
    </step>
  </procedure>
</topic>
